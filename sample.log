ğŸŸ© ãƒ­ã‚°ã‚’åˆæœŸåŒ–
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=128 mult=2
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© Parsing model identifier. Schema: None, Identifier: ViT-L-14
ğŸŸ© Loaded built-in ViT-L-14 model config.
ğŸŸ¦ Starting new HTTPS connection (1): huggingface.co:443
ğŸŸ¦ https://huggingface.co:443 "HEAD /timm/vit_large_patch14_clip_224.openai/resolve/main/open_clip_model.safetensors HTTP/1.1" 302 0
ğŸŸ© Instantiating model architecture: CLIP
ğŸŸ© Loading full pretrained weights from: /root/.cache/huggingface/hub/models--timm--vit_large_patch14_clip_224.openai/snapshots/18d0535469bb561bf468d76c1d73aa35156c922b/open_clip_model.safetensors
ğŸŸ© Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}
ğŸŸ© Model ViT-L-14 creation process complete.
ğŸŸ¦ https://huggingface.co:443 "HEAD /anas-awadalla/mpt-1b-redpajama-200b/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/anas-awadalla/mpt-1b-redpajama-200b/50d6bc94e17812873f39c36c5f815263fa71fb80/tokenizer_config.json HTTP/1.1" 200 0
ğŸŸ¦ https://huggingface.co:443 "GET /api/models/anas-awadalla/mpt-1b-redpajama-200b/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
ğŸŸ© ãƒ‘ãƒƒãƒ‰ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¿½åŠ 
ğŸŸ© ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’èª­ã¿è¾¼ã¿ GPTNeoXTokenizerFast(name_or_path='anas-awadalla/mpt-1b-redpajama-200b', vocab_size=50254, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<|endofchunk|>', '<image>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	0: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	1: AddedToken("<|padding|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	50254: AddedToken("                        ", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),
	50255: AddedToken("                       ", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),
	50256: AddedToken("                      ", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),
	50257: AddedToken("                     ", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),
	50258: AddedToken("                    ", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),
	50259: AddedToken("                   ", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),
	50260: AddedToken("                  ", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),
	50261: AddedToken("                 ", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),
	50262: AddedToken("                ", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),
	50263: AddedToken("               ", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),
	50264: AddedToken("              ", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),
	50265: AddedToken("             ", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),
	50266: AddedToken("            ", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),
	50267: AddedToken("           ", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),
	50268: AddedToken("          ", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),
	50269: AddedToken("         ", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),
	50270: AddedToken("        ", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),
	50271: AddedToken("       ", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),
	50272: AddedToken("      ", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),
	50273: AddedToken("     ", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),
	50274: AddedToken("    ", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),
	50275: AddedToken("   ", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),
	50276: AddedToken("  ", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),
	50277: AddedToken("<|endofchunk|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	50278: AddedToken("<image>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	50279: AddedToken("<PAD>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
ğŸŸ¦ https://huggingface.co:443 "HEAD /anas-awadalla/mpt-1b-redpajama-200b/resolve/main/config.json HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/anas-awadalla/mpt-1b-redpajama-200b/50d6bc94e17812873f39c36c5f815263fa71fb80/config.json HTTP/1.1" 200 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /anas-awadalla/mpt-1b-redpajama-200b/resolve/main/configuration_mosaic_gpt.py HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/anas-awadalla/mpt-1b-redpajama-200b/50d6bc94e17812873f39c36c5f815263fa71fb80/configuration_mosaic_gpt.py HTTP/1.1" 200 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /anas-awadalla/mpt-1b-redpajama-200b/resolve/main/mosaic_gpt.py HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/anas-awadalla/mpt-1b-redpajama-200b/50d6bc94e17812873f39c36c5f815263fa71fb80/mosaic_gpt.py HTTP/1.1" 200 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /anas-awadalla/mpt-1b-redpajama-200b/resolve/main/model.safetensors HTTP/1.1" 404 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /anas-awadalla/mpt-1b-redpajama-200b/resolve/main/generation_config.json HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/anas-awadalla/mpt-1b-redpajama-200b/50d6bc94e17812873f39c36c5f815263fa71fb80/generation_config.json HTTP/1.1" 200 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /anas-awadalla/mpt-1b-redpajama-200b/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’èª­ã¿è¾¼ã¿å®Œäº† lang_encoder=MosaicGPT(
  (transformer): ModuleDict(
    (wte): Embedding(50432, 2048)
    (emb_drop): Dropout(p=0, inplace=False)
    (blocks): ModuleList(
      (0-23): 24 x GPTBlock(
        (ln_1): LPLayerNorm((2048,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (Wqkv): Linear(in_features=2048, out_features=6144, bias=False)
          (q_ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
          (k_ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
          (out_proj): Linear(in_features=2048, out_features=2048, bias=False)
        )
        (ln_2): LPLayerNorm((2048,), eps=1e-05, elementwise_affine=True)
        (mlp): GPTMLP(
          (mlp_up): Linear(in_features=2048, out_features=8192, bias=False)
          (mlp_act): GELU(approximate='none')
          (mlp_down): Linear(in_features=8192, out_features=2048, bias=False)
        )
        (resid_attn_dropout): Dropout(p=0, inplace=False)
        (resid_mlp_dropout): Dropout(p=0, inplace=False)
      )
    )
    (ln_f): LPLayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
) lang_encoder.config=MosaicGPTConfig {
  "alibi": true,
  "alibi_bias_max": 8,
  "architectures": [
    "MosaicGPT"
  ],
  "attn_clip_qkv": null,
  "attn_impl": "torch",
  "attn_pdrop": 0,
  "attn_qk_ln": true,
  "attn_uses_sequence_id": false,
  "auto_map": {
    "AutoConfig": "configuration_mosaic_gpt.MosaicGPTConfig",
    "AutoModelForCausalLM": "mosaic_gpt.MosaicGPT"
  },
  "d_model": 2048,
  "dtype": "float32",
  "emb_init_std": null,
  "emb_init_uniform_lim": null,
  "emb_pdrop": 0,
  "embedding_fraction": 1.0,
  "fan_mode": "fan_in",
  "init_device": "cpu",
  "init_div_is_residual": true,
  "init_gain": 0,
  "init_nonlinearity": "relu",
  "init_std": 0.02,
  "logit_scale": null,
  "low_precision_layernorm": true,
  "max_seq_len": 2048,
  "mlp_ratio": 4,
  "model_type": "mosaic_gpt",
  "n_heads": 16,
  "n_layers": 24,
  "no_bias": true,
  "param_init_fn": "kaiming_normal_",
  "prefix_lm": false,
  "resid_pdrop": 0,
  "softmax_scale": null,
  "tokenizer_name": "EleutherAI/gpt-neox-20b",
  "transformers_version": "4.57.1",
  "use_cache": false,
  "verbose": 0,
  "vocab_size": 50432
}

ğŸŸ© MPT EmbeddingFnMixinã‚’é©ç”¨
ğŸŸ© FlamingoLMMixinã‚’é©ç”¨
ğŸŸ© ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å±æ€§åã‚’æ¨æ¸¬ decoder_layers_attr_name='transformer.blocks'
ğŸŸ© ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å±æ€§åã‚’è¨­å®š decoder_layers_attr_name='transformer.blocks'
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®ãƒˆãƒ¼ã‚¯ãƒ³åŸ‹ã‚è¾¼ã¿ã‚’ãƒªã‚µã‚¤ã‚º len(text_tokenizer)=50280
ğŸŸ© Flamingoãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ– eoc_token_id=50277, media_token_id=50278, vis_dim=1024, cross_attn_every_n_layers=1, gradient_checkpointing=False
ğŸŸ© self.lang_dim=2048
ğŸŸ© PerceiverResamplerã‚’åˆæœŸåŒ– dim=1024, depth=6, dim_head=64, heads=8, num_latents=64, max_num_media=None, max_num_frames=None, ff_mult=4
ğŸŸ© PerceiverAttentionã‚’åˆæœŸåŒ– dim=1024, dim_head=64, heads=8
ğŸŸ¦ self.scale=0.125
ğŸŸ¦ inner_dim=512
ğŸŸ© PerceiverAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=1024 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© PerceiverAttentionã‚’åˆæœŸåŒ– dim=1024, dim_head=64, heads=8
ğŸŸ¦ self.scale=0.125
ğŸŸ¦ inner_dim=512
ğŸŸ© PerceiverAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=1024 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© PerceiverAttentionã‚’åˆæœŸåŒ– dim=1024, dim_head=64, heads=8
ğŸŸ¦ self.scale=0.125
ğŸŸ¦ inner_dim=512
ğŸŸ© PerceiverAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=1024 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© PerceiverAttentionã‚’åˆæœŸåŒ– dim=1024, dim_head=64, heads=8
ğŸŸ¦ self.scale=0.125
ğŸŸ¦ inner_dim=512
ğŸŸ© PerceiverAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=1024 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© PerceiverAttentionã‚’åˆæœŸåŒ– dim=1024, dim_head=64, heads=8
ğŸŸ¦ self.scale=0.125
ğŸŸ¦ inner_dim=512
ğŸŸ© PerceiverAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=1024 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© PerceiverAttentionã‚’åˆæœŸåŒ– dim=1024, dim_head=64, heads=8
ğŸŸ¦ self.scale=0.125
ğŸŸ¦ inner_dim=512
ğŸŸ© PerceiverAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=1024 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© PerceiverResamplerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLMMixinã‚’åˆæœŸåŒ– media_token_id=50278, lang_hidden_size=2048, vis_hidden_size=1024, cross_attn_every_n_layers=1, gradient_checkpointing=False
ğŸŸ© GatedCrossAttentionBlockã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True
ğŸŸ© MaskedCrossAttentionã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, only_attend_immediate_media=True
ğŸŸ¦ self.scale=0.125
ğŸŸ© inner_dim=512
ğŸŸ© MaskedCrossAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=2048 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True
ğŸŸ© MaskedCrossAttentionã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, only_attend_immediate_media=True
ğŸŸ¦ self.scale=0.125
ğŸŸ© inner_dim=512
ğŸŸ© MaskedCrossAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=2048 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True
ğŸŸ© MaskedCrossAttentionã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, only_attend_immediate_media=True
ğŸŸ¦ self.scale=0.125
ğŸŸ© inner_dim=512
ğŸŸ© MaskedCrossAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=2048 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True
ğŸŸ© MaskedCrossAttentionã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, only_attend_immediate_media=True
ğŸŸ¦ self.scale=0.125
ğŸŸ© inner_dim=512
ğŸŸ© MaskedCrossAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=2048 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True
ğŸŸ© MaskedCrossAttentionã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, only_attend_immediate_media=True
ğŸŸ¦ self.scale=0.125
ğŸŸ© inner_dim=512
ğŸŸ© MaskedCrossAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=2048 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True
ğŸŸ© MaskedCrossAttentionã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, only_attend_immediate_media=True
ğŸŸ¦ self.scale=0.125
ğŸŸ© inner_dim=512
ğŸŸ© MaskedCrossAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=2048 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True
ğŸŸ© MaskedCrossAttentionã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, only_attend_immediate_media=True
ğŸŸ¦ self.scale=0.125
ğŸŸ© inner_dim=512
ğŸŸ© MaskedCrossAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=2048 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True
ğŸŸ© MaskedCrossAttentionã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, only_attend_immediate_media=True
ğŸŸ¦ self.scale=0.125
ğŸŸ© inner_dim=512
ğŸŸ© MaskedCrossAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=2048 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True
ğŸŸ© MaskedCrossAttentionã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, only_attend_immediate_media=True
ğŸŸ¦ self.scale=0.125
ğŸŸ© inner_dim=512
ğŸŸ© MaskedCrossAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=2048 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True
ğŸŸ© MaskedCrossAttentionã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, only_attend_immediate_media=True
ğŸŸ¦ self.scale=0.125
ğŸŸ© inner_dim=512
ğŸŸ© MaskedCrossAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=2048 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True
ğŸŸ© MaskedCrossAttentionã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, only_attend_immediate_media=True
ğŸŸ¦ self.scale=0.125
ğŸŸ© inner_dim=512
ğŸŸ© MaskedCrossAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=2048 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True
ğŸŸ© MaskedCrossAttentionã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, only_attend_immediate_media=True
ğŸŸ¦ self.scale=0.125
ğŸŸ© inner_dim=512
ğŸŸ© MaskedCrossAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=2048 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True
ğŸŸ© MaskedCrossAttentionã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, only_attend_immediate_media=True
ğŸŸ¦ self.scale=0.125
ğŸŸ© inner_dim=512
ğŸŸ© MaskedCrossAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=2048 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True
ğŸŸ© MaskedCrossAttentionã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, only_attend_immediate_media=True
ğŸŸ¦ self.scale=0.125
ğŸŸ© inner_dim=512
ğŸŸ© MaskedCrossAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=2048 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True
ğŸŸ© MaskedCrossAttentionã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, only_attend_immediate_media=True
ğŸŸ¦ self.scale=0.125
ğŸŸ© inner_dim=512
ğŸŸ© MaskedCrossAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=2048 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True
ğŸŸ© MaskedCrossAttentionã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, only_attend_immediate_media=True
ğŸŸ¦ self.scale=0.125
ğŸŸ© inner_dim=512
ğŸŸ© MaskedCrossAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=2048 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True
ğŸŸ© MaskedCrossAttentionã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, only_attend_immediate_media=True
ğŸŸ¦ self.scale=0.125
ğŸŸ© inner_dim=512
ğŸŸ© MaskedCrossAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=2048 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True
ğŸŸ© MaskedCrossAttentionã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, only_attend_immediate_media=True
ğŸŸ¦ self.scale=0.125
ğŸŸ© inner_dim=512
ğŸŸ© MaskedCrossAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=2048 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True
ğŸŸ© MaskedCrossAttentionã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, only_attend_immediate_media=True
ğŸŸ¦ self.scale=0.125
ğŸŸ© inner_dim=512
ğŸŸ© MaskedCrossAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=2048 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True
ğŸŸ© MaskedCrossAttentionã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, only_attend_immediate_media=True
ğŸŸ¦ self.scale=0.125
ğŸŸ© inner_dim=512
ğŸŸ© MaskedCrossAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=2048 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True
ğŸŸ© MaskedCrossAttentionã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, only_attend_immediate_media=True
ğŸŸ¦ self.scale=0.125
ğŸŸ© inner_dim=512
ğŸŸ© MaskedCrossAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=2048 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True
ğŸŸ© MaskedCrossAttentionã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, only_attend_immediate_media=True
ğŸŸ¦ self.scale=0.125
ğŸŸ© inner_dim=512
ğŸŸ© MaskedCrossAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=2048 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True
ğŸŸ© MaskedCrossAttentionã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, only_attend_immediate_media=True
ğŸŸ¦ self.scale=0.125
ğŸŸ© inner_dim=512
ğŸŸ© MaskedCrossAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=2048 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True
ğŸŸ© MaskedCrossAttentionã‚’åˆæœŸåŒ– dim=2048, dim_visual=1024, dim_head=64, heads=8, only_attend_immediate_media=True
ğŸŸ¦ self.scale=0.125
ğŸŸ© inner_dim=512
ğŸŸ© MaskedCrossAttentionã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ– dim=2048 mult=4
ğŸŸ© ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–å®Œäº†
ğŸŸ© GatedCrossAttentionBlockã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© Flamingoãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLayerã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLayerã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLayerã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLayerã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLayerã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLayerã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLayerã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLayerã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLayerã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLayerã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLayerã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLayerã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLayerã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLayerã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLayerã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLayerã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLayerã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLayerã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLayerã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLayerã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLayerã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLayerã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLayerã‚’åˆæœŸåŒ– gradient_checkpointing=False
ğŸŸ© FlamingoLayerã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© Flamingoãƒ¬ã‚¤ãƒ¤ãƒ¼ã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© FlamingoLMMixinã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© Flamingoãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–å®Œäº†
ğŸŸ© Flamingoãƒ¢ãƒ‡ãƒ«ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 2,559,117,360
ğŸŸ© ãƒ¢ãƒ‡ãƒ«ã®å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ•ãƒªãƒ¼ã‚º
ğŸŸ© Perceiverã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚¢ãƒ³ãƒ•ãƒªãƒ¼ã‚º
ğŸŸ© Gated Cross Attention Layersã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚¢ãƒ³ãƒ•ãƒªãƒ¼ã‚º
ğŸŸ© LM Input Embeddingsã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚¢ãƒ³ãƒ•ãƒªãƒ¼ã‚º
ğŸŸ© è¨“ç·´å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 1,046,992,944
ğŸŸ¦ https://huggingface.co:443 "HEAD /openflamingo/OpenFlamingo-3B-vitl-mpt1b/resolve/main/checkpoint.pt HTTP/1.1" 302 0
ğŸŸ¦ Starting new HTTP connection (1): images.cocodataset.org:80
ğŸŸ¦ http://images.cocodataset.org:80 "GET /val2017/000000039769.jpg HTTP/1.1" 200 173131
ğŸŸ¦ Starting new HTTP connection (1): images.cocodataset.org:80
ğŸŸ¦ http://images.cocodataset.org:80 "GET /test-stuff2017/000000028137.jpg HTTP/1.1" 200 184441
ğŸŸ¦ Starting new HTTP connection (1): images.cocodataset.org:80
ğŸŸ¦ http://images.cocodataset.org:80 "GET /test-stuff2017/000000028352.jpg HTTP/1.1" 200 169658
ğŸŸ© ç”»åƒã‚’å‰å‡¦ç† vision_x[0].shape=torch.Size([1, 3, 224, 224]), vision_x[0].dtype=torch.float32
ğŸŸ© ç”»åƒã‚’çµåˆ vision_x.shape=torch.Size([3, 3, 224, 224]), vision_x.dtype=torch.float32
ğŸŸ© ç”»åƒã‚’ãƒªã‚·ã‚§ã‚¤ãƒ— vision_x.shape=torch.Size([1, 3, 1, 3, 224, 224]), vision_x.dtype=torch.float32
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆã‚’æº–å‚™ text_list=['<image>An image of two cats.<|endofchunk|><image>An image of a bathroom sink.<|endofchunk|><image>An image of']
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆã‚’å‰å‡¦ç† lang_x['input_ids']=tensor([[50278,  1145,  2460,   273,   767, 16581,    15, 50277, 50278,  1145,
          2460,   273,   247, 15336, 16338,    15, 50277, 50278,  1145,  2460,
           273]])
ğŸŸ© Flamingoã®generateé–‹å§‹ vision_x.shape=torch.Size([1, 3, 1, 3, 224, 224]), lang_x.shape=torch.Size([1, 21]), None if attention_mask is None else attention_mask.shape=torch.Size([1, 21]), dict_keys(['max_new_tokens', 'num_beams'])
ğŸŸ¦ repeated vision_x.shape=torch.Size([3, 3, 1, 3, 224, 224]), lang_x.shape=torch.Size([1, 21])
ğŸŸ© ç”Ÿã®ç”»åƒãƒ†ãƒ³ã‚½ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰é–‹å§‹ vision_x.shape=torch.Size([3, 3, 1, 3, 224, 224]), vision_x.dtype=torch.float32
ğŸŸ¦ flatten vision_x.shape=torch.Size([9, 3, 224, 224])
ğŸŸ¦ encoded vision_x.shape=torch.Size([9, 256, 1024]), vision_x.dtype=torch.float32
ğŸŸ¦ unflatten vision_x.shape=torch.Size([3, 3, 1, 256, 1024])
ğŸŸ© PerceiverResamplerã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 3, 1, 256, 1024]), x.dtype=torch.float32
ğŸŸ¦ x.shape=torch.Size([3, 3, 256, 1024])
ğŸŸ¦ latents.shape=torch.Size([3, 3, 64, 1024])
ğŸŸ© PerceiverAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 3, 256, 1024]), x.dtype=torch.float32 latents.shape=torch.Size([3, 3, 64, 1024]), latents.dtype=torch.float32
ğŸŸ¦ q.shape=torch.Size([3, 3, 64, 512])
ğŸŸ¦ kv_input.shape=torch.Size([3, 3, 320, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 3, 320, 512]), v.shape=torch.Size([3, 3, 320, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 3, 64, 64]), k.shape=torch.Size([3, 8, 3, 320, 64]), v.shape=torch.Size([3, 8, 3, 320, 64])
ğŸŸ© PerceiverAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 3, 64, 1024]) out.dtype=torch.float32
ğŸŸ© PerceiverAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 3, 256, 1024]), x.dtype=torch.float32 latents.shape=torch.Size([3, 3, 64, 1024]), latents.dtype=torch.float32
ğŸŸ¦ q.shape=torch.Size([3, 3, 64, 512])
ğŸŸ¦ kv_input.shape=torch.Size([3, 3, 320, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 3, 320, 512]), v.shape=torch.Size([3, 3, 320, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 3, 64, 64]), k.shape=torch.Size([3, 8, 3, 320, 64]), v.shape=torch.Size([3, 8, 3, 320, 64])
ğŸŸ© PerceiverAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 3, 64, 1024]) out.dtype=torch.float32
ğŸŸ© PerceiverAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 3, 256, 1024]), x.dtype=torch.float32 latents.shape=torch.Size([3, 3, 64, 1024]), latents.dtype=torch.float32
ğŸŸ¦ q.shape=torch.Size([3, 3, 64, 512])
ğŸŸ¦ kv_input.shape=torch.Size([3, 3, 320, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 3, 320, 512]), v.shape=torch.Size([3, 3, 320, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 3, 64, 64]), k.shape=torch.Size([3, 8, 3, 320, 64]), v.shape=torch.Size([3, 8, 3, 320, 64])
ğŸŸ© PerceiverAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 3, 64, 1024]) out.dtype=torch.float32
ğŸŸ© PerceiverAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 3, 256, 1024]), x.dtype=torch.float32 latents.shape=torch.Size([3, 3, 64, 1024]), latents.dtype=torch.float32
ğŸŸ¦ q.shape=torch.Size([3, 3, 64, 512])
ğŸŸ¦ kv_input.shape=torch.Size([3, 3, 320, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 3, 320, 512]), v.shape=torch.Size([3, 3, 320, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 3, 64, 64]), k.shape=torch.Size([3, 8, 3, 320, 64]), v.shape=torch.Size([3, 8, 3, 320, 64])
ğŸŸ© PerceiverAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 3, 64, 1024]) out.dtype=torch.float32
ğŸŸ© PerceiverAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 3, 256, 1024]), x.dtype=torch.float32 latents.shape=torch.Size([3, 3, 64, 1024]), latents.dtype=torch.float32
ğŸŸ¦ q.shape=torch.Size([3, 3, 64, 512])
ğŸŸ¦ kv_input.shape=torch.Size([3, 3, 320, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 3, 320, 512]), v.shape=torch.Size([3, 3, 320, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 3, 64, 64]), k.shape=torch.Size([3, 8, 3, 320, 64]), v.shape=torch.Size([3, 8, 3, 320, 64])
ğŸŸ© PerceiverAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 3, 64, 1024]) out.dtype=torch.float32
ğŸŸ© PerceiverAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 3, 256, 1024]), x.dtype=torch.float32 latents.shape=torch.Size([3, 3, 64, 1024]), latents.dtype=torch.float32
ğŸŸ¦ q.shape=torch.Size([3, 3, 64, 512])
ğŸŸ¦ kv_input.shape=torch.Size([3, 3, 320, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 3, 320, 512]), v.shape=torch.Size([3, 3, 320, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 3, 64, 64]), k.shape=torch.Size([3, 8, 3, 320, 64]), v.shape=torch.Size([3, 8, 3, 320, 64])
ğŸŸ© PerceiverAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 3, 64, 1024]) out.dtype=torch.float32
ğŸŸ© PerceiverResamplerã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 3, 64, 1024]) out.dtype=torch.float32
ğŸŸ¦ resampled vision_x.shape=torch.Size([3, 3, 64, 1024]), vision_x.dtype=torch.float32
ğŸŸ© ç”Ÿã®ç”»åƒãƒ†ãƒ³ã‚½ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å®Œäº† vision_x.shape=torch.Size([3, 3, 64, 1024]) vision_x.dtype=torch.float32
ğŸŸ© FlamingoLMMixinã®é †ä¼æ’­é–‹å§‹ input_ids.shape=torch.Size([3, 21]), input_ids.dtype=torch.int64, None if attention_mask is None else attention_mask.shape=torch.Size([3, 21]), dict_keys(['prefix_mask', 'sequence_id', 'past_key_values', 'use_cache', 'return_dict'])
ğŸŸ¦ media_locations.shape=torch.Size([3, 21]), media_locations.dtype=torch.bool
ğŸŸ¦ use_cached_media_locations=False
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ¦ T_txt=21
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 21, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 21, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 21, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 21])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 21, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 21, 64])
ğŸŸ¦ out.shape=torch.Size([3, 21, 512])
ğŸŸ¦ out.shape=torch.Size([3, 21, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 21, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 21, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-2.0925e-01, -5.9118e-02,  6.5251e-02,  ...,  4.1091e-01,
          -3.5243e-01,  3.7260e-01],
         [-1.7433e-02, -1.4965e-01,  3.6832e-02,  ...,  1.0424e-01,
           3.2264e-03,  4.7463e-01],
         [-1.9068e-02, -1.3694e-01, -1.2874e-01,  ...,  1.6081e-01,
          -1.5760e-01,  1.9950e-01],
         ...,
         [ 2.8632e-02, -1.5350e-01,  4.6180e-03,  ...,  7.7684e-02,
           2.8640e-02,  4.4226e-01],
         [ 1.8914e-02, -1.4606e-01, -1.3678e-01,  ...,  1.6836e-01,
          -1.6449e-01,  2.0091e-01],
         [ 2.5405e-02, -1.5146e-01,  3.8443e-02,  ..., -8.5981e-02,
           4.6484e-04,  3.0404e-01]],

        [[-2.0925e-01, -5.9118e-02,  6.5251e-02,  ...,  4.1091e-01,
          -3.5243e-01,  3.7260e-01],
         [-1.7433e-02, -1.4965e-01,  3.6832e-02,  ...,  1.0424e-01,
           3.2264e-03,  4.7463e-01],
         [-1.9068e-02, -1.3694e-01, -1.2874e-01,  ...,  1.6081e-01,
          -1.5760e-01,  1.9950e-01],
         ...,
         [ 2.8632e-02, -1.5350e-01,  4.6179e-03,  ...,  7.7684e-02,
           2.8640e-02,  4.4226e-01],
         [ 1.8914e-02, -1.4606e-01, -1.3678e-01,  ...,  1.6836e-01,
          -1.6449e-01,  2.0091e-01],
         [ 2.5405e-02, -1.5146e-01,  3.8443e-02,  ..., -8.5981e-02,
           4.6483e-04,  3.0404e-01]],

        [[-2.0925e-01, -5.9117e-02,  6.5251e-02,  ...,  4.1091e-01,
          -3.5243e-01,  3.7260e-01],
         [-1.7433e-02, -1.4965e-01,  3.6832e-02,  ...,  1.0424e-01,
           3.2265e-03,  4.7463e-01],
         [-1.9068e-02, -1.3694e-01, -1.2874e-01,  ...,  1.6081e-01,
          -1.5760e-01,  1.9950e-01],
         ...,
         [ 2.8632e-02, -1.5350e-01,  4.6180e-03,  ...,  7.7684e-02,
           2.8640e-02,  4.4226e-01],
         [ 1.8914e-02, -1.4606e-01, -1.3678e-01,  ...,  1.6836e-01,
          -1.6449e-01,  2.0091e-01],
         [ 2.5405e-02, -1.5146e-01,  3.8443e-02,  ..., -8.5981e-02,
           4.6475e-04,  3.0404e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ¦ T_txt=21
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 21, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 21, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 21, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 21])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 21, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 21, 64])
ğŸŸ¦ out.shape=torch.Size([3, 21, 512])
ğŸŸ¦ out.shape=torch.Size([3, 21, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 21, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 21, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-0.0762, -0.3746,  0.1300,  ...,  0.1017, -0.0332,  0.2191],
         [-0.0236, -0.1139, -0.0499,  ...,  0.0464,  0.0973,  0.4798],
         [ 0.0476, -0.1903,  0.0666,  ..., -0.0123, -0.0800,  0.3086],
         ...,
         [ 0.0722, -0.0607, -0.0632,  ...,  0.0137,  0.1349,  0.5097],
         [ 0.1003, -0.1236,  0.0705,  ..., -0.0096, -0.0471,  0.3702],
         [ 0.0278, -0.1336, -0.0075,  ..., -0.1681, -0.0534,  0.5033]],

        [[-0.0762, -0.3746,  0.1300,  ...,  0.1017, -0.0332,  0.2191],
         [-0.0236, -0.1139, -0.0499,  ...,  0.0464,  0.0973,  0.4798],
         [ 0.0476, -0.1903,  0.0666,  ..., -0.0123, -0.0800,  0.3086],
         ...,
         [ 0.0722, -0.0607, -0.0632,  ...,  0.0137,  0.1349,  0.5097],
         [ 0.1003, -0.1236,  0.0705,  ..., -0.0096, -0.0471,  0.3702],
         [ 0.0278, -0.1336, -0.0075,  ..., -0.1681, -0.0534,  0.5033]],

        [[-0.0762, -0.3746,  0.1300,  ...,  0.1017, -0.0332,  0.2191],
         [-0.0236, -0.1139, -0.0499,  ...,  0.0464,  0.0973,  0.4798],
         [ 0.0476, -0.1903,  0.0666,  ..., -0.0123, -0.0800,  0.3086],
         ...,
         [ 0.0722, -0.0607, -0.0632,  ...,  0.0137,  0.1349,  0.5097],
         [ 0.1003, -0.1236,  0.0705,  ..., -0.0096, -0.0471,  0.3702],
         [ 0.0278, -0.1336, -0.0075,  ..., -0.1681, -0.0534,  0.5033]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ¦ T_txt=21
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 21, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 21, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 21, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 21])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 21, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 21, 64])
ğŸŸ¦ out.shape=torch.Size([3, 21, 512])
ğŸŸ¦ out.shape=torch.Size([3, 21, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 21, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 21, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-0.0423, -0.4800,  0.0985,  ..., -0.1247,  0.1871, -0.2268],
         [-0.0501, -0.1131, -0.1332,  ...,  0.1946,  0.1566,  0.3318],
         [-0.0369, -0.1714,  0.2051,  ...,  0.1376, -0.1982,  0.2490],
         ...,
         [-0.0166, -0.0496, -0.0412,  ...,  0.0990,  0.2447,  0.4206],
         [-0.0399, -0.2604,  0.3385,  ...,  0.0974, -0.1178,  0.1742],
         [-0.0864, -0.1342,  0.0755,  ..., -0.1099, -0.0017,  0.3514]],

        [[-0.0423, -0.4800,  0.0985,  ..., -0.1247,  0.1871, -0.2268],
         [-0.0501, -0.1131, -0.1332,  ...,  0.1946,  0.1566,  0.3318],
         [-0.0369, -0.1714,  0.2051,  ...,  0.1376, -0.1982,  0.2490],
         ...,
         [-0.0166, -0.0496, -0.0412,  ...,  0.0990,  0.2447,  0.4206],
         [-0.0399, -0.2604,  0.3385,  ...,  0.0974, -0.1178,  0.1742],
         [-0.0864, -0.1342,  0.0755,  ..., -0.1099, -0.0017,  0.3514]],

        [[-0.0423, -0.4800,  0.0985,  ..., -0.1247,  0.1871, -0.2268],
         [-0.0501, -0.1131, -0.1332,  ...,  0.1946,  0.1566,  0.3318],
         [-0.0369, -0.1714,  0.2051,  ...,  0.1376, -0.1982,  0.2490],
         ...,
         [-0.0166, -0.0496, -0.0412,  ...,  0.0990,  0.2447,  0.4206],
         [-0.0399, -0.2604,  0.3385,  ...,  0.0974, -0.1178,  0.1742],
         [-0.0864, -0.1342,  0.0755,  ..., -0.1099, -0.0017,  0.3514]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ¦ T_txt=21
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 21, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 21, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 21, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 21])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 21, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 21, 64])
ğŸŸ¦ out.shape=torch.Size([3, 21, 512])
ğŸŸ¦ out.shape=torch.Size([3, 21, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 21, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 21, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-0.6808, -0.0752, -0.2681,  ..., -0.1388, -0.2275, -0.2143],
         [-0.2353, -0.1768, -0.1707,  ...,  0.0178,  0.0832,  0.2217],
         [ 0.1139, -0.0718,  0.1118,  ...,  0.0826, -0.0978,  0.2029],
         ...,
         [-0.1567, -0.0215,  0.0189,  ...,  0.0527,  0.2387,  0.2889],
         [ 0.0286, -0.0663,  0.1672,  ..., -0.0161, -0.0736,  0.1485],
         [ 0.0567,  0.0876,  0.0517,  ...,  0.0078, -0.1083,  0.5091]],

        [[-0.6808, -0.0752, -0.2681,  ..., -0.1388, -0.2275, -0.2143],
         [-0.2353, -0.1768, -0.1707,  ...,  0.0178,  0.0832,  0.2217],
         [ 0.1139, -0.0718,  0.1118,  ...,  0.0826, -0.0978,  0.2029],
         ...,
         [-0.1567, -0.0215,  0.0189,  ...,  0.0527,  0.2387,  0.2889],
         [ 0.0286, -0.0663,  0.1672,  ..., -0.0161, -0.0736,  0.1485],
         [ 0.0567,  0.0876,  0.0517,  ...,  0.0078, -0.1083,  0.5091]],

        [[-0.6808, -0.0752, -0.2681,  ..., -0.1388, -0.2275, -0.2143],
         [-0.2353, -0.1768, -0.1707,  ...,  0.0178,  0.0832,  0.2217],
         [ 0.1139, -0.0718,  0.1118,  ...,  0.0826, -0.0978,  0.2029],
         ...,
         [-0.1567, -0.0215,  0.0189,  ...,  0.0527,  0.2387,  0.2889],
         [ 0.0286, -0.0663,  0.1672,  ..., -0.0161, -0.0736,  0.1485],
         [ 0.0567,  0.0876,  0.0517,  ...,  0.0078, -0.1083,  0.5091]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ¦ T_txt=21
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 21, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 21, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 21, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 21])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 21, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 21, 64])
ğŸŸ¦ out.shape=torch.Size([3, 21, 512])
ğŸŸ¦ out.shape=torch.Size([3, 21, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 21, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 21, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.0310e+00,  7.9414e-01, -1.4750e+00,  ...,  3.6145e-01,
           1.5208e+00, -2.4390e-01],
         [-5.7247e-01, -9.2225e-02, -2.4184e-01,  ...,  5.1393e-02,
           3.1086e-02,  2.4566e-01],
         [ 6.8573e-02, -5.9338e-02,  1.0359e-01,  ...,  5.0657e-02,
           1.8189e-01,  4.9062e-02],
         ...,
         [-3.8292e-01,  7.6682e-02, -1.3805e-01,  ...,  1.0520e-01,
           1.9327e-01,  4.3492e-01],
         [ 3.8942e-02,  6.5045e-03,  5.5976e-02,  ..., -3.1300e-02,
           2.4623e-02,  1.2090e-02],
         [ 5.8649e-04,  7.3301e-02, -2.1840e-01,  ...,  5.6920e-02,
           5.3535e-02,  3.7094e-01]],

        [[-4.0310e+00,  7.9414e-01, -1.4750e+00,  ...,  3.6145e-01,
           1.5208e+00, -2.4390e-01],
         [-5.7247e-01, -9.2225e-02, -2.4184e-01,  ...,  5.1393e-02,
           3.1086e-02,  2.4566e-01],
         [ 6.8573e-02, -5.9338e-02,  1.0359e-01,  ...,  5.0657e-02,
           1.8189e-01,  4.9062e-02],
         ...,
         [-3.8292e-01,  7.6682e-02, -1.3805e-01,  ...,  1.0520e-01,
           1.9327e-01,  4.3492e-01],
         [ 3.8942e-02,  6.5043e-03,  5.5976e-02,  ..., -3.1300e-02,
           2.4623e-02,  1.2090e-02],
         [ 5.8647e-04,  7.3301e-02, -2.1840e-01,  ...,  5.6920e-02,
           5.3535e-02,  3.7094e-01]],

        [[-4.0310e+00,  7.9414e-01, -1.4750e+00,  ...,  3.6145e-01,
           1.5208e+00, -2.4390e-01],
         [-5.7247e-01, -9.2225e-02, -2.4184e-01,  ...,  5.1394e-02,
           3.1086e-02,  2.4566e-01],
         [ 6.8573e-02, -5.9338e-02,  1.0359e-01,  ...,  5.0657e-02,
           1.8189e-01,  4.9063e-02],
         ...,
         [-3.8292e-01,  7.6682e-02, -1.3805e-01,  ...,  1.0520e-01,
           1.9327e-01,  4.3492e-01],
         [ 3.8942e-02,  6.5047e-03,  5.5976e-02,  ..., -3.1300e-02,
           2.4623e-02,  1.2090e-02],
         [ 5.8622e-04,  7.3301e-02, -2.1840e-01,  ...,  5.6920e-02,
           5.3535e-02,  3.7094e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ¦ T_txt=21
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 21, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 21, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 21, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 21])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 21, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 21, 64])
ğŸŸ¦ out.shape=torch.Size([3, 21, 512])
ğŸŸ¦ out.shape=torch.Size([3, 21, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 21, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 21, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.7946e+00,  9.0221e-01, -1.2882e+00,  ...,  1.1832e+00,
           2.5226e+00, -5.9823e-02],
         [-5.6193e-01, -1.5785e-01, -2.8558e-01,  ..., -3.8618e-02,
          -1.3092e-02,  1.2509e-01],
         [ 4.1303e-03, -1.2649e-01, -2.6289e-01,  ...,  2.2804e-01,
          -9.2656e-02,  5.5099e-03],
         ...,
         [-6.4434e-01,  9.1292e-02, -5.1098e-02,  ...,  1.1851e-01,
           6.0202e-02,  5.1087e-01],
         [-1.9361e-01,  1.8242e-01, -1.8671e-01,  ...,  1.9924e-01,
          -2.6155e-01,  1.1251e-01],
         [-4.1566e-01,  2.0328e-01, -1.5304e-01,  ...,  7.1610e-02,
           2.6326e-02,  3.2153e-01]],

        [[-4.7946e+00,  9.0221e-01, -1.2882e+00,  ...,  1.1832e+00,
           2.5226e+00, -5.9823e-02],
         [-5.6193e-01, -1.5785e-01, -2.8558e-01,  ..., -3.8618e-02,
          -1.3092e-02,  1.2509e-01],
         [ 4.1303e-03, -1.2649e-01, -2.6289e-01,  ...,  2.2804e-01,
          -9.2656e-02,  5.5099e-03],
         ...,
         [-6.4434e-01,  9.1292e-02, -5.1098e-02,  ...,  1.1851e-01,
           6.0202e-02,  5.1087e-01],
         [-1.9361e-01,  1.8242e-01, -1.8671e-01,  ...,  1.9924e-01,
          -2.6155e-01,  1.1251e-01],
         [-4.1566e-01,  2.0328e-01, -1.5304e-01,  ...,  7.1609e-02,
           2.6325e-02,  3.2153e-01]],

        [[-4.7946e+00,  9.0221e-01, -1.2882e+00,  ...,  1.1832e+00,
           2.5226e+00, -5.9824e-02],
         [-5.6193e-01, -1.5785e-01, -2.8558e-01,  ..., -3.8618e-02,
          -1.3092e-02,  1.2509e-01],
         [ 4.1305e-03, -1.2649e-01, -2.6289e-01,  ...,  2.2804e-01,
          -9.2657e-02,  5.5101e-03],
         ...,
         [-6.4434e-01,  9.1292e-02, -5.1097e-02,  ...,  1.1851e-01,
           6.0202e-02,  5.1087e-01],
         [-1.9361e-01,  1.8242e-01, -1.8671e-01,  ...,  1.9924e-01,
          -2.6155e-01,  1.1251e-01],
         [-4.1566e-01,  2.0328e-01, -1.5304e-01,  ...,  7.1610e-02,
           2.6326e-02,  3.2153e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ¦ T_txt=21
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 21, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 21, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 21, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 21])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 21, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 21, 64])
ğŸŸ¦ out.shape=torch.Size([3, 21, 512])
ğŸŸ¦ out.shape=torch.Size([3, 21, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 21, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 21, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.2771e+00,  1.3169e+00, -1.5839e+00,  ...,  1.5235e+00,
           2.5618e+00,  3.0273e-01],
         [-5.1019e-01, -2.0753e-01, -3.9353e-01,  ..., -3.0973e-02,
           3.3680e-01,  1.5358e-01],
         [ 9.6702e-02, -5.6518e-01, -1.5635e-01,  ...,  8.8999e-03,
           7.6486e-02, -5.2476e-03],
         ...,
         [-4.2772e-01,  6.0314e-02, -2.1200e-01,  ...,  7.8294e-02,
           3.8151e-01,  4.8335e-01],
         [ 1.3968e-01, -2.8755e-01,  1.2602e-01,  ..., -5.6688e-02,
           1.7580e-02,  3.1946e-03],
         [-2.2878e-01,  2.1636e-01, -6.4803e-03,  ...,  9.7471e-02,
           1.7168e-01,  1.4387e-01]],

        [[-5.2771e+00,  1.3169e+00, -1.5839e+00,  ...,  1.5235e+00,
           2.5618e+00,  3.0273e-01],
         [-5.1019e-01, -2.0753e-01, -3.9353e-01,  ..., -3.0973e-02,
           3.3680e-01,  1.5358e-01],
         [ 9.6702e-02, -5.6518e-01, -1.5635e-01,  ...,  8.8999e-03,
           7.6486e-02, -5.2476e-03],
         ...,
         [-4.2772e-01,  6.0314e-02, -2.1200e-01,  ...,  7.8293e-02,
           3.8151e-01,  4.8335e-01],
         [ 1.3968e-01, -2.8755e-01,  1.2602e-01,  ..., -5.6688e-02,
           1.7580e-02,  3.1942e-03],
         [-2.2878e-01,  2.1636e-01, -6.4799e-03,  ...,  9.7471e-02,
           1.7168e-01,  1.4387e-01]],

        [[-5.2771e+00,  1.3169e+00, -1.5839e+00,  ...,  1.5235e+00,
           2.5618e+00,  3.0273e-01],
         [-5.1019e-01, -2.0753e-01, -3.9353e-01,  ..., -3.0973e-02,
           3.3680e-01,  1.5358e-01],
         [ 9.6702e-02, -5.6518e-01, -1.5635e-01,  ...,  8.8995e-03,
           7.6486e-02, -5.2473e-03],
         ...,
         [-4.2772e-01,  6.0314e-02, -2.1200e-01,  ...,  7.8293e-02,
           3.8151e-01,  4.8335e-01],
         [ 1.3968e-01, -2.8755e-01,  1.2602e-01,  ..., -5.6688e-02,
           1.7580e-02,  3.1946e-03],
         [-2.2878e-01,  2.1636e-01, -6.4800e-03,  ...,  9.7471e-02,
           1.7168e-01,  1.4387e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ¦ T_txt=21
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 21, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 21, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 21, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 21])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 21, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 21, 64])
ğŸŸ¦ out.shape=torch.Size([3, 21, 512])
ğŸŸ¦ out.shape=torch.Size([3, 21, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 21, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 21, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.3925e+00,  1.2785e+00, -1.7428e+00,  ...,  1.6187e+00,
           2.6666e+00,  6.3102e-01],
         [-7.2190e-01, -9.0366e-02, -3.7054e-01,  ..., -4.8731e-02,
           5.0303e-02,  4.0432e-02],
         [ 3.2142e-02, -5.6480e-01, -2.0480e-01,  ...,  6.2426e-02,
          -1.1226e-01,  5.0910e-03],
         ...,
         [-6.1080e-01,  7.6897e-02, -2.1292e-01,  ...,  1.2086e-01,
           5.0522e-02,  5.6541e-01],
         [ 1.7065e-01, -8.8157e-02,  7.1555e-02,  ...,  5.6628e-02,
          -2.0010e-01, -3.2694e-02],
         [-4.7935e-01,  1.4615e-01, -1.9178e-01,  ...,  1.2073e-01,
          -1.3311e-01,  8.5742e-02]],

        [[-5.3925e+00,  1.2785e+00, -1.7428e+00,  ...,  1.6187e+00,
           2.6666e+00,  6.3102e-01],
         [-7.2190e-01, -9.0366e-02, -3.7054e-01,  ..., -4.8731e-02,
           5.0303e-02,  4.0432e-02],
         [ 3.2142e-02, -5.6480e-01, -2.0480e-01,  ...,  6.2426e-02,
          -1.1226e-01,  5.0910e-03],
         ...,
         [-6.1080e-01,  7.6896e-02, -2.1292e-01,  ...,  1.2086e-01,
           5.0522e-02,  5.6541e-01],
         [ 1.7065e-01, -8.8157e-02,  7.1555e-02,  ...,  5.6628e-02,
          -2.0010e-01, -3.2694e-02],
         [-4.7935e-01,  1.4615e-01, -1.9178e-01,  ...,  1.2073e-01,
          -1.3311e-01,  8.5742e-02]],

        [[-5.3925e+00,  1.2785e+00, -1.7428e+00,  ...,  1.6187e+00,
           2.6666e+00,  6.3102e-01],
         [-7.2190e-01, -9.0366e-02, -3.7054e-01,  ..., -4.8731e-02,
           5.0304e-02,  4.0432e-02],
         [ 3.2142e-02, -5.6480e-01, -2.0480e-01,  ...,  6.2426e-02,
          -1.1226e-01,  5.0909e-03],
         ...,
         [-6.1080e-01,  7.6897e-02, -2.1292e-01,  ...,  1.2086e-01,
           5.0522e-02,  5.6541e-01],
         [ 1.7065e-01, -8.8157e-02,  7.1555e-02,  ...,  5.6627e-02,
          -2.0010e-01, -3.2694e-02],
         [-4.7935e-01,  1.4615e-01, -1.9178e-01,  ...,  1.2073e-01,
          -1.3311e-01,  8.5742e-02]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ¦ T_txt=21
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 21, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 21, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 21, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 21])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 21, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 21, 64])
ğŸŸ¦ out.shape=torch.Size([3, 21, 512])
ğŸŸ¦ out.shape=torch.Size([3, 21, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 21, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 21, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.7653,  1.1008, -1.8155,  ...,  2.3020,  2.1681,  1.0300],
         [-0.6620, -0.0777, -0.5133,  ..., -0.2264,  0.1684, -0.0159],
         [ 0.0287, -0.6121, -0.4236,  ..., -0.2224,  0.0996,  0.0129],
         ...,
         [-0.5000,  0.0593, -0.3372,  ..., -0.2333,  0.0534,  0.2287],
         [ 0.2910, -0.3232, -0.0891,  ..., -0.2288,  0.0756, -0.3264],
         [-0.2309,  0.0085, -0.2722,  ..., -0.1629,  0.2583, -0.0625]],

        [[-5.7653,  1.1008, -1.8155,  ...,  2.3020,  2.1681,  1.0300],
         [-0.6620, -0.0777, -0.5133,  ..., -0.2264,  0.1684, -0.0159],
         [ 0.0287, -0.6121, -0.4236,  ..., -0.2224,  0.0996,  0.0129],
         ...,
         [-0.5000,  0.0593, -0.3372,  ..., -0.2333,  0.0534,  0.2287],
         [ 0.2910, -0.3232, -0.0891,  ..., -0.2288,  0.0756, -0.3264],
         [-0.2309,  0.0085, -0.2722,  ..., -0.1629,  0.2583, -0.0625]],

        [[-5.7653,  1.1008, -1.8155,  ...,  2.3020,  2.1681,  1.0300],
         [-0.6620, -0.0777, -0.5133,  ..., -0.2264,  0.1684, -0.0159],
         [ 0.0287, -0.6121, -0.4236,  ..., -0.2224,  0.0996,  0.0129],
         ...,
         [-0.5000,  0.0593, -0.3372,  ..., -0.2333,  0.0534,  0.2287],
         [ 0.2910, -0.3232, -0.0891,  ..., -0.2288,  0.0756, -0.3264],
         [-0.2309,  0.0085, -0.2722,  ..., -0.1629,  0.2583, -0.0625]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ¦ T_txt=21
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 21, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 21, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 21, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 21])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 21, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 21, 64])
ğŸŸ¦ out.shape=torch.Size([3, 21, 512])
ğŸŸ¦ out.shape=torch.Size([3, 21, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 21, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 21, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.8693,  0.9375, -1.8379,  ...,  2.4698,  2.0660,  1.2787],
         [-0.6894,  0.2462, -0.4958,  ..., -0.2522,  0.1503,  0.0796],
         [ 0.1173, -0.2899, -0.5417,  ..., -0.1367,  0.0710,  0.1026],
         ...,
         [-0.4590, -0.0736, -0.3668,  ..., -0.1384,  0.2711,  0.5534],
         [ 0.5661, -0.2151, -0.3742,  ..., -0.2024,  0.2790, -0.0597],
         [-0.0958, -0.1788, -0.4582,  ..., -0.1067,  0.3161,  0.3464]],

        [[-5.8693,  0.9375, -1.8379,  ...,  2.4698,  2.0660,  1.2787],
         [-0.6894,  0.2462, -0.4958,  ..., -0.2522,  0.1503,  0.0796],
         [ 0.1173, -0.2899, -0.5417,  ..., -0.1367,  0.0710,  0.1026],
         ...,
         [-0.4590, -0.0736, -0.3668,  ..., -0.1384,  0.2711,  0.5534],
         [ 0.5661, -0.2151, -0.3742,  ..., -0.2024,  0.2790, -0.0597],
         [-0.0958, -0.1788, -0.4582,  ..., -0.1067,  0.3161,  0.3464]],

        [[-5.8693,  0.9375, -1.8379,  ...,  2.4698,  2.0660,  1.2787],
         [-0.6894,  0.2462, -0.4958,  ..., -0.2522,  0.1503,  0.0796],
         [ 0.1173, -0.2899, -0.5417,  ..., -0.1367,  0.0710,  0.1026],
         ...,
         [-0.4590, -0.0736, -0.3668,  ..., -0.1384,  0.2711,  0.5534],
         [ 0.5661, -0.2151, -0.3742,  ..., -0.2024,  0.2790, -0.0597],
         [-0.0958, -0.1788, -0.4582,  ..., -0.1067,  0.3161,  0.3464]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ¦ T_txt=21
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 21, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 21, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 21, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 21])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 21, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 21, 64])
ğŸŸ¦ out.shape=torch.Size([3, 21, 512])
ğŸŸ¦ out.shape=torch.Size([3, 21, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 21, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 21, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.6016,  1.2408, -1.6460,  ...,  3.1029,  2.1120,  1.1936],
         [-0.5132,  0.1307, -0.5725,  ..., -0.0805,  0.0303, -0.1367],
         [ 0.2105, -0.6863, -0.6633,  ...,  0.2212,  0.3595,  0.2320],
         ...,
         [-0.4000, -0.1674, -0.2648,  ...,  0.0422,  0.0093,  0.2720],
         [ 0.2628, -0.2662, -0.4232,  ..., -0.0868,  0.1921, -0.0403],
         [-0.1682, -0.4626, -0.5883,  ..., -0.0632,  0.1946,  0.1242]],

        [[-5.6016,  1.2408, -1.6460,  ...,  3.1029,  2.1120,  1.1936],
         [-0.5132,  0.1307, -0.5725,  ..., -0.0805,  0.0303, -0.1367],
         [ 0.2105, -0.6863, -0.6633,  ...,  0.2212,  0.3595,  0.2320],
         ...,
         [-0.4000, -0.1674, -0.2648,  ...,  0.0422,  0.0093,  0.2720],
         [ 0.2628, -0.2662, -0.4232,  ..., -0.0868,  0.1921, -0.0403],
         [-0.1682, -0.4626, -0.5883,  ..., -0.0632,  0.1946,  0.1242]],

        [[-5.6016,  1.2408, -1.6460,  ...,  3.1029,  2.1120,  1.1936],
         [-0.5132,  0.1307, -0.5725,  ..., -0.0805,  0.0303, -0.1367],
         [ 0.2105, -0.6863, -0.6633,  ...,  0.2212,  0.3595,  0.2320],
         ...,
         [-0.4000, -0.1674, -0.2648,  ...,  0.0422,  0.0093,  0.2720],
         [ 0.2628, -0.2662, -0.4232,  ..., -0.0868,  0.1921, -0.0403],
         [-0.1682, -0.4626, -0.5883,  ..., -0.0632,  0.1946,  0.1242]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ¦ T_txt=21
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 21, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 21, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 21, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 21])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 21, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 21, 64])
ğŸŸ¦ out.shape=torch.Size([3, 21, 512])
ğŸŸ¦ out.shape=torch.Size([3, 21, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 21, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 21, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.5722,  1.3828, -1.6196,  ...,  3.5095,  2.5083,  1.2801],
         [-0.7604,  0.1403, -0.7794,  ...,  0.1032,  0.1174, -0.2312],
         [-0.0521, -0.3372, -0.8223,  ...,  0.0621,  0.1464,  0.1382],
         ...,
         [-0.2864, -0.3451, -0.3638,  ..., -0.2696, -0.1493,  0.2436],
         [ 0.3477, -0.1342, -0.2301,  ..., -0.4374, -0.3828, -0.2864],
         [-0.3934, -0.2799, -0.2061,  ..., -0.4735,  0.0483,  0.0476]],

        [[-5.5722,  1.3828, -1.6196,  ...,  3.5095,  2.5083,  1.2801],
         [-0.7604,  0.1403, -0.7794,  ...,  0.1032,  0.1174, -0.2312],
         [-0.0521, -0.3372, -0.8223,  ...,  0.0621,  0.1464,  0.1382],
         ...,
         [-0.2864, -0.3451, -0.3638,  ..., -0.2696, -0.1493,  0.2436],
         [ 0.3477, -0.1342, -0.2301,  ..., -0.4374, -0.3828, -0.2864],
         [-0.3934, -0.2799, -0.2061,  ..., -0.4735,  0.0483,  0.0476]],

        [[-5.5722,  1.3828, -1.6196,  ...,  3.5095,  2.5083,  1.2801],
         [-0.7604,  0.1403, -0.7794,  ...,  0.1032,  0.1174, -0.2312],
         [-0.0521, -0.3372, -0.8223,  ...,  0.0621,  0.1464,  0.1382],
         ...,
         [-0.2864, -0.3451, -0.3638,  ..., -0.2696, -0.1493,  0.2436],
         [ 0.3477, -0.1342, -0.2301,  ..., -0.4374, -0.3828, -0.2864],
         [-0.3934, -0.2799, -0.2061,  ..., -0.4735,  0.0483,  0.0476]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ¦ T_txt=21
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 21, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 21, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 21, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 21])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 21, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 21, 64])
ğŸŸ¦ out.shape=torch.Size([3, 21, 512])
ğŸŸ¦ out.shape=torch.Size([3, 21, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 21, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 21, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.6640e+00,  1.4165e+00, -1.7391e+00,  ...,  3.7237e+00,
           2.6647e+00,  1.4654e+00],
         [-6.0783e-01, -2.5051e-02, -1.0078e+00,  ...,  2.4022e-02,
          -3.9409e-02, -4.4003e-01],
         [-2.3939e-01, -7.4469e-01, -9.9975e-01,  ..., -1.7663e-01,
           9.6495e-02,  5.5717e-02],
         ...,
         [-3.9332e-01, -5.2636e-01, -2.2768e-01,  ..., -6.2002e-02,
          -6.4868e-02,  1.8349e-01],
         [-7.0807e-02, -4.1917e-01, -5.5701e-02,  ..., -2.1743e-01,
          -1.3310e-01, -4.2003e-01],
         [-3.9262e-01, -3.0471e-01, -1.6317e-03,  ..., -1.2015e-01,
           1.6517e-01, -7.2140e-02]],

        [[-5.6640e+00,  1.4165e+00, -1.7391e+00,  ...,  3.7237e+00,
           2.6647e+00,  1.4654e+00],
         [-6.0783e-01, -2.5051e-02, -1.0078e+00,  ...,  2.4022e-02,
          -3.9409e-02, -4.4003e-01],
         [-2.3939e-01, -7.4469e-01, -9.9975e-01,  ..., -1.7663e-01,
           9.6495e-02,  5.5717e-02],
         ...,
         [-3.9332e-01, -5.2636e-01, -2.2768e-01,  ..., -6.2002e-02,
          -6.4868e-02,  1.8349e-01],
         [-7.0807e-02, -4.1917e-01, -5.5701e-02,  ..., -2.1743e-01,
          -1.3310e-01, -4.2003e-01],
         [-3.9262e-01, -3.0471e-01, -1.6316e-03,  ..., -1.2015e-01,
           1.6517e-01, -7.2140e-02]],

        [[-5.6640e+00,  1.4165e+00, -1.7391e+00,  ...,  3.7237e+00,
           2.6647e+00,  1.4654e+00],
         [-6.0783e-01, -2.5051e-02, -1.0078e+00,  ...,  2.4022e-02,
          -3.9409e-02, -4.4003e-01],
         [-2.3939e-01, -7.4469e-01, -9.9975e-01,  ..., -1.7663e-01,
           9.6496e-02,  5.5718e-02],
         ...,
         [-3.9332e-01, -5.2636e-01, -2.2768e-01,  ..., -6.2002e-02,
          -6.4867e-02,  1.8349e-01],
         [-7.0807e-02, -4.1917e-01, -5.5700e-02,  ..., -2.1743e-01,
          -1.3310e-01, -4.2003e-01],
         [-3.9262e-01, -3.0471e-01, -1.6309e-03,  ..., -1.2016e-01,
           1.6517e-01, -7.2139e-02]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ¦ T_txt=21
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 21, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 21, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 21, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 21])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 21, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 21, 64])
ğŸŸ¦ out.shape=torch.Size([3, 21, 512])
ğŸŸ¦ out.shape=torch.Size([3, 21, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 21, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 21, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.3878,  1.2637, -1.3476,  ...,  3.9388,  2.7129,  1.6259],
         [-0.6773,  0.0069, -0.7329,  ...,  0.2023,  0.1743, -0.1756],
         [-0.3587, -0.5944, -1.0050,  ...,  0.2275,  0.4650,  0.1995],
         ...,
         [-0.6247, -0.7543, -0.3405,  ...,  0.1096,  0.2421,  0.5044],
         [-0.1259, -0.3586,  0.2386,  ..., -0.0128,  0.2053, -0.4407],
         [-0.3912, -0.3264,  0.2907,  ..., -0.3382,  0.2944,  0.1950]],

        [[-5.3878,  1.2637, -1.3476,  ...,  3.9388,  2.7129,  1.6259],
         [-0.6773,  0.0069, -0.7329,  ...,  0.2023,  0.1743, -0.1756],
         [-0.3587, -0.5944, -1.0050,  ...,  0.2275,  0.4650,  0.1995],
         ...,
         [-0.6247, -0.7543, -0.3405,  ...,  0.1096,  0.2421,  0.5044],
         [-0.1259, -0.3586,  0.2386,  ..., -0.0128,  0.2053, -0.4407],
         [-0.3912, -0.3264,  0.2907,  ..., -0.3382,  0.2944,  0.1950]],

        [[-5.3878,  1.2637, -1.3476,  ...,  3.9388,  2.7129,  1.6259],
         [-0.6773,  0.0069, -0.7329,  ...,  0.2023,  0.1743, -0.1756],
         [-0.3587, -0.5944, -1.0050,  ...,  0.2275,  0.4650,  0.1995],
         ...,
         [-0.6247, -0.7543, -0.3405,  ...,  0.1096,  0.2421,  0.5044],
         [-0.1259, -0.3586,  0.2386,  ..., -0.0128,  0.2053, -0.4407],
         [-0.3912, -0.3264,  0.2907,  ..., -0.3382,  0.2944,  0.1950]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ¦ T_txt=21
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 21, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 21, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 21, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 21])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 21, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 21, 64])
ğŸŸ¦ out.shape=torch.Size([3, 21, 512])
ğŸŸ¦ out.shape=torch.Size([3, 21, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 21, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 21, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.0959,  0.8567, -1.2666,  ...,  3.8593,  2.8167,  1.9328],
         [-0.9069, -0.3564, -0.8761,  ...,  0.1384,  0.2888, -0.1783],
         [-0.2450, -0.8774, -1.2020,  ...,  0.3088,  0.3829,  0.2829],
         ...,
         [-0.5242, -0.9904, -0.2355,  ...,  0.0950,  0.3671,  0.3994],
         [ 0.0167, -0.7679,  0.0568,  ...,  0.0863,  0.2424, -0.5152],
         [-0.4925, -0.3971,  0.1859,  ..., -0.0988,  0.3347,  0.3610]],

        [[-5.0959,  0.8567, -1.2666,  ...,  3.8593,  2.8167,  1.9328],
         [-0.9069, -0.3564, -0.8761,  ...,  0.1384,  0.2888, -0.1783],
         [-0.2450, -0.8774, -1.2020,  ...,  0.3088,  0.3829,  0.2829],
         ...,
         [-0.5242, -0.9904, -0.2355,  ...,  0.0950,  0.3671,  0.3994],
         [ 0.0167, -0.7679,  0.0568,  ...,  0.0863,  0.2424, -0.5152],
         [-0.4925, -0.3971,  0.1859,  ..., -0.0988,  0.3347,  0.3610]],

        [[-5.0959,  0.8567, -1.2666,  ...,  3.8593,  2.8167,  1.9328],
         [-0.9069, -0.3564, -0.8761,  ...,  0.1384,  0.2888, -0.1783],
         [-0.2450, -0.8774, -1.2020,  ...,  0.3088,  0.3829,  0.2829],
         ...,
         [-0.5242, -0.9904, -0.2355,  ...,  0.0950,  0.3671,  0.3994],
         [ 0.0167, -0.7679,  0.0568,  ...,  0.0863,  0.2424, -0.5152],
         [-0.4925, -0.3971,  0.1859,  ..., -0.0988,  0.3347,  0.3610]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ¦ T_txt=21
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 21, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 21, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 21, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 21])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 21, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 21, 64])
ğŸŸ¦ out.shape=torch.Size([3, 21, 512])
ğŸŸ¦ out.shape=torch.Size([3, 21, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 21, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 21, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.8058,  0.7302, -1.0989,  ...,  3.8324,  2.7810,  1.7821],
         [-0.7038, -0.6393, -0.6297,  ..., -0.0359,  0.1719, -0.3344],
         [-0.1649, -0.7010, -0.9241,  ...,  0.5318,  0.1623, -0.1670],
         ...,
         [-0.6433, -1.0455, -0.2708,  ..., -0.2748,  0.4827,  0.4143],
         [-0.1391, -0.8753,  0.2839,  ...,  0.3533,  0.0579, -0.6393],
         [-0.6376, -0.3177, -0.2238,  ..., -0.7059,  0.4351,  0.1451]],

        [[-4.8058,  0.7302, -1.0989,  ...,  3.8324,  2.7810,  1.7821],
         [-0.7038, -0.6393, -0.6297,  ..., -0.0359,  0.1719, -0.3344],
         [-0.1649, -0.7010, -0.9241,  ...,  0.5318,  0.1623, -0.1670],
         ...,
         [-0.6433, -1.0455, -0.2708,  ..., -0.2748,  0.4827,  0.4143],
         [-0.1391, -0.8753,  0.2839,  ...,  0.3533,  0.0579, -0.6393],
         [-0.6376, -0.3177, -0.2238,  ..., -0.7059,  0.4351,  0.1451]],

        [[-4.8058,  0.7302, -1.0989,  ...,  3.8324,  2.7810,  1.7821],
         [-0.7038, -0.6393, -0.6297,  ..., -0.0359,  0.1719, -0.3344],
         [-0.1649, -0.7010, -0.9241,  ...,  0.5318,  0.1623, -0.1670],
         ...,
         [-0.6433, -1.0455, -0.2708,  ..., -0.2748,  0.4827,  0.4143],
         [-0.1391, -0.8753,  0.2839,  ...,  0.3533,  0.0579, -0.6393],
         [-0.6376, -0.3177, -0.2238,  ..., -0.7059,  0.4351,  0.1451]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ¦ T_txt=21
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 21, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 21, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 21, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 21])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 21, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 21, 64])
ğŸŸ¦ out.shape=torch.Size([3, 21, 512])
ğŸŸ¦ out.shape=torch.Size([3, 21, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 21, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 21, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.5423,  0.4867, -1.3078,  ...,  4.0570,  2.7591,  1.7055],
         [-0.7944, -1.0986, -0.8873,  ..., -0.3006, -0.1496, -0.3139],
         [ 0.3003, -0.6765, -0.9426,  ...,  0.2994,  0.2125, -0.2227],
         ...,
         [-0.4824, -1.1683, -0.8361,  ..., -0.1666,  0.5882,  0.2543],
         [ 0.3279, -0.9457, -0.1564,  ...,  0.5173,  0.3617, -0.5718],
         [-0.6745, -0.0524, -0.9399,  ..., -0.6166,  0.3006, -0.1860]],

        [[-4.5423,  0.4867, -1.3078,  ...,  4.0570,  2.7591,  1.7055],
         [-0.7944, -1.0986, -0.8873,  ..., -0.3006, -0.1496, -0.3139],
         [ 0.3003, -0.6765, -0.9426,  ...,  0.2994,  0.2125, -0.2227],
         ...,
         [-0.4824, -1.1683, -0.8361,  ..., -0.1666,  0.5882,  0.2543],
         [ 0.3279, -0.9457, -0.1564,  ...,  0.5173,  0.3617, -0.5718],
         [-0.6745, -0.0524, -0.9399,  ..., -0.6166,  0.3006, -0.1860]],

        [[-4.5423,  0.4867, -1.3078,  ...,  4.0570,  2.7591,  1.7055],
         [-0.7944, -1.0986, -0.8873,  ..., -0.3006, -0.1496, -0.3139],
         [ 0.3003, -0.6765, -0.9426,  ...,  0.2994,  0.2125, -0.2227],
         ...,
         [-0.4824, -1.1683, -0.8361,  ..., -0.1666,  0.5882,  0.2543],
         [ 0.3279, -0.9457, -0.1564,  ...,  0.5173,  0.3617, -0.5718],
         [-0.6745, -0.0524, -0.9399,  ..., -0.6166,  0.3006, -0.1860]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ¦ T_txt=21
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 21, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 21, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 21, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 21])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 21, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 21, 64])
ğŸŸ¦ out.shape=torch.Size([3, 21, 512])
ğŸŸ¦ out.shape=torch.Size([3, 21, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 21, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 21, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.4194,  0.4068, -1.0771,  ...,  4.0394,  2.7712,  1.5921],
         [-1.0025, -1.3143, -1.0197,  ..., -0.7655, -0.0488, -0.4858],
         [ 0.0073, -0.6469, -0.9511,  ...,  0.0354,  0.6350,  0.2235],
         ...,
         [-0.5080, -0.9775, -0.7723,  ..., -0.2946,  1.1046,  0.1838],
         [ 0.1066, -1.0839, -0.3253,  ...,  0.2411,  0.8854, -0.7035],
         [-0.7279,  0.0073, -0.7943,  ..., -0.6395,  0.7086, -0.1990]],

        [[-4.4194,  0.4068, -1.0771,  ...,  4.0394,  2.7712,  1.5921],
         [-1.0025, -1.3143, -1.0197,  ..., -0.7655, -0.0488, -0.4858],
         [ 0.0073, -0.6469, -0.9511,  ...,  0.0354,  0.6350,  0.2235],
         ...,
         [-0.5080, -0.9775, -0.7723,  ..., -0.2946,  1.1046,  0.1838],
         [ 0.1066, -1.0839, -0.3253,  ...,  0.2411,  0.8854, -0.7035],
         [-0.7279,  0.0073, -0.7943,  ..., -0.6395,  0.7086, -0.1990]],

        [[-4.4194,  0.4068, -1.0771,  ...,  4.0394,  2.7712,  1.5921],
         [-1.0025, -1.3143, -1.0197,  ..., -0.7654, -0.0488, -0.4858],
         [ 0.0073, -0.6469, -0.9511,  ...,  0.0354,  0.6350,  0.2235],
         ...,
         [-0.5080, -0.9775, -0.7723,  ..., -0.2946,  1.1046,  0.1838],
         [ 0.1066, -1.0839, -0.3253,  ...,  0.2411,  0.8854, -0.7035],
         [-0.7279,  0.0073, -0.7943,  ..., -0.6395,  0.7086, -0.1990]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ¦ T_txt=21
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 21, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 21, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 21, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 21])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 21, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 21, 64])
ğŸŸ¦ out.shape=torch.Size([3, 21, 512])
ğŸŸ¦ out.shape=torch.Size([3, 21, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 21, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 21, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.6486,  0.4370, -1.0679,  ...,  4.0760,  2.7873,  1.4896],
         [-0.9182, -1.6641, -0.8037,  ..., -1.0706, -0.0978,  0.0856],
         [-0.3296, -1.1621, -1.2796,  ..., -0.3973,  0.5544,  0.2346],
         ...,
         [-1.3720, -1.2018, -0.7182,  ..., -0.4695,  0.9297,  0.3855],
         [-0.6062, -1.6136, -0.5444,  ...,  0.2676,  0.6767, -0.6523],
         [-1.6143,  0.0609, -0.3366,  ..., -0.3927,  0.6869, -0.1472]],

        [[-4.6486,  0.4370, -1.0679,  ...,  4.0760,  2.7873,  1.4896],
         [-0.9182, -1.6641, -0.8037,  ..., -1.0706, -0.0978,  0.0856],
         [-0.3296, -1.1621, -1.2796,  ..., -0.3973,  0.5544,  0.2346],
         ...,
         [-1.3720, -1.2018, -0.7182,  ..., -0.4695,  0.9297,  0.3855],
         [-0.6062, -1.6136, -0.5444,  ...,  0.2676,  0.6767, -0.6523],
         [-1.6143,  0.0609, -0.3366,  ..., -0.3927,  0.6869, -0.1472]],

        [[-4.6486,  0.4370, -1.0679,  ...,  4.0760,  2.7874,  1.4896],
         [-0.9182, -1.6641, -0.8037,  ..., -1.0706, -0.0978,  0.0856],
         [-0.3296, -1.1621, -1.2796,  ..., -0.3973,  0.5544,  0.2346],
         ...,
         [-1.3720, -1.2018, -0.7182,  ..., -0.4695,  0.9297,  0.3855],
         [-0.6062, -1.6136, -0.5444,  ...,  0.2676,  0.6767, -0.6523],
         [-1.6143,  0.0609, -0.3367,  ..., -0.3927,  0.6869, -0.1472]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ¦ T_txt=21
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 21, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 21, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 21, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 21])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 21, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 21, 64])
ğŸŸ¦ out.shape=torch.Size([3, 21, 512])
ğŸŸ¦ out.shape=torch.Size([3, 21, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 21, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 21, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.6982,  0.6115, -1.1511,  ...,  3.9602,  2.6816,  1.0754],
         [-0.8318, -2.6615, -1.2791,  ..., -1.1889,  0.2650, -0.4843],
         [-0.0270, -1.6365, -1.4973,  ..., -0.5320,  0.8756,  0.4654],
         ...,
         [-1.2324, -1.2761, -1.1728,  ..., -0.3167,  1.0761,  0.0993],
         [-0.7566, -1.3210, -0.7751,  ...,  0.3029,  0.7884, -0.8653],
         [-1.3130,  0.1763, -0.6732,  ..., -0.1909,  0.6826, -0.5629]],

        [[-4.6982,  0.6115, -1.1511,  ...,  3.9602,  2.6816,  1.0754],
         [-0.8318, -2.6615, -1.2791,  ..., -1.1889,  0.2650, -0.4843],
         [-0.0270, -1.6365, -1.4973,  ..., -0.5320,  0.8756,  0.4654],
         ...,
         [-1.2324, -1.2761, -1.1729,  ..., -0.3167,  1.0761,  0.0993],
         [-0.7566, -1.3210, -0.7751,  ...,  0.3029,  0.7884, -0.8653],
         [-1.3130,  0.1763, -0.6732,  ..., -0.1909,  0.6826, -0.5629]],

        [[-4.6982,  0.6115, -1.1511,  ...,  3.9602,  2.6816,  1.0754],
         [-0.8318, -2.6615, -1.2791,  ..., -1.1889,  0.2650, -0.4843],
         [-0.0270, -1.6365, -1.4973,  ..., -0.5320,  0.8756,  0.4654],
         ...,
         [-1.2324, -1.2761, -1.1729,  ..., -0.3167,  1.0761,  0.0993],
         [-0.7566, -1.3210, -0.7751,  ...,  0.3029,  0.7884, -0.8653],
         [-1.3130,  0.1763, -0.6732,  ..., -0.1909,  0.6826, -0.5629]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ¦ T_txt=21
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 21, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 21, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 21, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 21])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 21, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 21, 64])
ğŸŸ¦ out.shape=torch.Size([3, 21, 512])
ğŸŸ¦ out.shape=torch.Size([3, 21, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 21, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 21, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.1992,  0.1086, -1.3292,  ...,  4.5845,  3.1037,  0.6413],
         [-1.7888, -3.0735, -0.9035,  ..., -0.6403, -0.3643, -0.1203],
         [ 0.6715, -1.5127, -1.2408,  ...,  0.3204,  1.0818,  0.3063],
         ...,
         [-1.2905, -1.3492, -0.7128,  ...,  0.0732,  1.2337, -0.1755],
         [-0.0998, -1.3933, -0.4809,  ...,  1.4542,  1.4927, -1.2638],
         [-1.3948,  0.1298, -0.3071,  ...,  0.0908,  0.1769, -0.6371]],

        [[-4.1992,  0.1086, -1.3292,  ...,  4.5845,  3.1037,  0.6413],
         [-1.7888, -3.0735, -0.9035,  ..., -0.6403, -0.3643, -0.1203],
         [ 0.6715, -1.5127, -1.2408,  ...,  0.3204,  1.0818,  0.3063],
         ...,
         [-1.2905, -1.3492, -0.7128,  ...,  0.0732,  1.2337, -0.1755],
         [-0.0998, -1.3933, -0.4809,  ...,  1.4542,  1.4927, -1.2638],
         [-1.3948,  0.1298, -0.3071,  ...,  0.0908,  0.1769, -0.6371]],

        [[-4.1992,  0.1086, -1.3292,  ...,  4.5845,  3.1037,  0.6413],
         [-1.7888, -3.0735, -0.9035,  ..., -0.6403, -0.3643, -0.1203],
         [ 0.6715, -1.5127, -1.2408,  ...,  0.3204,  1.0818,  0.3063],
         ...,
         [-1.2905, -1.3492, -0.7128,  ...,  0.0732,  1.2337, -0.1755],
         [-0.0998, -1.3933, -0.4809,  ...,  1.4542,  1.4927, -1.2638],
         [-1.3948,  0.1298, -0.3071,  ...,  0.0908,  0.1769, -0.6371]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ¦ T_txt=21
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 21, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 21, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 21, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 21])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 21, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 21, 64])
ğŸŸ¦ out.shape=torch.Size([3, 21, 512])
ğŸŸ¦ out.shape=torch.Size([3, 21, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 21, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 21, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-3.4956, -0.4549, -1.3173,  ...,  5.3489,  3.8643,  0.0495],
         [-1.1846, -2.7309, -0.3251,  ..., -0.5469, -0.2345,  0.0928],
         [ 0.3590, -0.8857, -1.3176,  ...,  0.7098,  1.7219,  0.2027],
         ...,
         [-1.4256, -0.5181, -0.6444,  ...,  0.7368,  1.8982, -0.0886],
         [-0.2198, -0.9331, -1.0763,  ...,  1.8544,  2.3436, -1.4822],
         [-0.7701,  0.4790, -0.4627,  ...,  0.6082,  1.0008, -1.0690]],

        [[-3.4956, -0.4549, -1.3173,  ...,  5.3489,  3.8643,  0.0495],
         [-1.1846, -2.7309, -0.3251,  ..., -0.5469, -0.2345,  0.0928],
         [ 0.3590, -0.8857, -1.3176,  ...,  0.7098,  1.7219,  0.2027],
         ...,
         [-1.4256, -0.5181, -0.6444,  ...,  0.7368,  1.8982, -0.0886],
         [-0.2198, -0.9331, -1.0763,  ...,  1.8544,  2.3436, -1.4822],
         [-0.7701,  0.4790, -0.4627,  ...,  0.6082,  1.0008, -1.0690]],

        [[-3.4956, -0.4549, -1.3173,  ...,  5.3489,  3.8643,  0.0495],
         [-1.1846, -2.7309, -0.3251,  ..., -0.5469, -0.2345,  0.0928],
         [ 0.3590, -0.8857, -1.3176,  ...,  0.7098,  1.7219,  0.2027],
         ...,
         [-1.4256, -0.5181, -0.6444,  ...,  0.7368,  1.8982, -0.0886],
         [-0.2198, -0.9331, -1.0763,  ...,  1.8544,  2.3436, -1.4822],
         [-0.7701,  0.4790, -0.4627,  ...,  0.6082,  1.0008, -1.0690]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ¦ T_txt=21
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 21, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 21, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 21, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 21])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 21, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 21, 64])
ğŸŸ¦ out.shape=torch.Size([3, 21, 512])
ğŸŸ¦ out.shape=torch.Size([3, 21, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 21, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 21, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-2.3185, -1.3191, -1.7786,  ...,  8.3678,  3.3047, -0.5910],
         [-0.8119, -3.2357, -0.0329,  ...,  1.3220, -0.3964,  0.9723],
         [ 0.6821, -0.7940, -0.2673,  ...,  3.2716,  1.7577,  0.8690],
         ...,
         [-1.5436, -0.6999, -0.0666,  ...,  3.4704,  0.7257,  0.1168],
         [ 0.0433, -1.1789, -0.6269,  ...,  4.0073,  2.5114, -0.7028],
         [-0.5466, -0.3479, -0.8769,  ...,  3.6395, -0.0427, -0.5646]],

        [[-2.3185, -1.3191, -1.7786,  ...,  8.3678,  3.3047, -0.5910],
         [-0.8119, -3.2357, -0.0329,  ...,  1.3220, -0.3964,  0.9723],
         [ 0.6821, -0.7940, -0.2673,  ...,  3.2716,  1.7577,  0.8690],
         ...,
         [-1.5436, -0.6999, -0.0666,  ...,  3.4704,  0.7257,  0.1168],
         [ 0.0433, -1.1789, -0.6269,  ...,  4.0073,  2.5114, -0.7028],
         [-0.5466, -0.3479, -0.8769,  ...,  3.6395, -0.0427, -0.5646]],

        [[-2.3185, -1.3191, -1.7786,  ...,  8.3678,  3.3047, -0.5910],
         [-0.8119, -3.2357, -0.0329,  ...,  1.3220, -0.3964,  0.9723],
         [ 0.6821, -0.7940, -0.2673,  ...,  3.2716,  1.7577,  0.8690],
         ...,
         [-1.5436, -0.6999, -0.0666,  ...,  3.4704,  0.7257,  0.1168],
         [ 0.0433, -1.1789, -0.6269,  ...,  4.0073,  2.5114, -0.7028],
         [-0.5466, -0.3479, -0.8769,  ...,  3.6395, -0.0427, -0.5646]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 21, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 21]), use_cached_media=False
ğŸŸ¦ T_txt=21
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 21, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 21, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 21, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 21])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 21, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 21, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 21, 64])
ğŸŸ¦ out.shape=torch.Size([3, 21, 512])
ğŸŸ¦ out.shape=torch.Size([3, 21, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 21, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 21, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 21, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-1.2009, -0.4256,  0.9579,  ...,  3.0081,  1.0086, -0.1812],
         [-0.2749, -1.1022, -0.6093,  ...,  1.7677, -1.5354, -0.1590],
         [ 0.9989,  0.1369, -0.1196,  ...,  5.2063,  0.3365, -0.3707],
         ...,
         [-1.7784,  0.9846,  0.2860,  ...,  5.1388, -1.0615, -1.5348],
         [-0.4515, -1.1408, -0.7140,  ...,  6.3310,  1.6319, -1.8021],
         [-0.8508, -0.5504, -0.4473,  ...,  6.0300, -0.6670, -1.1407]],

        [[-1.2009, -0.4256,  0.9579,  ...,  3.0081,  1.0086, -0.1812],
         [-0.2749, -1.1022, -0.6093,  ...,  1.7677, -1.5354, -0.1590],
         [ 0.9989,  0.1369, -0.1196,  ...,  5.2063,  0.3365, -0.3707],
         ...,
         [-1.7784,  0.9846,  0.2860,  ...,  5.1388, -1.0615, -1.5348],
         [-0.4515, -1.1408, -0.7140,  ...,  6.3310,  1.6319, -1.8021],
         [-0.8508, -0.5504, -0.4473,  ...,  6.0300, -0.6670, -1.1407]],

        [[-1.2009, -0.4256,  0.9579,  ...,  3.0081,  1.0086, -0.1812],
         [-0.2749, -1.1022, -0.6093,  ...,  1.7677, -1.5354, -0.1590],
         [ 0.9989,  0.1369, -0.1195,  ...,  5.2063,  0.3365, -0.3707],
         ...,
         [-1.7784,  0.9846,  0.2860,  ...,  5.1388, -1.0615, -1.5348],
         [-0.4515, -1.1408, -0.7140,  ...,  6.3310,  1.6319, -1.8021],
         [-0.8508, -0.5504, -0.4473,  ...,  6.0300, -0.6670, -1.1407]]]), None)
ğŸŸ© FlamingoLMMixinã®é †ä¼æ’­å®Œäº†
ğŸŸ© FlamingoLMMixinã®é †ä¼æ’­é–‹å§‹ input_ids.shape=torch.Size([3, 22]), input_ids.dtype=torch.int64, None if attention_mask is None else attention_mask.shape=torch.Size([3, 22]), dict_keys(['prefix_mask', 'sequence_id', 'past_key_values', 'use_cache', 'return_dict'])
ğŸŸ¦ media_locations.shape=torch.Size([3, 22]), media_locations.dtype=torch.bool
ğŸŸ¦ use_cached_media_locations=False
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ¦ T_txt=22
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 22, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 22, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 22, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 22])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 22, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 22, 64])
ğŸŸ¦ out.shape=torch.Size([3, 22, 512])
ğŸŸ¦ out.shape=torch.Size([3, 22, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 22, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 22, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-2.0925e-01, -5.9118e-02,  6.5251e-02,  ...,  4.1091e-01,
          -3.5243e-01,  3.7260e-01],
         [-1.7433e-02, -1.4965e-01,  3.6832e-02,  ...,  1.0424e-01,
           3.2264e-03,  4.7463e-01],
         [-1.9068e-02, -1.3694e-01, -1.2874e-01,  ...,  1.6081e-01,
          -1.5760e-01,  1.9950e-01],
         ...,
         [ 1.8914e-02, -1.4606e-01, -1.3678e-01,  ...,  1.6836e-01,
          -1.6449e-01,  2.0091e-01],
         [ 2.5405e-02, -1.5146e-01,  3.8443e-02,  ..., -8.5981e-02,
           4.6475e-04,  3.0404e-01],
         [ 2.9948e-02, -1.0168e-02, -6.5073e-02,  ...,  1.2525e-01,
          -1.2270e-02,  2.5134e-01]],

        [[-2.0925e-01, -5.9118e-02,  6.5251e-02,  ...,  4.1091e-01,
          -3.5243e-01,  3.7260e-01],
         [-1.7433e-02, -1.4965e-01,  3.6832e-02,  ...,  1.0424e-01,
           3.2264e-03,  4.7463e-01],
         [-1.9068e-02, -1.3694e-01, -1.2874e-01,  ...,  1.6081e-01,
          -1.5760e-01,  1.9950e-01],
         ...,
         [ 1.8914e-02, -1.4606e-01, -1.3678e-01,  ...,  1.6836e-01,
          -1.6449e-01,  2.0091e-01],
         [ 2.5405e-02, -1.5146e-01,  3.8443e-02,  ..., -8.5981e-02,
           4.6477e-04,  3.0404e-01],
         [-1.8059e-03,  1.9626e-02, -7.2609e-02,  ...,  6.3279e-02,
          -1.2837e-02, -3.9373e-03]],

        [[-2.0925e-01, -5.9117e-02,  6.5251e-02,  ...,  4.1091e-01,
          -3.5243e-01,  3.7260e-01],
         [-1.7433e-02, -1.4965e-01,  3.6832e-02,  ...,  1.0424e-01,
           3.2264e-03,  4.7463e-01],
         [-1.9068e-02, -1.3694e-01, -1.2874e-01,  ...,  1.6081e-01,
          -1.5760e-01,  1.9950e-01],
         ...,
         [ 1.8915e-02, -1.4606e-01, -1.3678e-01,  ...,  1.6836e-01,
          -1.6449e-01,  2.0091e-01],
         [ 2.5405e-02, -1.5146e-01,  3.8443e-02,  ..., -8.5981e-02,
           4.6471e-04,  3.0404e-01],
         [ 7.4043e-02, -8.6381e-02, -1.2563e-01,  ...,  1.0118e-01,
          -4.5065e-02,  3.3846e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ¦ T_txt=22
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 22, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 22, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 22, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 22])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 22, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 22, 64])
ğŸŸ¦ out.shape=torch.Size([3, 22, 512])
ğŸŸ¦ out.shape=torch.Size([3, 22, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 22, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 22, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-0.0762, -0.3746,  0.1300,  ...,  0.1017, -0.0332,  0.2191],
         [-0.0236, -0.1139, -0.0499,  ...,  0.0464,  0.0973,  0.4798],
         [ 0.0476, -0.1903,  0.0666,  ..., -0.0123, -0.0800,  0.3086],
         ...,
         [ 0.1003, -0.1236,  0.0705,  ..., -0.0096, -0.0471,  0.3702],
         [ 0.0278, -0.1336, -0.0075,  ..., -0.1681, -0.0534,  0.5033],
         [ 0.0278,  0.0493, -0.0914,  ...,  0.1708, -0.1178,  0.4907]],

        [[-0.0762, -0.3746,  0.1300,  ...,  0.1017, -0.0332,  0.2191],
         [-0.0236, -0.1139, -0.0499,  ...,  0.0464,  0.0973,  0.4798],
         [ 0.0476, -0.1903,  0.0666,  ..., -0.0123, -0.0800,  0.3086],
         ...,
         [ 0.1003, -0.1236,  0.0705,  ..., -0.0096, -0.0471,  0.3702],
         [ 0.0278, -0.1336, -0.0075,  ..., -0.1681, -0.0534,  0.5033],
         [-0.0781,  0.0454, -0.0721,  ...,  0.0595, -0.0373,  0.1428]],

        [[-0.0762, -0.3746,  0.1300,  ...,  0.1017, -0.0332,  0.2191],
         [-0.0236, -0.1139, -0.0499,  ...,  0.0464,  0.0973,  0.4798],
         [ 0.0476, -0.1903,  0.0666,  ..., -0.0123, -0.0800,  0.3086],
         ...,
         [ 0.1003, -0.1236,  0.0705,  ..., -0.0096, -0.0471,  0.3702],
         [ 0.0278, -0.1336, -0.0075,  ..., -0.1681, -0.0534,  0.5033],
         [ 0.0731, -0.0727, -0.2313,  ...,  0.1010, -0.1302,  0.5542]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ¦ T_txt=22
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 22, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 22, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 22, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 22])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 22, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 22, 64])
ğŸŸ¦ out.shape=torch.Size([3, 22, 512])
ğŸŸ¦ out.shape=torch.Size([3, 22, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 22, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 22, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-0.0423, -0.4800,  0.0985,  ..., -0.1247,  0.1871, -0.2268],
         [-0.0501, -0.1131, -0.1332,  ...,  0.1946,  0.1566,  0.3318],
         [-0.0369, -0.1714,  0.2051,  ...,  0.1376, -0.1982,  0.2490],
         ...,
         [-0.0399, -0.2604,  0.3385,  ...,  0.0974, -0.1178,  0.1742],
         [-0.0864, -0.1342,  0.0755,  ..., -0.1099, -0.0017,  0.3514],
         [ 0.0585,  0.1236, -0.0072,  ...,  0.1960, -0.0054,  0.3329]],

        [[-0.0423, -0.4800,  0.0985,  ..., -0.1247,  0.1871, -0.2268],
         [-0.0501, -0.1131, -0.1332,  ...,  0.1946,  0.1566,  0.3318],
         [-0.0369, -0.1714,  0.2051,  ...,  0.1376, -0.1982,  0.2490],
         ...,
         [-0.0399, -0.2604,  0.3385,  ...,  0.0974, -0.1178,  0.1742],
         [-0.0864, -0.1342,  0.0755,  ..., -0.1099, -0.0017,  0.3514],
         [-0.0923,  0.0879,  0.0206,  ...,  0.0524,  0.0767, -0.0988]],

        [[-0.0423, -0.4800,  0.0985,  ..., -0.1247,  0.1871, -0.2268],
         [-0.0501, -0.1131, -0.1332,  ...,  0.1946,  0.1566,  0.3318],
         [-0.0369, -0.1714,  0.2051,  ...,  0.1376, -0.1982,  0.2490],
         ...,
         [-0.0399, -0.2604,  0.3385,  ...,  0.0974, -0.1178,  0.1742],
         [-0.0864, -0.1342,  0.0755,  ..., -0.1099, -0.0017,  0.3514],
         [ 0.0445, -0.0668, -0.1460,  ...,  0.1272,  0.0121,  0.4292]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ¦ T_txt=22
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 22, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 22, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 22, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 22])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 22, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 22, 64])
ğŸŸ¦ out.shape=torch.Size([3, 22, 512])
ğŸŸ¦ out.shape=torch.Size([3, 22, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 22, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 22, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-0.6808, -0.0752, -0.2681,  ..., -0.1388, -0.2275, -0.2143],
         [-0.2353, -0.1768, -0.1707,  ...,  0.0178,  0.0832,  0.2217],
         [ 0.1139, -0.0718,  0.1118,  ...,  0.0826, -0.0978,  0.2029],
         ...,
         [ 0.0286, -0.0663,  0.1672,  ..., -0.0161, -0.0736,  0.1485],
         [ 0.0567,  0.0876,  0.0517,  ...,  0.0078, -0.1083,  0.5091],
         [-0.0029,  0.1539,  0.0426,  ...,  0.1117,  0.0696,  0.2327]],

        [[-0.6808, -0.0752, -0.2681,  ..., -0.1388, -0.2275, -0.2143],
         [-0.2353, -0.1768, -0.1707,  ...,  0.0178,  0.0832,  0.2217],
         [ 0.1139, -0.0718,  0.1118,  ...,  0.0826, -0.0978,  0.2029],
         ...,
         [ 0.0286, -0.0663,  0.1672,  ..., -0.0161, -0.0736,  0.1485],
         [ 0.0567,  0.0876,  0.0517,  ...,  0.0078, -0.1083,  0.5091],
         [-0.0540,  0.0675, -0.0095,  ...,  0.0388,  0.0280, -0.1516]],

        [[-0.6808, -0.0752, -0.2681,  ..., -0.1388, -0.2275, -0.2143],
         [-0.2353, -0.1768, -0.1707,  ...,  0.0178,  0.0832,  0.2217],
         [ 0.1139, -0.0718,  0.1118,  ...,  0.0826, -0.0978,  0.2029],
         ...,
         [ 0.0286, -0.0663,  0.1672,  ..., -0.0161, -0.0736,  0.1485],
         [ 0.0567,  0.0876,  0.0517,  ...,  0.0078, -0.1083,  0.5091],
         [-0.0808,  0.0286, -0.0291,  ..., -0.0008,  0.1158,  0.3411]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ¦ T_txt=22
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 22, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 22, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 22, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 22])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 22, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 22, 64])
ğŸŸ¦ out.shape=torch.Size([3, 22, 512])
ğŸŸ¦ out.shape=torch.Size([3, 22, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 22, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 22, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.0310e+00,  7.9414e-01, -1.4750e+00,  ...,  3.6145e-01,
           1.5208e+00, -2.4390e-01],
         [-5.7247e-01, -9.2225e-02, -2.4184e-01,  ...,  5.1393e-02,
           3.1086e-02,  2.4566e-01],
         [ 6.8573e-02, -5.9338e-02,  1.0359e-01,  ...,  5.0657e-02,
           1.8189e-01,  4.9062e-02],
         ...,
         [ 3.8942e-02,  6.5046e-03,  5.5976e-02,  ..., -3.1300e-02,
           2.4623e-02,  1.2090e-02],
         [ 5.8646e-04,  7.3301e-02, -2.1840e-01,  ...,  5.6920e-02,
           5.3535e-02,  3.7094e-01],
         [-4.4851e-02,  1.2006e-01, -6.3868e-02,  ...,  6.3939e-02,
          -7.4924e-02,  3.2249e-01]],

        [[-4.0310e+00,  7.9414e-01, -1.4750e+00,  ...,  3.6145e-01,
           1.5208e+00, -2.4390e-01],
         [-5.7247e-01, -9.2225e-02, -2.4184e-01,  ...,  5.1393e-02,
           3.1086e-02,  2.4566e-01],
         [ 6.8573e-02, -5.9338e-02,  1.0359e-01,  ...,  5.0657e-02,
           1.8189e-01,  4.9062e-02],
         ...,
         [ 3.8942e-02,  6.5046e-03,  5.5976e-02,  ..., -3.1300e-02,
           2.4623e-02,  1.2090e-02],
         [ 5.8650e-04,  7.3301e-02, -2.1840e-01,  ...,  5.6920e-02,
           5.3535e-02,  3.7094e-01],
         [ 7.0384e-02,  1.3529e-01, -1.3731e-01,  ..., -4.8713e-02,
          -8.5848e-02, -2.3024e-01]],

        [[-4.0310e+00,  7.9414e-01, -1.4750e+00,  ...,  3.6145e-01,
           1.5208e+00, -2.4390e-01],
         [-5.7247e-01, -9.2225e-02, -2.4184e-01,  ...,  5.1393e-02,
           3.1086e-02,  2.4566e-01],
         [ 6.8573e-02, -5.9338e-02,  1.0359e-01,  ...,  5.0657e-02,
           1.8189e-01,  4.9062e-02],
         ...,
         [ 3.8942e-02,  6.5048e-03,  5.5976e-02,  ..., -3.1300e-02,
           2.4623e-02,  1.2090e-02],
         [ 5.8647e-04,  7.3301e-02, -2.1840e-01,  ...,  5.6920e-02,
           5.3535e-02,  3.7094e-01],
         [-1.0418e-01,  2.9669e-02, -2.2618e-01,  ..., -7.1319e-02,
          -4.9033e-02,  4.3000e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ¦ T_txt=22
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 22, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 22, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 22, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 22])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 22, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 22, 64])
ğŸŸ¦ out.shape=torch.Size([3, 22, 512])
ğŸŸ¦ out.shape=torch.Size([3, 22, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 22, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 22, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.7946e+00,  9.0221e-01, -1.2882e+00,  ...,  1.1832e+00,
           2.5226e+00, -5.9823e-02],
         [-5.6193e-01, -1.5785e-01, -2.8558e-01,  ..., -3.8618e-02,
          -1.3092e-02,  1.2509e-01],
         [ 4.1303e-03, -1.2649e-01, -2.6289e-01,  ...,  2.2804e-01,
          -9.2656e-02,  5.5101e-03],
         ...,
         [-1.9361e-01,  1.8242e-01, -1.8671e-01,  ...,  1.9924e-01,
          -2.6155e-01,  1.1251e-01],
         [-4.1566e-01,  2.0328e-01, -1.5304e-01,  ...,  7.1610e-02,
           2.6326e-02,  3.2153e-01],
         [-2.1025e-01,  3.5201e-02,  2.9223e-02,  ...,  3.3373e-01,
           3.1496e-02,  9.7370e-02]],

        [[-4.7946e+00,  9.0221e-01, -1.2882e+00,  ...,  1.1832e+00,
           2.5226e+00, -5.9823e-02],
         [-5.6193e-01, -1.5785e-01, -2.8558e-01,  ..., -3.8618e-02,
          -1.3092e-02,  1.2509e-01],
         [ 4.1303e-03, -1.2649e-01, -2.6289e-01,  ...,  2.2804e-01,
          -9.2656e-02,  5.5101e-03],
         ...,
         [-1.9361e-01,  1.8242e-01, -1.8671e-01,  ...,  1.9924e-01,
          -2.6155e-01,  1.1251e-01],
         [-4.1566e-01,  2.0328e-01, -1.5304e-01,  ...,  7.1609e-02,
           2.6326e-02,  3.2153e-01],
         [-9.1819e-02,  6.1464e-02, -3.5122e-02,  ...,  3.9136e-03,
          -3.1486e-02, -3.6333e-01]],

        [[-4.7946e+00,  9.0221e-01, -1.2882e+00,  ...,  1.1832e+00,
           2.5226e+00, -5.9824e-02],
         [-5.6193e-01, -1.5785e-01, -2.8558e-01,  ..., -3.8618e-02,
          -1.3092e-02,  1.2509e-01],
         [ 4.1303e-03, -1.2649e-01, -2.6289e-01,  ...,  2.2804e-01,
          -9.2657e-02,  5.5097e-03],
         ...,
         [-1.9361e-01,  1.8242e-01, -1.8671e-01,  ...,  1.9924e-01,
          -2.6155e-01,  1.1251e-01],
         [-4.1566e-01,  2.0328e-01, -1.5304e-01,  ...,  7.1610e-02,
           2.6326e-02,  3.2153e-01],
         [-3.4284e-01, -1.3329e-03, -5.0193e-02,  ...,  2.0860e-01,
           2.3468e-02,  2.7112e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ¦ T_txt=22
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 22, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 22, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 22, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 22])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 22, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 22, 64])
ğŸŸ¦ out.shape=torch.Size([3, 22, 512])
ğŸŸ¦ out.shape=torch.Size([3, 22, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 22, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 22, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.2771e+00,  1.3169e+00, -1.5839e+00,  ...,  1.5235e+00,
           2.5618e+00,  3.0273e-01],
         [-5.1019e-01, -2.0753e-01, -3.9353e-01,  ..., -3.0973e-02,
           3.3680e-01,  1.5358e-01],
         [ 9.6702e-02, -5.6518e-01, -1.5635e-01,  ...,  8.8998e-03,
           7.6486e-02, -5.2470e-03],
         ...,
         [ 1.3968e-01, -2.8755e-01,  1.2602e-01,  ..., -5.6688e-02,
           1.7580e-02,  3.1946e-03],
         [-2.2878e-01,  2.1636e-01, -6.4802e-03,  ...,  9.7471e-02,
           1.7168e-01,  1.4387e-01],
         [-1.3436e-01,  1.5734e-01, -2.1990e-01,  ...,  4.6067e-01,
           1.1024e-01,  1.8483e-01]],

        [[-5.2771e+00,  1.3169e+00, -1.5839e+00,  ...,  1.5235e+00,
           2.5618e+00,  3.0273e-01],
         [-5.1019e-01, -2.0753e-01, -3.9353e-01,  ..., -3.0973e-02,
           3.3680e-01,  1.5358e-01],
         [ 9.6702e-02, -5.6518e-01, -1.5635e-01,  ...,  8.8998e-03,
           7.6486e-02, -5.2470e-03],
         ...,
         [ 1.3968e-01, -2.8755e-01,  1.2602e-01,  ..., -5.6688e-02,
           1.7580e-02,  3.1947e-03],
         [-2.2878e-01,  2.1636e-01, -6.4801e-03,  ...,  9.7471e-02,
           1.7168e-01,  1.4387e-01],
         [ 1.0023e-01,  2.9017e-01, -3.2888e-01,  ...,  2.2725e-01,
           6.2536e-02, -3.8436e-01]],

        [[-5.2771e+00,  1.3169e+00, -1.5839e+00,  ...,  1.5235e+00,
           2.5618e+00,  3.0273e-01],
         [-5.1019e-01, -2.0753e-01, -3.9353e-01,  ..., -3.0973e-02,
           3.3680e-01,  1.5358e-01],
         [ 9.6702e-02, -5.6518e-01, -1.5635e-01,  ...,  8.8997e-03,
           7.6485e-02, -5.2472e-03],
         ...,
         [ 1.3968e-01, -2.8755e-01,  1.2602e-01,  ..., -5.6688e-02,
           1.7580e-02,  3.1950e-03],
         [-2.2878e-01,  2.1636e-01, -6.4799e-03,  ...,  9.7471e-02,
           1.7168e-01,  1.4387e-01],
         [-2.3985e-01,  8.4361e-02, -2.3733e-01,  ...,  3.3294e-01,
           1.4696e-01,  3.5174e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ¦ T_txt=22
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 22, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 22, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 22, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 22])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 22, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 22, 64])
ğŸŸ¦ out.shape=torch.Size([3, 22, 512])
ğŸŸ¦ out.shape=torch.Size([3, 22, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 22, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 22, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.3925e+00,  1.2785e+00, -1.7428e+00,  ...,  1.6187e+00,
           2.6666e+00,  6.3102e-01],
         [-7.2190e-01, -9.0366e-02, -3.7054e-01,  ..., -4.8731e-02,
           5.0303e-02,  4.0432e-02],
         [ 3.2142e-02, -5.6480e-01, -2.0480e-01,  ...,  6.2426e-02,
          -1.1226e-01,  5.0912e-03],
         ...,
         [ 1.7065e-01, -8.8156e-02,  7.1555e-02,  ...,  5.6628e-02,
          -2.0010e-01, -3.2694e-02],
         [-4.7935e-01,  1.4615e-01, -1.9178e-01,  ...,  1.2073e-01,
          -1.3311e-01,  8.5742e-02],
         [-2.0149e-01,  2.5538e-01,  1.1703e-04,  ...,  4.8664e-01,
          -3.3184e-01,  5.2587e-02]],

        [[-5.3925e+00,  1.2785e+00, -1.7428e+00,  ...,  1.6187e+00,
           2.6666e+00,  6.3102e-01],
         [-7.2190e-01, -9.0366e-02, -3.7054e-01,  ..., -4.8731e-02,
           5.0303e-02,  4.0432e-02],
         [ 3.2142e-02, -5.6480e-01, -2.0480e-01,  ...,  6.2426e-02,
          -1.1226e-01,  5.0912e-03],
         ...,
         [ 1.7065e-01, -8.8157e-02,  7.1555e-02,  ...,  5.6627e-02,
          -2.0010e-01, -3.2694e-02],
         [-4.7935e-01,  1.4615e-01, -1.9178e-01,  ...,  1.2073e-01,
          -1.3311e-01,  8.5742e-02],
         [-2.2096e-02,  3.7302e-01, -3.6384e-01,  ...,  1.6317e-01,
          -2.1042e-01, -3.3812e-01]],

        [[-5.3925e+00,  1.2785e+00, -1.7428e+00,  ...,  1.6187e+00,
           2.6666e+00,  6.3102e-01],
         [-7.2190e-01, -9.0366e-02, -3.7054e-01,  ..., -4.8731e-02,
           5.0303e-02,  4.0432e-02],
         [ 3.2142e-02, -5.6480e-01, -2.0480e-01,  ...,  6.2426e-02,
          -1.1226e-01,  5.0911e-03],
         ...,
         [ 1.7065e-01, -8.8157e-02,  7.1555e-02,  ...,  5.6627e-02,
          -2.0010e-01, -3.2694e-02],
         [-4.7935e-01,  1.4615e-01, -1.9178e-01,  ...,  1.2073e-01,
          -1.3311e-01,  8.5742e-02],
         [-3.1700e-01,  7.7825e-02,  4.7752e-02,  ...,  3.7195e-01,
          -2.0389e-01,  2.1260e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ¦ T_txt=22
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 22, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 22, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 22, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 22])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 22, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 22, 64])
ğŸŸ¦ out.shape=torch.Size([3, 22, 512])
ğŸŸ¦ out.shape=torch.Size([3, 22, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 22, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 22, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.7653,  1.1008, -1.8155,  ...,  2.3020,  2.1681,  1.0300],
         [-0.6620, -0.0777, -0.5133,  ..., -0.2264,  0.1684, -0.0159],
         [ 0.0287, -0.6121, -0.4236,  ..., -0.2224,  0.0996,  0.0129],
         ...,
         [ 0.2910, -0.3232, -0.0891,  ..., -0.2288,  0.0756, -0.3264],
         [-0.2309,  0.0085, -0.2722,  ..., -0.1629,  0.2583, -0.0625],
         [-0.0325, -0.0701,  0.0903,  ...,  0.1330, -0.1774, -0.1450]],

        [[-5.7653,  1.1008, -1.8155,  ...,  2.3020,  2.1681,  1.0300],
         [-0.6620, -0.0777, -0.5133,  ..., -0.2264,  0.1684, -0.0159],
         [ 0.0287, -0.6121, -0.4236,  ..., -0.2224,  0.0996,  0.0129],
         ...,
         [ 0.2910, -0.3232, -0.0891,  ..., -0.2288,  0.0756, -0.3264],
         [-0.2309,  0.0085, -0.2722,  ..., -0.1629,  0.2583, -0.0625],
         [ 0.0917,  0.1726, -0.3757,  ..., -0.0870, -0.0496, -0.4644]],

        [[-5.7653,  1.1008, -1.8155,  ...,  2.3020,  2.1681,  1.0300],
         [-0.6620, -0.0777, -0.5133,  ..., -0.2264,  0.1684, -0.0159],
         [ 0.0287, -0.6121, -0.4236,  ..., -0.2224,  0.0996,  0.0129],
         ...,
         [ 0.2910, -0.3232, -0.0891,  ..., -0.2288,  0.0756, -0.3264],
         [-0.2309,  0.0085, -0.2722,  ..., -0.1629,  0.2583, -0.0625],
         [-0.0426, -0.1735,  0.0781,  ...,  0.0589, -0.0719,  0.0338]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ¦ T_txt=22
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 22, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 22, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 22, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 22])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 22, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 22, 64])
ğŸŸ¦ out.shape=torch.Size([3, 22, 512])
ğŸŸ¦ out.shape=torch.Size([3, 22, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 22, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 22, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.8693e+00,  9.3745e-01, -1.8379e+00,  ...,  2.4698e+00,
           2.0660e+00,  1.2787e+00],
         [-6.8941e-01,  2.4615e-01, -4.9576e-01,  ..., -2.5218e-01,
           1.5029e-01,  7.9583e-02],
         [ 1.1727e-01, -2.8995e-01, -5.4170e-01,  ..., -1.3670e-01,
           7.0986e-02,  1.0259e-01],
         ...,
         [ 5.6605e-01, -2.1509e-01, -3.7418e-01,  ..., -2.0239e-01,
           2.7904e-01, -5.9670e-02],
         [-9.5838e-02, -1.7879e-01, -4.5818e-01,  ..., -1.0674e-01,
           3.1609e-01,  3.4635e-01],
         [ 1.9294e-01,  1.1087e-01,  1.4712e-01,  ..., -1.6258e-04,
          -3.1137e-02,  1.7252e-01]],

        [[-5.8693e+00,  9.3745e-01, -1.8379e+00,  ...,  2.4698e+00,
           2.0660e+00,  1.2787e+00],
         [-6.8941e-01,  2.4615e-01, -4.9576e-01,  ..., -2.5218e-01,
           1.5029e-01,  7.9583e-02],
         [ 1.1727e-01, -2.8995e-01, -5.4170e-01,  ..., -1.3670e-01,
           7.0986e-02,  1.0259e-01],
         ...,
         [ 5.6605e-01, -2.1509e-01, -3.7418e-01,  ..., -2.0239e-01,
           2.7904e-01, -5.9670e-02],
         [-9.5838e-02, -1.7879e-01, -4.5818e-01,  ..., -1.0674e-01,
           3.1609e-01,  3.4635e-01],
         [ 9.5525e-02,  2.9042e-01, -2.4612e-01,  ..., -3.3959e-01,
           1.2475e-02, -4.0806e-02]],

        [[-5.8693e+00,  9.3745e-01, -1.8379e+00,  ...,  2.4698e+00,
           2.0660e+00,  1.2787e+00],
         [-6.8941e-01,  2.4615e-01, -4.9576e-01,  ..., -2.5218e-01,
           1.5029e-01,  7.9583e-02],
         [ 1.1727e-01, -2.8995e-01, -5.4170e-01,  ..., -1.3670e-01,
           7.0986e-02,  1.0259e-01],
         ...,
         [ 5.6605e-01, -2.1509e-01, -3.7418e-01,  ..., -2.0239e-01,
           2.7904e-01, -5.9670e-02],
         [-9.5838e-02, -1.7879e-01, -4.5818e-01,  ..., -1.0674e-01,
           3.1609e-01,  3.4635e-01],
         [ 6.5113e-02,  4.1624e-02,  1.0161e-01,  ..., -8.3677e-02,
           6.6423e-02,  3.7447e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ¦ T_txt=22
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 22, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 22, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 22, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 22])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 22, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 22, 64])
ğŸŸ¦ out.shape=torch.Size([3, 22, 512])
ğŸŸ¦ out.shape=torch.Size([3, 22, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 22, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 22, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.6016,  1.2408, -1.6460,  ...,  3.1029,  2.1120,  1.1936],
         [-0.5132,  0.1307, -0.5725,  ..., -0.0805,  0.0303, -0.1367],
         [ 0.2105, -0.6863, -0.6633,  ...,  0.2212,  0.3595,  0.2320],
         ...,
         [ 0.2628, -0.2662, -0.4232,  ..., -0.0868,  0.1921, -0.0403],
         [-0.1682, -0.4626, -0.5883,  ..., -0.0632,  0.1946,  0.1242],
         [-0.0388, -0.0288, -0.0640,  ...,  0.0703, -0.2369,  0.0478]],

        [[-5.6016,  1.2408, -1.6460,  ...,  3.1029,  2.1120,  1.1936],
         [-0.5132,  0.1307, -0.5725,  ..., -0.0805,  0.0303, -0.1367],
         [ 0.2105, -0.6863, -0.6633,  ...,  0.2212,  0.3595,  0.2320],
         ...,
         [ 0.2628, -0.2662, -0.4232,  ..., -0.0868,  0.1921, -0.0403],
         [-0.1682, -0.4626, -0.5883,  ..., -0.0632,  0.1946,  0.1242],
         [-0.2168,  0.0882, -0.2264,  ...,  0.0302, -0.1054, -0.2631]],

        [[-5.6016,  1.2408, -1.6460,  ...,  3.1029,  2.1120,  1.1936],
         [-0.5132,  0.1307, -0.5725,  ..., -0.0805,  0.0303, -0.1367],
         [ 0.2105, -0.6863, -0.6633,  ...,  0.2212,  0.3595,  0.2320],
         ...,
         [ 0.2628, -0.2662, -0.4232,  ..., -0.0868,  0.1921, -0.0403],
         [-0.1682, -0.4626, -0.5883,  ..., -0.0632,  0.1946,  0.1242],
         [-0.1072, -0.0344, -0.1227,  ...,  0.0201, -0.1590,  0.0884]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ¦ T_txt=22
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 22, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 22, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 22, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 22])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 22, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 22, 64])
ğŸŸ¦ out.shape=torch.Size([3, 22, 512])
ğŸŸ¦ out.shape=torch.Size([3, 22, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 22, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 22, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.5722,  1.3828, -1.6196,  ...,  3.5095,  2.5083,  1.2801],
         [-0.7604,  0.1403, -0.7794,  ...,  0.1032,  0.1174, -0.2312],
         [-0.0521, -0.3372, -0.8223,  ...,  0.0621,  0.1464,  0.1382],
         ...,
         [ 0.3477, -0.1342, -0.2301,  ..., -0.4374, -0.3828, -0.2864],
         [-0.3934, -0.2799, -0.2061,  ..., -0.4735,  0.0483,  0.0476],
         [-0.3888,  0.0774, -0.0618,  ..., -0.3501, -0.3116,  0.3053]],

        [[-5.5722,  1.3828, -1.6196,  ...,  3.5095,  2.5083,  1.2801],
         [-0.7604,  0.1403, -0.7794,  ...,  0.1032,  0.1174, -0.2312],
         [-0.0521, -0.3372, -0.8223,  ...,  0.0621,  0.1464,  0.1382],
         ...,
         [ 0.3477, -0.1342, -0.2301,  ..., -0.4374, -0.3828, -0.2864],
         [-0.3934, -0.2799, -0.2061,  ..., -0.4735,  0.0483,  0.0476],
         [-0.4124,  0.1867, -0.3309,  ..., -0.0146, -0.0751, -0.2397]],

        [[-5.5722,  1.3828, -1.6196,  ...,  3.5095,  2.5083,  1.2801],
         [-0.7604,  0.1403, -0.7794,  ...,  0.1032,  0.1174, -0.2312],
         [-0.0521, -0.3372, -0.8223,  ...,  0.0621,  0.1464,  0.1382],
         ...,
         [ 0.3477, -0.1342, -0.2301,  ..., -0.4374, -0.3828, -0.2864],
         [-0.3934, -0.2799, -0.2061,  ..., -0.4735,  0.0483,  0.0476],
         [-0.3329,  0.1113, -0.1318,  ..., -0.2220, -0.1379,  0.4419]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ¦ T_txt=22
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 22, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 22, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 22, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 22])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 22, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 22, 64])
ğŸŸ¦ out.shape=torch.Size([3, 22, 512])
ğŸŸ¦ out.shape=torch.Size([3, 22, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 22, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 22, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.6640e+00,  1.4165e+00, -1.7391e+00,  ...,  3.7237e+00,
           2.6647e+00,  1.4654e+00],
         [-6.0783e-01, -2.5051e-02, -1.0078e+00,  ...,  2.4022e-02,
          -3.9409e-02, -4.4003e-01],
         [-2.3939e-01, -7.4469e-01, -9.9975e-01,  ..., -1.7663e-01,
           9.6496e-02,  5.5717e-02],
         ...,
         [-7.0807e-02, -4.1917e-01, -5.5701e-02,  ..., -2.1743e-01,
          -1.3310e-01, -4.2003e-01],
         [-3.9262e-01, -3.0471e-01, -1.6310e-03,  ..., -1.2015e-01,
           1.6517e-01, -7.2140e-02],
         [-5.2806e-01, -1.1494e-01,  1.3895e-01,  ..., -2.9315e-01,
          -1.1028e-01,  4.4209e-01]],

        [[-5.6640e+00,  1.4165e+00, -1.7391e+00,  ...,  3.7237e+00,
           2.6647e+00,  1.4654e+00],
         [-6.0783e-01, -2.5051e-02, -1.0078e+00,  ...,  2.4022e-02,
          -3.9409e-02, -4.4003e-01],
         [-2.3939e-01, -7.4469e-01, -9.9975e-01,  ..., -1.7663e-01,
           9.6496e-02,  5.5717e-02],
         ...,
         [-7.0807e-02, -4.1918e-01, -5.5701e-02,  ..., -2.1743e-01,
          -1.3310e-01, -4.2003e-01],
         [-3.9262e-01, -3.0471e-01, -1.6314e-03,  ..., -1.2015e-01,
           1.6517e-01, -7.2140e-02],
         [-2.5073e-01,  5.7864e-02, -2.5767e-01,  ..., -2.2618e-01,
          -9.0730e-02, -3.6314e-01]],

        [[-5.6640e+00,  1.4165e+00, -1.7391e+00,  ...,  3.7237e+00,
           2.6647e+00,  1.4654e+00],
         [-6.0783e-01, -2.5051e-02, -1.0078e+00,  ...,  2.4022e-02,
          -3.9409e-02, -4.4003e-01],
         [-2.3939e-01, -7.4469e-01, -9.9975e-01,  ..., -1.7663e-01,
           9.6496e-02,  5.5718e-02],
         ...,
         [-7.0806e-02, -4.1918e-01, -5.5702e-02,  ..., -2.1743e-01,
          -1.3310e-01, -4.2003e-01],
         [-3.9262e-01, -3.0471e-01, -1.6314e-03,  ..., -1.2016e-01,
           1.6517e-01, -7.2140e-02],
         [-4.3965e-01, -1.4570e-01, -1.1044e-01,  ..., -1.5448e-01,
           6.8531e-02,  5.5012e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ¦ T_txt=22
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 22, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 22, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 22, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 22])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 22, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 22, 64])
ğŸŸ¦ out.shape=torch.Size([3, 22, 512])
ğŸŸ¦ out.shape=torch.Size([3, 22, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 22, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 22, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.3878,  1.2637, -1.3476,  ...,  3.9388,  2.7129,  1.6259],
         [-0.6773,  0.0069, -0.7329,  ...,  0.2023,  0.1743, -0.1756],
         [-0.3587, -0.5944, -1.0050,  ...,  0.2275,  0.4650,  0.1995],
         ...,
         [-0.1259, -0.3586,  0.2386,  ..., -0.0128,  0.2053, -0.4407],
         [-0.3912, -0.3264,  0.2907,  ..., -0.3382,  0.2944,  0.1950],
         [-0.4809, -0.3364,  0.3896,  ..., -0.2721,  0.0814,  0.6517]],

        [[-5.3878,  1.2637, -1.3476,  ...,  3.9388,  2.7129,  1.6259],
         [-0.6773,  0.0069, -0.7329,  ...,  0.2023,  0.1743, -0.1756],
         [-0.3587, -0.5944, -1.0050,  ...,  0.2275,  0.4650,  0.1995],
         ...,
         [-0.1259, -0.3586,  0.2386,  ..., -0.0128,  0.2053, -0.4407],
         [-0.3912, -0.3264,  0.2907,  ..., -0.3382,  0.2944,  0.1950],
         [-0.3776, -0.2005, -0.2288,  ..., -0.2464,  0.0399, -0.5056]],

        [[-5.3878,  1.2637, -1.3476,  ...,  3.9388,  2.7129,  1.6259],
         [-0.6773,  0.0069, -0.7329,  ...,  0.2023,  0.1743, -0.1756],
         [-0.3587, -0.5944, -1.0050,  ...,  0.2275,  0.4650,  0.1995],
         ...,
         [-0.1259, -0.3586,  0.2386,  ..., -0.0128,  0.2053, -0.4407],
         [-0.3912, -0.3264,  0.2907,  ..., -0.3382,  0.2944,  0.1950],
         [-0.5359, -0.3399,  0.0364,  ..., -0.0771,  0.1621,  0.7395]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ¦ T_txt=22
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 22, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 22, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 22, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 22])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 22, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 22, 64])
ğŸŸ¦ out.shape=torch.Size([3, 22, 512])
ğŸŸ¦ out.shape=torch.Size([3, 22, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 22, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 22, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.0959e+00,  8.5670e-01, -1.2666e+00,  ...,  3.8593e+00,
           2.8167e+00,  1.9328e+00],
         [-9.0690e-01, -3.5641e-01, -8.7610e-01,  ...,  1.3842e-01,
           2.8884e-01, -1.7834e-01],
         [-2.4497e-01, -8.7742e-01, -1.2020e+00,  ...,  3.0884e-01,
           3.8290e-01,  2.8289e-01],
         ...,
         [ 1.6695e-02, -7.6792e-01,  5.6771e-02,  ...,  8.6255e-02,
           2.4240e-01, -5.1523e-01],
         [-4.9250e-01, -3.9705e-01,  1.8587e-01,  ..., -9.8828e-02,
           3.3473e-01,  3.6105e-01],
         [-6.2545e-01, -4.2646e-01,  3.0677e-01,  ...,  2.1251e-01,
          -6.2344e-02,  8.1318e-01]],

        [[-5.0959e+00,  8.5670e-01, -1.2666e+00,  ...,  3.8593e+00,
           2.8167e+00,  1.9328e+00],
         [-9.0690e-01, -3.5641e-01, -8.7610e-01,  ...,  1.3842e-01,
           2.8884e-01, -1.7834e-01],
         [-2.4497e-01, -8.7742e-01, -1.2020e+00,  ...,  3.0884e-01,
           3.8290e-01,  2.8289e-01],
         ...,
         [ 1.6694e-02, -7.6792e-01,  5.6772e-02,  ...,  8.6255e-02,
           2.4240e-01, -5.1523e-01],
         [-4.9250e-01, -3.9705e-01,  1.8587e-01,  ..., -9.8828e-02,
           3.3473e-01,  3.6105e-01],
         [-2.1849e-01, -4.2778e-02, -7.8789e-02,  ..., -4.8647e-02,
          -4.9569e-03, -3.5574e-01]],

        [[-5.0959e+00,  8.5671e-01, -1.2666e+00,  ...,  3.8593e+00,
           2.8167e+00,  1.9328e+00],
         [-9.0690e-01, -3.5641e-01, -8.7610e-01,  ...,  1.3842e-01,
           2.8884e-01, -1.7834e-01],
         [-2.4497e-01, -8.7742e-01, -1.2020e+00,  ...,  3.0884e-01,
           3.8290e-01,  2.8290e-01],
         ...,
         [ 1.6695e-02, -7.6792e-01,  5.6771e-02,  ...,  8.6254e-02,
           2.4240e-01, -5.1523e-01],
         [-4.9250e-01, -3.9705e-01,  1.8587e-01,  ..., -9.8828e-02,
           3.3473e-01,  3.6105e-01],
         [-7.0452e-01, -4.7636e-01, -6.0126e-02,  ...,  2.9102e-01,
           2.1736e-02,  7.7821e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ¦ T_txt=22
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 22, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 22, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 22, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 22])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 22, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 22, 64])
ğŸŸ¦ out.shape=torch.Size([3, 22, 512])
ğŸŸ¦ out.shape=torch.Size([3, 22, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 22, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 22, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.8058,  0.7302, -1.0989,  ...,  3.8324,  2.7810,  1.7821],
         [-0.7038, -0.6393, -0.6297,  ..., -0.0359,  0.1719, -0.3344],
         [-0.1649, -0.7010, -0.9241,  ...,  0.5318,  0.1623, -0.1670],
         ...,
         [-0.1391, -0.8753,  0.2839,  ...,  0.3533,  0.0579, -0.6393],
         [-0.6376, -0.3177, -0.2238,  ..., -0.7059,  0.4351,  0.1451],
         [-0.7060, -0.5439,  0.1309,  ..., -0.2375,  0.0102,  0.6080]],

        [[-4.8058,  0.7302, -1.0989,  ...,  3.8324,  2.7810,  1.7821],
         [-0.7038, -0.6393, -0.6297,  ..., -0.0359,  0.1719, -0.3344],
         [-0.1649, -0.7010, -0.9241,  ...,  0.5318,  0.1623, -0.1670],
         ...,
         [-0.1391, -0.8753,  0.2839,  ...,  0.3533,  0.0579, -0.6393],
         [-0.6376, -0.3177, -0.2238,  ..., -0.7059,  0.4351,  0.1451],
         [-0.3922,  0.0939, -0.3508,  ..., -0.0926,  0.0155, -0.5093]],

        [[-4.8058,  0.7302, -1.0989,  ...,  3.8324,  2.7810,  1.7821],
         [-0.7038, -0.6393, -0.6297,  ..., -0.0359,  0.1719, -0.3344],
         [-0.1649, -0.7010, -0.9241,  ...,  0.5318,  0.1623, -0.1670],
         ...,
         [-0.1391, -0.8753,  0.2839,  ...,  0.3533,  0.0579, -0.6393],
         [-0.6376, -0.3177, -0.2238,  ..., -0.7059,  0.4351,  0.1451],
         [-0.7927, -0.7673, -0.2881,  ..., -0.1545,  0.2104,  0.6852]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ¦ T_txt=22
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 22, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 22, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 22, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 22])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 22, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 22, 64])
ğŸŸ¦ out.shape=torch.Size([3, 22, 512])
ğŸŸ¦ out.shape=torch.Size([3, 22, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 22, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 22, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.5423,  0.4867, -1.3078,  ...,  4.0570,  2.7591,  1.7055],
         [-0.7944, -1.0986, -0.8873,  ..., -0.3006, -0.1496, -0.3139],
         [ 0.3003, -0.6765, -0.9426,  ...,  0.2994,  0.2125, -0.2227],
         ...,
         [ 0.3279, -0.9457, -0.1564,  ...,  0.5173,  0.3617, -0.5718],
         [-0.6745, -0.0524, -0.9399,  ..., -0.6166,  0.3006, -0.1860],
         [-0.6692, -0.5936, -0.6865,  ..., -0.2726,  0.2328,  0.2570]],

        [[-4.5423,  0.4867, -1.3078,  ...,  4.0570,  2.7591,  1.7055],
         [-0.7944, -1.0986, -0.8873,  ..., -0.3006, -0.1496, -0.3139],
         [ 0.3003, -0.6765, -0.9426,  ...,  0.2994,  0.2125, -0.2227],
         ...,
         [ 0.3279, -0.9457, -0.1564,  ...,  0.5173,  0.3617, -0.5718],
         [-0.6745, -0.0524, -0.9399,  ..., -0.6166,  0.3006, -0.1860],
         [-0.6283,  0.1323, -0.8518,  ..., -0.2223,  0.1371, -0.7421]],

        [[-4.5423,  0.4867, -1.3078,  ...,  4.0570,  2.7591,  1.7055],
         [-0.7944, -1.0986, -0.8873,  ..., -0.3006, -0.1496, -0.3139],
         [ 0.3003, -0.6765, -0.9426,  ...,  0.2994,  0.2125, -0.2227],
         ...,
         [ 0.3279, -0.9457, -0.1564,  ...,  0.5173,  0.3617, -0.5718],
         [-0.6745, -0.0524, -0.9399,  ..., -0.6166,  0.3006, -0.1860],
         [-0.8460, -0.9213, -0.9959,  ..., -0.2556,  0.3351,  0.3685]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ¦ T_txt=22
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 22, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 22, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 22, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 22])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 22, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 22, 64])
ğŸŸ¦ out.shape=torch.Size([3, 22, 512])
ğŸŸ¦ out.shape=torch.Size([3, 22, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 22, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 22, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.4194,  0.4068, -1.0771,  ...,  4.0394,  2.7712,  1.5921],
         [-1.0025, -1.3143, -1.0197,  ..., -0.7655, -0.0488, -0.4858],
         [ 0.0073, -0.6469, -0.9511,  ...,  0.0354,  0.6350,  0.2235],
         ...,
         [ 0.1066, -1.0839, -0.3253,  ...,  0.2411,  0.8854, -0.7035],
         [-0.7279,  0.0073, -0.7943,  ..., -0.6395,  0.7086, -0.1990],
         [-0.9102, -0.4974, -0.5201,  ...,  0.0245,  0.5392,  0.1246]],

        [[-4.4194,  0.4068, -1.0771,  ...,  4.0394,  2.7712,  1.5921],
         [-1.0025, -1.3143, -1.0197,  ..., -0.7655, -0.0488, -0.4858],
         [ 0.0073, -0.6469, -0.9511,  ...,  0.0354,  0.6350,  0.2235],
         ...,
         [ 0.1066, -1.0839, -0.3253,  ...,  0.2411,  0.8854, -0.7035],
         [-0.7279,  0.0073, -0.7943,  ..., -0.6395,  0.7086, -0.1990],
         [-0.5798,  0.3248, -0.8516,  ..., -0.0990,  0.6703, -0.9285]],

        [[-4.4194,  0.4068, -1.0771,  ...,  4.0394,  2.7712,  1.5921],
         [-1.0025, -1.3143, -1.0197,  ..., -0.7654, -0.0488, -0.4858],
         [ 0.0073, -0.6469, -0.9511,  ...,  0.0354,  0.6350,  0.2235],
         ...,
         [ 0.1066, -1.0839, -0.3253,  ...,  0.2411,  0.8854, -0.7035],
         [-0.7279,  0.0073, -0.7943,  ..., -0.6395,  0.7086, -0.1990],
         [-0.9273, -0.9649, -0.7816,  ...,  0.0384,  0.9091,  0.0981]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ¦ T_txt=22
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 22, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 22, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 22, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 22])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 22, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 22, 64])
ğŸŸ¦ out.shape=torch.Size([3, 22, 512])
ğŸŸ¦ out.shape=torch.Size([3, 22, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 22, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 22, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.6486,  0.4370, -1.0679,  ...,  4.0760,  2.7873,  1.4896],
         [-0.9182, -1.6641, -0.8037,  ..., -1.0706, -0.0978,  0.0856],
         [-0.3296, -1.1621, -1.2796,  ..., -0.3973,  0.5544,  0.2346],
         ...,
         [-0.6062, -1.6136, -0.5444,  ...,  0.2676,  0.6767, -0.6523],
         [-1.6143,  0.0609, -0.3366,  ..., -0.3927,  0.6869, -0.1472],
         [-1.7840, -0.4746, -0.2996,  ...,  0.7651,  0.4493,  0.4203]],

        [[-4.6486,  0.4370, -1.0679,  ...,  4.0760,  2.7873,  1.4896],
         [-0.9182, -1.6641, -0.8037,  ..., -1.0706, -0.0978,  0.0856],
         [-0.3296, -1.1621, -1.2796,  ..., -0.3973,  0.5544,  0.2346],
         ...,
         [-0.6062, -1.6136, -0.5444,  ...,  0.2676,  0.6767, -0.6523],
         [-1.6143,  0.0609, -0.3366,  ..., -0.3927,  0.6869, -0.1472],
         [-1.8375,  0.3271, -0.4510,  ...,  0.4644,  0.5750, -0.6263]],

        [[-4.6486,  0.4370, -1.0679,  ...,  4.0760,  2.7874,  1.4896],
         [-0.9182, -1.6641, -0.8037,  ..., -1.0706, -0.0978,  0.0856],
         [-0.3296, -1.1621, -1.2796,  ..., -0.3973,  0.5544,  0.2346],
         ...,
         [-0.6062, -1.6136, -0.5444,  ...,  0.2676,  0.6767, -0.6523],
         [-1.6143,  0.0609, -0.3367,  ..., -0.3927,  0.6869, -0.1472],
         [-1.8880, -0.9903, -0.5595,  ...,  0.8453,  0.5977,  0.3093]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ¦ T_txt=22
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 22, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 22, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 22, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 22])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 22, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 22, 64])
ğŸŸ¦ out.shape=torch.Size([3, 22, 512])
ğŸŸ¦ out.shape=torch.Size([3, 22, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 22, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 22, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.6982,  0.6115, -1.1511,  ...,  3.9602,  2.6816,  1.0754],
         [-0.8318, -2.6615, -1.2791,  ..., -1.1889,  0.2650, -0.4843],
         [-0.0270, -1.6365, -1.4973,  ..., -0.5320,  0.8756,  0.4654],
         ...,
         [-0.7566, -1.3210, -0.7751,  ...,  0.3029,  0.7884, -0.8653],
         [-1.3130,  0.1763, -0.6732,  ..., -0.1909,  0.6826, -0.5629],
         [-1.0176, -0.0554, -0.8662,  ...,  1.2393,  0.3358,  0.2461]],

        [[-4.6982,  0.6115, -1.1511,  ...,  3.9602,  2.6816,  1.0754],
         [-0.8318, -2.6615, -1.2791,  ..., -1.1889,  0.2650, -0.4843],
         [-0.0270, -1.6365, -1.4973,  ..., -0.5320,  0.8756,  0.4654],
         ...,
         [-0.7566, -1.3210, -0.7751,  ...,  0.3029,  0.7884, -0.8653],
         [-1.3130,  0.1763, -0.6732,  ..., -0.1909,  0.6826, -0.5629],
         [-1.1829,  0.4788, -1.3613,  ...,  0.3685,  0.6476, -0.8746]],

        [[-4.6982,  0.6115, -1.1511,  ...,  3.9602,  2.6816,  1.0754],
         [-0.8318, -2.6615, -1.2791,  ..., -1.1889,  0.2650, -0.4843],
         [-0.0270, -1.6365, -1.4973,  ..., -0.5320,  0.8756,  0.4654],
         ...,
         [-0.7566, -1.3210, -0.7751,  ...,  0.3029,  0.7884, -0.8653],
         [-1.3130,  0.1763, -0.6732,  ..., -0.1909,  0.6826, -0.5629],
         [-0.9543, -0.9874, -1.3691,  ...,  1.2388,  0.5839, -0.1599]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ¦ T_txt=22
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 22, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 22, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 22, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 22])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 22, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 22, 64])
ğŸŸ¦ out.shape=torch.Size([3, 22, 512])
ğŸŸ¦ out.shape=torch.Size([3, 22, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 22, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 22, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.1992e+00,  1.0861e-01, -1.3292e+00,  ...,  4.5845e+00,
           3.1037e+00,  6.4127e-01],
         [-1.7888e+00, -3.0735e+00, -9.0352e-01,  ..., -6.4027e-01,
          -3.6426e-01, -1.2033e-01],
         [ 6.7153e-01, -1.5127e+00, -1.2408e+00,  ...,  3.2038e-01,
           1.0818e+00,  3.0631e-01],
         ...,
         [-9.9808e-02, -1.3933e+00, -4.8086e-01,  ...,  1.4542e+00,
           1.4927e+00, -1.2638e+00],
         [-1.3948e+00,  1.2983e-01, -3.0708e-01,  ...,  9.0817e-02,
           1.7694e-01, -6.3714e-01],
         [-1.2233e+00,  7.7007e-03, -9.8320e-01,  ...,  1.7667e+00,
           1.6642e-04,  4.6981e-01]],

        [[-4.1992e+00,  1.0861e-01, -1.3292e+00,  ...,  4.5845e+00,
           3.1037e+00,  6.4127e-01],
         [-1.7888e+00, -3.0735e+00, -9.0352e-01,  ..., -6.4027e-01,
          -3.6426e-01, -1.2033e-01],
         [ 6.7153e-01, -1.5127e+00, -1.2408e+00,  ...,  3.2038e-01,
           1.0818e+00,  3.0631e-01],
         ...,
         [-9.9807e-02, -1.3933e+00, -4.8086e-01,  ...,  1.4542e+00,
           1.4927e+00, -1.2638e+00],
         [-1.3948e+00,  1.2983e-01, -3.0708e-01,  ...,  9.0818e-02,
           1.7694e-01, -6.3714e-01],
         [-1.1927e+00,  4.4982e-01, -1.2152e+00,  ...,  5.4608e-01,
           2.8118e-03, -8.2147e-01]],

        [[-4.1992e+00,  1.0861e-01, -1.3292e+00,  ...,  4.5845e+00,
           3.1037e+00,  6.4127e-01],
         [-1.7888e+00, -3.0735e+00, -9.0352e-01,  ..., -6.4027e-01,
          -3.6426e-01, -1.2033e-01],
         [ 6.7153e-01, -1.5127e+00, -1.2408e+00,  ...,  3.2038e-01,
           1.0818e+00,  3.0631e-01],
         ...,
         [-9.9808e-02, -1.3933e+00, -4.8086e-01,  ...,  1.4542e+00,
           1.4927e+00, -1.2638e+00],
         [-1.3948e+00,  1.2983e-01, -3.0708e-01,  ...,  9.0817e-02,
           1.7694e-01, -6.3715e-01],
         [-9.5021e-01, -6.1833e-01, -1.4299e+00,  ...,  1.7722e+00,
           2.7957e-01, -1.1463e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ¦ T_txt=22
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 22, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 22, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 22, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 22])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 22, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 22, 64])
ğŸŸ¦ out.shape=torch.Size([3, 22, 512])
ğŸŸ¦ out.shape=torch.Size([3, 22, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 22, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 22, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-3.4956, -0.4549, -1.3173,  ...,  5.3489,  3.8643,  0.0495],
         [-1.1846, -2.7309, -0.3251,  ..., -0.5469, -0.2345,  0.0928],
         [ 0.3590, -0.8857, -1.3176,  ...,  0.7098,  1.7219,  0.2027],
         ...,
         [-0.2198, -0.9331, -1.0763,  ...,  1.8544,  2.3436, -1.4822],
         [-0.7701,  0.4790, -0.4627,  ...,  0.6082,  1.0008, -1.0690],
         [-0.3139,  0.4464, -0.5054,  ...,  2.4753,  0.8644,  0.2732]],

        [[-3.4956, -0.4549, -1.3173,  ...,  5.3489,  3.8643,  0.0495],
         [-1.1846, -2.7309, -0.3251,  ..., -0.5469, -0.2345,  0.0928],
         [ 0.3590, -0.8857, -1.3176,  ...,  0.7098,  1.7219,  0.2027],
         ...,
         [-0.2198, -0.9331, -1.0763,  ...,  1.8544,  2.3436, -1.4822],
         [-0.7701,  0.4790, -0.4627,  ...,  0.6082,  1.0008, -1.0690],
         [-0.4583,  0.3666, -1.1747,  ...,  1.3708,  1.1463, -1.1482]],

        [[-3.4956, -0.4549, -1.3173,  ...,  5.3489,  3.8643,  0.0495],
         [-1.1846, -2.7309, -0.3251,  ..., -0.5469, -0.2345,  0.0928],
         [ 0.3590, -0.8857, -1.3176,  ...,  0.7098,  1.7219,  0.2027],
         ...,
         [-0.2198, -0.9331, -1.0763,  ...,  1.8544,  2.3437, -1.4822],
         [-0.7701,  0.4790, -0.4627,  ...,  0.6082,  1.0008, -1.0690],
         [-0.6122, -0.1560, -1.4754,  ...,  2.5555,  1.4248, -0.3558]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ¦ T_txt=22
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 22, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 22, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 22, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 22])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 22, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 22, 64])
ğŸŸ¦ out.shape=torch.Size([3, 22, 512])
ğŸŸ¦ out.shape=torch.Size([3, 22, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 22, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 22, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-2.3185, -1.3191, -1.7786,  ...,  8.3678,  3.3047, -0.5910],
         [-0.8119, -3.2357, -0.0329,  ...,  1.3220, -0.3964,  0.9723],
         [ 0.6821, -0.7940, -0.2673,  ...,  3.2716,  1.7577,  0.8690],
         ...,
         [ 0.0433, -1.1789, -0.6269,  ...,  4.0073,  2.5114, -0.7028],
         [-0.5466, -0.3479, -0.8769,  ...,  3.6395, -0.0427, -0.5646],
         [-1.2651, -0.5760, -0.2561,  ...,  5.3449, -0.6345,  0.3618]],

        [[-2.3185, -1.3191, -1.7786,  ...,  8.3678,  3.3047, -0.5910],
         [-0.8119, -3.2357, -0.0329,  ...,  1.3220, -0.3964,  0.9723],
         [ 0.6821, -0.7940, -0.2673,  ...,  3.2716,  1.7577,  0.8690],
         ...,
         [ 0.0433, -1.1789, -0.6269,  ...,  4.0073,  2.5114, -0.7028],
         [-0.5466, -0.3479, -0.8769,  ...,  3.6395, -0.0427, -0.5646],
         [-0.7256, -0.6420, -0.6707,  ...,  4.4103,  0.0997, -0.6675]],

        [[-2.3185, -1.3191, -1.7786,  ...,  8.3678,  3.3047, -0.5910],
         [-0.8119, -3.2357, -0.0329,  ...,  1.3220, -0.3964,  0.9723],
         [ 0.6821, -0.7940, -0.2673,  ...,  3.2716,  1.7577,  0.8690],
         ...,
         [ 0.0433, -1.1789, -0.6269,  ...,  4.0073,  2.5114, -0.7028],
         [-0.5466, -0.3479, -0.8769,  ...,  3.6395, -0.0427, -0.5646],
         [-1.5712, -0.8342, -1.2580,  ...,  5.5036,  0.1635, -0.4738]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 22, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 22]), use_cached_media=False
ğŸŸ¦ T_txt=22
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 22, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 22, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 22, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 22])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 22, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 22, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 22, 64])
ğŸŸ¦ out.shape=torch.Size([3, 22, 512])
ğŸŸ¦ out.shape=torch.Size([3, 22, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 22, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 22, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 22, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-1.2009, -0.4256,  0.9579,  ...,  3.0081,  1.0086, -0.1812],
         [-0.2749, -1.1022, -0.6093,  ...,  1.7677, -1.5354, -0.1590],
         [ 0.9989,  0.1369, -0.1196,  ...,  5.2063,  0.3365, -0.3707],
         ...,
         [-0.4515, -1.1408, -0.7140,  ...,  6.3310,  1.6319, -1.8021],
         [-0.8508, -0.5504, -0.4473,  ...,  6.0300, -0.6670, -1.1407],
         [-2.0599, -0.3107,  0.2120,  ...,  6.8373, -1.3011, -1.2283]],

        [[-1.2009, -0.4256,  0.9579,  ...,  3.0081,  1.0086, -0.1812],
         [-0.2749, -1.1022, -0.6093,  ...,  1.7677, -1.5354, -0.1590],
         [ 0.9989,  0.1369, -0.1196,  ...,  5.2063,  0.3365, -0.3707],
         ...,
         [-0.4515, -1.1408, -0.7140,  ...,  6.3310,  1.6319, -1.8021],
         [-0.8508, -0.5504, -0.4473,  ...,  6.0300, -0.6670, -1.1407],
         [-1.5641, -0.6479,  0.0385,  ...,  5.9044, -0.2900, -1.1607]],

        [[-1.2009, -0.4256,  0.9579,  ...,  3.0081,  1.0086, -0.1812],
         [-0.2749, -1.1022, -0.6093,  ...,  1.7677, -1.5354, -0.1590],
         [ 0.9989,  0.1369, -0.1195,  ...,  5.2063,  0.3365, -0.3707],
         ...,
         [-0.4515, -1.1408, -0.7140,  ...,  6.3310,  1.6319, -1.8021],
         [-0.8508, -0.5504, -0.4473,  ...,  6.0300, -0.6670, -1.1407],
         [-2.5447, -0.2420, -0.8022,  ...,  6.9380, -0.7304, -1.9989]]]), None)
ğŸŸ© FlamingoLMMixinã®é †ä¼æ’­å®Œäº†
ğŸŸ© FlamingoLMMixinã®é †ä¼æ’­é–‹å§‹ input_ids.shape=torch.Size([3, 23]), input_ids.dtype=torch.int64, None if attention_mask is None else attention_mask.shape=torch.Size([3, 23]), dict_keys(['prefix_mask', 'sequence_id', 'past_key_values', 'use_cache', 'return_dict'])
ğŸŸ¦ media_locations.shape=torch.Size([3, 23]), media_locations.dtype=torch.bool
ğŸŸ¦ use_cached_media_locations=False
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ¦ T_txt=23
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 23, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 23, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 23, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 23])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 23, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 23, 64])
ğŸŸ¦ out.shape=torch.Size([3, 23, 512])
ğŸŸ¦ out.shape=torch.Size([3, 23, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 23, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 23, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-2.0925e-01, -5.9118e-02,  6.5251e-02,  ...,  4.1091e-01,
          -3.5243e-01,  3.7260e-01],
         [-1.7433e-02, -1.4965e-01,  3.6832e-02,  ...,  1.0424e-01,
           3.2264e-03,  4.7463e-01],
         [-1.9068e-02, -1.3694e-01, -1.2874e-01,  ...,  1.6081e-01,
          -1.5760e-01,  1.9950e-01],
         ...,
         [ 2.5405e-02, -1.5146e-01,  3.8443e-02,  ..., -8.5981e-02,
           4.6477e-04,  3.0404e-01],
         [ 2.9948e-02, -1.0168e-02, -6.5073e-02,  ...,  1.2525e-01,
          -1.2270e-02,  2.5134e-01],
         [ 2.4382e-02,  4.6793e-02,  4.2986e-01,  ...,  6.5511e-02,
          -7.4303e-02,  4.5366e-01]],

        [[-2.0925e-01, -5.9118e-02,  6.5251e-02,  ...,  4.1091e-01,
          -3.5243e-01,  3.7260e-01],
         [-1.7433e-02, -1.4965e-01,  3.6832e-02,  ...,  1.0424e-01,
           3.2264e-03,  4.7463e-01],
         [-1.9068e-02, -1.3694e-01, -1.2874e-01,  ...,  1.6081e-01,
          -1.5760e-01,  1.9950e-01],
         ...,
         [ 2.5405e-02, -1.5146e-01,  3.8443e-02,  ..., -8.5981e-02,
           4.6477e-04,  3.0404e-01],
         [ 2.9948e-02, -1.0168e-02, -6.5073e-02,  ...,  1.2525e-01,
          -1.2270e-02,  2.5134e-01],
         [-5.5688e-02,  6.8127e-02,  4.8199e-01,  ..., -3.1098e-02,
          -3.7724e-01,  7.1877e-01]],

        [[-2.0925e-01, -5.9117e-02,  6.5251e-02,  ...,  4.1091e-01,
          -3.5243e-01,  3.7260e-01],
         [-1.7433e-02, -1.4965e-01,  3.6832e-02,  ...,  1.0424e-01,
           3.2265e-03,  4.7463e-01],
         [-1.9068e-02, -1.3694e-01, -1.2874e-01,  ...,  1.6081e-01,
          -1.5760e-01,  1.9950e-01],
         ...,
         [ 2.5405e-02, -1.5146e-01,  3.8443e-02,  ..., -8.5981e-02,
           4.6475e-04,  3.0404e-01],
         [ 2.9948e-02, -1.0168e-02, -6.5073e-02,  ...,  1.2525e-01,
          -1.2270e-02,  2.5134e-01],
         [-4.2961e-02,  1.5962e-02,  8.8459e-02,  ...,  1.4490e-01,
          -2.7009e-01,  3.2329e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ¦ T_txt=23
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 23, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 23, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 23, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 23])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 23, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 23, 64])
ğŸŸ¦ out.shape=torch.Size([3, 23, 512])
ğŸŸ¦ out.shape=torch.Size([3, 23, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 23, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 23, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-0.0762, -0.3746,  0.1300,  ...,  0.1017, -0.0332,  0.2191],
         [-0.0236, -0.1139, -0.0499,  ...,  0.0464,  0.0973,  0.4798],
         [ 0.0476, -0.1903,  0.0666,  ..., -0.0123, -0.0800,  0.3086],
         ...,
         [ 0.0278, -0.1336, -0.0075,  ..., -0.1681, -0.0534,  0.5033],
         [ 0.0278,  0.0493, -0.0914,  ...,  0.1708, -0.1178,  0.4907],
         [-0.0708,  0.0919,  0.6011,  ...,  0.0187, -0.1797,  0.5978]],

        [[-0.0762, -0.3746,  0.1300,  ...,  0.1017, -0.0332,  0.2191],
         [-0.0236, -0.1139, -0.0499,  ...,  0.0464,  0.0973,  0.4798],
         [ 0.0476, -0.1903,  0.0666,  ..., -0.0123, -0.0800,  0.3086],
         ...,
         [ 0.0278, -0.1336, -0.0075,  ..., -0.1681, -0.0534,  0.5033],
         [ 0.0278,  0.0493, -0.0914,  ...,  0.1708, -0.1178,  0.4907],
         [ 0.1335,  0.0972,  0.4912,  ..., -0.0506, -0.4505,  0.8139]],

        [[-0.0762, -0.3746,  0.1300,  ...,  0.1017, -0.0332,  0.2191],
         [-0.0236, -0.1139, -0.0499,  ...,  0.0464,  0.0973,  0.4798],
         [ 0.0476, -0.1903,  0.0666,  ..., -0.0123, -0.0800,  0.3086],
         ...,
         [ 0.0278, -0.1336, -0.0075,  ..., -0.1681, -0.0534,  0.5033],
         [ 0.0278,  0.0493, -0.0914,  ...,  0.1708, -0.1178,  0.4907],
         [ 0.0833,  0.0445,  0.0383,  ...,  0.0544, -0.3543,  0.4273]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ¦ T_txt=23
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 23, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 23, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 23, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 23])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 23, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 23, 64])
ğŸŸ¦ out.shape=torch.Size([3, 23, 512])
ğŸŸ¦ out.shape=torch.Size([3, 23, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 23, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 23, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-0.0423, -0.4800,  0.0985,  ..., -0.1247,  0.1871, -0.2268],
         [-0.0501, -0.1131, -0.1332,  ...,  0.1946,  0.1566,  0.3318],
         [-0.0369, -0.1714,  0.2051,  ...,  0.1376, -0.1982,  0.2490],
         ...,
         [-0.0864, -0.1342,  0.0755,  ..., -0.1099, -0.0017,  0.3514],
         [ 0.0585,  0.1236, -0.0072,  ...,  0.1960, -0.0054,  0.3329],
         [ 0.0758, -0.1454,  0.6495,  ..., -0.1463, -0.0908,  0.5520]],

        [[-0.0423, -0.4800,  0.0985,  ..., -0.1247,  0.1871, -0.2268],
         [-0.0501, -0.1131, -0.1332,  ...,  0.1946,  0.1566,  0.3318],
         [-0.0369, -0.1714,  0.2051,  ...,  0.1376, -0.1982,  0.2490],
         ...,
         [-0.0864, -0.1342,  0.0755,  ..., -0.1099, -0.0017,  0.3514],
         [ 0.0585,  0.1236, -0.0072,  ...,  0.1960, -0.0054,  0.3329],
         [ 0.2737, -0.1982,  0.2150,  ..., -0.0381, -0.3880,  0.8100]],

        [[-0.0423, -0.4800,  0.0985,  ..., -0.1247,  0.1871, -0.2268],
         [-0.0501, -0.1131, -0.1332,  ...,  0.1946,  0.1566,  0.3318],
         [-0.0369, -0.1714,  0.2051,  ...,  0.1376, -0.1982,  0.2490],
         ...,
         [-0.0864, -0.1342,  0.0755,  ..., -0.1099, -0.0017,  0.3514],
         [ 0.0585,  0.1236, -0.0072,  ...,  0.1960, -0.0054,  0.3329],
         [ 0.3162, -0.3469, -0.0568,  ...,  0.0922, -0.3327,  0.1896]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ¦ T_txt=23
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 23, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 23, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 23, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 23])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 23, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 23, 64])
ğŸŸ¦ out.shape=torch.Size([3, 23, 512])
ğŸŸ¦ out.shape=torch.Size([3, 23, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 23, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 23, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-0.6808, -0.0752, -0.2681,  ..., -0.1388, -0.2275, -0.2143],
         [-0.2353, -0.1768, -0.1707,  ...,  0.0178,  0.0832,  0.2217],
         [ 0.1139, -0.0718,  0.1118,  ...,  0.0826, -0.0978,  0.2029],
         ...,
         [ 0.0567,  0.0876,  0.0517,  ...,  0.0078, -0.1083,  0.5091],
         [-0.0029,  0.1539,  0.0426,  ...,  0.1117,  0.0696,  0.2327],
         [ 0.2183, -0.0785,  0.6720,  ..., -0.0715, -0.3156,  0.3742]],

        [[-0.6808, -0.0752, -0.2681,  ..., -0.1388, -0.2275, -0.2143],
         [-0.2353, -0.1768, -0.1707,  ...,  0.0178,  0.0832,  0.2217],
         [ 0.1139, -0.0718,  0.1118,  ...,  0.0826, -0.0978,  0.2029],
         ...,
         [ 0.0567,  0.0876,  0.0517,  ...,  0.0078, -0.1083,  0.5091],
         [-0.0029,  0.1539,  0.0426,  ...,  0.1117,  0.0696,  0.2327],
         [ 0.3311, -0.3437,  0.3384,  ...,  0.0665, -0.5832,  0.6978]],

        [[-0.6808, -0.0752, -0.2681,  ..., -0.1388, -0.2275, -0.2143],
         [-0.2353, -0.1768, -0.1707,  ...,  0.0178,  0.0832,  0.2217],
         [ 0.1139, -0.0718,  0.1118,  ...,  0.0826, -0.0978,  0.2029],
         ...,
         [ 0.0567,  0.0876,  0.0517,  ...,  0.0078, -0.1083,  0.5091],
         [-0.0029,  0.1539,  0.0426,  ...,  0.1117,  0.0696,  0.2327],
         [ 0.2828, -0.3943, -0.2090,  ...,  0.0794, -0.7080,  0.3038]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ¦ T_txt=23
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 23, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 23, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 23, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 23])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 23, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 23, 64])
ğŸŸ¦ out.shape=torch.Size([3, 23, 512])
ğŸŸ¦ out.shape=torch.Size([3, 23, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 23, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 23, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.0310e+00,  7.9414e-01, -1.4750e+00,  ...,  3.6145e-01,
           1.5208e+00, -2.4390e-01],
         [-5.7247e-01, -9.2225e-02, -2.4184e-01,  ...,  5.1393e-02,
           3.1086e-02,  2.4566e-01],
         [ 6.8574e-02, -5.9338e-02,  1.0359e-01,  ...,  5.0657e-02,
           1.8189e-01,  4.9062e-02],
         ...,
         [ 5.8634e-04,  7.3301e-02, -2.1840e-01,  ...,  5.6920e-02,
           5.3535e-02,  3.7094e-01],
         [-4.4851e-02,  1.2006e-01, -6.3868e-02,  ...,  6.3939e-02,
          -7.4924e-02,  3.2249e-01],
         [ 1.2980e-01, -1.4095e-01,  5.9571e-01,  ..., -3.7816e-02,
          -3.6397e-01,  2.1442e-01]],

        [[-4.0310e+00,  7.9414e-01, -1.4750e+00,  ...,  3.6145e-01,
           1.5208e+00, -2.4390e-01],
         [-5.7247e-01, -9.2225e-02, -2.4184e-01,  ...,  5.1393e-02,
           3.1086e-02,  2.4566e-01],
         [ 6.8574e-02, -5.9338e-02,  1.0359e-01,  ...,  5.0657e-02,
           1.8189e-01,  4.9062e-02],
         ...,
         [ 5.8634e-04,  7.3301e-02, -2.1840e-01,  ...,  5.6920e-02,
           5.3535e-02,  3.7094e-01],
         [-4.4851e-02,  1.2006e-01, -6.3868e-02,  ...,  6.3939e-02,
          -7.4924e-02,  3.2249e-01],
         [ 1.5532e-01, -5.3546e-01,  3.0481e-01,  ..., -3.2268e-02,
          -6.5266e-01,  4.1530e-01]],

        [[-4.0310e+00,  7.9414e-01, -1.4750e+00,  ...,  3.6145e-01,
           1.5208e+00, -2.4390e-01],
         [-5.7247e-01, -9.2225e-02, -2.4184e-01,  ...,  5.1394e-02,
           3.1086e-02,  2.4566e-01],
         [ 6.8573e-02, -5.9338e-02,  1.0359e-01,  ...,  5.0657e-02,
           1.8189e-01,  4.9062e-02],
         ...,
         [ 5.8629e-04,  7.3301e-02, -2.1840e-01,  ...,  5.6920e-02,
           5.3535e-02,  3.7094e-01],
         [-4.4851e-02,  1.2006e-01, -6.3868e-02,  ...,  6.3939e-02,
          -7.4924e-02,  3.2249e-01],
         [ 1.4056e-01, -3.3304e-01, -3.0574e-01,  ...,  2.1111e-01,
          -6.1058e-01,  2.0166e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ¦ T_txt=23
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 23, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 23, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 23, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 23])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 23, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 23, 64])
ğŸŸ¦ out.shape=torch.Size([3, 23, 512])
ğŸŸ¦ out.shape=torch.Size([3, 23, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 23, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 23, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.7946e+00,  9.0221e-01, -1.2882e+00,  ...,  1.1832e+00,
           2.5226e+00, -5.9823e-02],
         [-5.6193e-01, -1.5785e-01, -2.8558e-01,  ..., -3.8618e-02,
          -1.3091e-02,  1.2509e-01],
         [ 4.1306e-03, -1.2649e-01, -2.6289e-01,  ...,  2.2804e-01,
          -9.2657e-02,  5.5102e-03],
         ...,
         [-4.1566e-01,  2.0328e-01, -1.5304e-01,  ...,  7.1609e-02,
           2.6326e-02,  3.2153e-01],
         [-2.1025e-01,  3.5201e-02,  2.9223e-02,  ...,  3.3373e-01,
           3.1496e-02,  9.7370e-02],
         [ 1.5137e-01, -3.1456e-01,  6.1986e-01,  ..., -1.8698e-01,
          -4.2912e-01,  3.1011e-01]],

        [[-4.7946e+00,  9.0221e-01, -1.2882e+00,  ...,  1.1832e+00,
           2.5226e+00, -5.9823e-02],
         [-5.6193e-01, -1.5785e-01, -2.8558e-01,  ..., -3.8618e-02,
          -1.3091e-02,  1.2509e-01],
         [ 4.1306e-03, -1.2649e-01, -2.6289e-01,  ...,  2.2804e-01,
          -9.2657e-02,  5.5102e-03],
         ...,
         [-4.1566e-01,  2.0328e-01, -1.5304e-01,  ...,  7.1609e-02,
           2.6326e-02,  3.2153e-01],
         [-2.1025e-01,  3.5201e-02,  2.9223e-02,  ...,  3.3373e-01,
           3.1496e-02,  9.7370e-02],
         [ 9.5321e-02, -6.5955e-01,  6.1281e-01,  ..., -3.5334e-01,
          -8.4627e-01,  7.3372e-01]],

        [[-4.7946e+00,  9.0221e-01, -1.2882e+00,  ...,  1.1832e+00,
           2.5226e+00, -5.9824e-02],
         [-5.6193e-01, -1.5785e-01, -2.8558e-01,  ..., -3.8618e-02,
          -1.3092e-02,  1.2509e-01],
         [ 4.1305e-03, -1.2649e-01, -2.6289e-01,  ...,  2.2804e-01,
          -9.2657e-02,  5.5096e-03],
         ...,
         [-4.1566e-01,  2.0328e-01, -1.5304e-01,  ...,  7.1609e-02,
           2.6326e-02,  3.2153e-01],
         [-2.1025e-01,  3.5201e-02,  2.9223e-02,  ...,  3.3373e-01,
           3.1496e-02,  9.7370e-02],
         [-1.4386e-01, -3.2294e-01, -1.2232e-01,  ...,  2.8410e-02,
          -7.8617e-01,  2.1850e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ¦ T_txt=23
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 23, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 23, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 23, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 23])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 23, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 23, 64])
ğŸŸ¦ out.shape=torch.Size([3, 23, 512])
ğŸŸ¦ out.shape=torch.Size([3, 23, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 23, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 23, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.2771e+00,  1.3169e+00, -1.5839e+00,  ...,  1.5235e+00,
           2.5618e+00,  3.0273e-01],
         [-5.1019e-01, -2.0753e-01, -3.9353e-01,  ..., -3.0973e-02,
           3.3680e-01,  1.5358e-01],
         [ 9.6702e-02, -5.6518e-01, -1.5635e-01,  ...,  8.8999e-03,
           7.6486e-02, -5.2470e-03],
         ...,
         [-2.2878e-01,  2.1636e-01, -6.4801e-03,  ...,  9.7470e-02,
           1.7168e-01,  1.4387e-01],
         [-1.3436e-01,  1.5734e-01, -2.1990e-01,  ...,  4.6067e-01,
           1.1024e-01,  1.8483e-01],
         [ 3.8801e-01, -2.2128e-01,  7.5257e-01,  ..., -2.1136e-01,
          -2.9751e-02,  2.3278e-01]],

        [[-5.2771e+00,  1.3169e+00, -1.5839e+00,  ...,  1.5235e+00,
           2.5618e+00,  3.0273e-01],
         [-5.1019e-01, -2.0753e-01, -3.9353e-01,  ..., -3.0973e-02,
           3.3680e-01,  1.5358e-01],
         [ 9.6702e-02, -5.6518e-01, -1.5635e-01,  ...,  8.8999e-03,
           7.6486e-02, -5.2470e-03],
         ...,
         [-2.2878e-01,  2.1636e-01, -6.4801e-03,  ...,  9.7470e-02,
           1.7168e-01,  1.4387e-01],
         [-1.3436e-01,  1.5734e-01, -2.1990e-01,  ...,  4.6067e-01,
           1.1024e-01,  1.8483e-01],
         [ 4.7157e-01, -4.8962e-01,  7.7679e-01,  ..., -3.1238e-01,
          -5.8977e-01,  8.6680e-01]],

        [[-5.2771e+00,  1.3169e+00, -1.5839e+00,  ...,  1.5235e+00,
           2.5618e+00,  3.0273e-01],
         [-5.1019e-01, -2.0753e-01, -3.9353e-01,  ..., -3.0973e-02,
           3.3680e-01,  1.5358e-01],
         [ 9.6702e-02, -5.6518e-01, -1.5635e-01,  ...,  8.8999e-03,
           7.6486e-02, -5.2475e-03],
         ...,
         [-2.2878e-01,  2.1636e-01, -6.4801e-03,  ...,  9.7471e-02,
           1.7168e-01,  1.4387e-01],
         [-1.3436e-01,  1.5734e-01, -2.1990e-01,  ...,  4.6067e-01,
           1.1024e-01,  1.8483e-01],
         [ 1.0088e-01, -3.1944e-02, -1.4198e-01,  ...,  4.4620e-02,
          -3.4667e-01,  1.2706e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ¦ T_txt=23
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 23, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 23, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 23, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 23])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 23, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 23, 64])
ğŸŸ¦ out.shape=torch.Size([3, 23, 512])
ğŸŸ¦ out.shape=torch.Size([3, 23, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 23, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 23, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.3925e+00,  1.2785e+00, -1.7428e+00,  ...,  1.6187e+00,
           2.6666e+00,  6.3102e-01],
         [-7.2190e-01, -9.0366e-02, -3.7054e-01,  ..., -4.8731e-02,
           5.0303e-02,  4.0432e-02],
         [ 3.2142e-02, -5.6480e-01, -2.0480e-01,  ...,  6.2426e-02,
          -1.1226e-01,  5.0913e-03],
         ...,
         [-4.7935e-01,  1.4615e-01, -1.9178e-01,  ...,  1.2073e-01,
          -1.3311e-01,  8.5742e-02],
         [-2.0149e-01,  2.5538e-01,  1.1709e-04,  ...,  4.8664e-01,
          -3.3184e-01,  5.2587e-02],
         [ 3.1804e-01, -2.3715e-01,  5.9929e-01,  ...,  3.9292e-02,
          -1.5933e-01,  2.9268e-01]],

        [[-5.3925e+00,  1.2785e+00, -1.7428e+00,  ...,  1.6187e+00,
           2.6666e+00,  6.3102e-01],
         [-7.2190e-01, -9.0366e-02, -3.7054e-01,  ..., -4.8731e-02,
           5.0303e-02,  4.0432e-02],
         [ 3.2142e-02, -5.6480e-01, -2.0480e-01,  ...,  6.2426e-02,
          -1.1226e-01,  5.0913e-03],
         ...,
         [-4.7935e-01,  1.4615e-01, -1.9178e-01,  ...,  1.2073e-01,
          -1.3311e-01,  8.5742e-02],
         [-2.0149e-01,  2.5538e-01,  1.1709e-04,  ...,  4.8664e-01,
          -3.3184e-01,  5.2587e-02],
         [ 4.7406e-01, -5.4928e-01,  6.2735e-01,  ..., -7.1124e-02,
          -6.2055e-01,  7.8802e-01]],

        [[-5.3925e+00,  1.2785e+00, -1.7428e+00,  ...,  1.6187e+00,
           2.6666e+00,  6.3102e-01],
         [-7.2190e-01, -9.0366e-02, -3.7054e-01,  ..., -4.8731e-02,
           5.0304e-02,  4.0432e-02],
         [ 3.2142e-02, -5.6480e-01, -2.0480e-01,  ...,  6.2426e-02,
          -1.1226e-01,  5.0907e-03],
         ...,
         [-4.7935e-01,  1.4615e-01, -1.9178e-01,  ...,  1.2073e-01,
          -1.3311e-01,  8.5743e-02],
         [-2.0149e-01,  2.5538e-01,  1.1662e-04,  ...,  4.8664e-01,
          -3.3184e-01,  5.2587e-02],
         [-2.0534e-04,  6.3333e-02, -2.4701e-01,  ...,  7.2723e-02,
          -5.3024e-01,  8.4360e-02]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ¦ T_txt=23
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 23, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 23, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 23, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 23])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 23, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 23, 64])
ğŸŸ¦ out.shape=torch.Size([3, 23, 512])
ğŸŸ¦ out.shape=torch.Size([3, 23, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 23, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 23, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.7653e+00,  1.1008e+00, -1.8155e+00,  ...,  2.3020e+00,
           2.1681e+00,  1.0300e+00],
         [-6.6199e-01, -7.7735e-02, -5.1326e-01,  ..., -2.2643e-01,
           1.6844e-01, -1.5884e-02],
         [ 2.8691e-02, -6.1208e-01, -4.2365e-01,  ..., -2.2236e-01,
           9.9554e-02,  1.2917e-02],
         ...,
         [-2.3085e-01,  8.4811e-03, -2.7222e-01,  ..., -1.6294e-01,
           2.5832e-01, -6.2542e-02],
         [-3.2457e-02, -7.0138e-02,  9.0337e-02,  ...,  1.3302e-01,
          -1.7736e-01, -1.4500e-01],
         [ 2.3910e-01, -5.2146e-01,  5.6144e-01,  ..., -1.4774e-01,
          -1.7351e-01, -1.3320e-03]],

        [[-5.7653e+00,  1.1008e+00, -1.8155e+00,  ...,  2.3020e+00,
           2.1681e+00,  1.0300e+00],
         [-6.6199e-01, -7.7735e-02, -5.1326e-01,  ..., -2.2643e-01,
           1.6844e-01, -1.5884e-02],
         [ 2.8691e-02, -6.1208e-01, -4.2365e-01,  ..., -2.2236e-01,
           9.9554e-02,  1.2917e-02],
         ...,
         [-2.3085e-01,  8.4811e-03, -2.7222e-01,  ..., -1.6294e-01,
           2.5832e-01, -6.2542e-02],
         [-3.2457e-02, -7.0138e-02,  9.0337e-02,  ...,  1.3302e-01,
          -1.7736e-01, -1.4500e-01],
         [ 4.0329e-01, -6.2026e-01,  5.3886e-01,  ..., -5.2571e-01,
          -7.1158e-01,  5.5968e-01]],

        [[-5.7653e+00,  1.1008e+00, -1.8155e+00,  ...,  2.3020e+00,
           2.1681e+00,  1.0300e+00],
         [-6.6199e-01, -7.7735e-02, -5.1326e-01,  ..., -2.2643e-01,
           1.6844e-01, -1.5885e-02],
         [ 2.8692e-02, -6.1208e-01, -4.2365e-01,  ..., -2.2236e-01,
           9.9554e-02,  1.2916e-02],
         ...,
         [-2.3085e-01,  8.4811e-03, -2.7222e-01,  ..., -1.6294e-01,
           2.5832e-01, -6.2542e-02],
         [-3.2457e-02, -7.0138e-02,  9.0336e-02,  ...,  1.3302e-01,
          -1.7736e-01, -1.4500e-01],
         [ 1.3864e-01, -4.6467e-02, -3.2801e-01,  ..., -4.2189e-02,
          -5.5515e-01, -1.6653e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ¦ T_txt=23
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 23, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 23, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 23, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 23])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 23, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 23, 64])
ğŸŸ¦ out.shape=torch.Size([3, 23, 512])
ğŸŸ¦ out.shape=torch.Size([3, 23, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 23, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 23, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.8693e+00,  9.3745e-01, -1.8379e+00,  ...,  2.4698e+00,
           2.0660e+00,  1.2787e+00],
         [-6.8941e-01,  2.4615e-01, -4.9576e-01,  ..., -2.5218e-01,
           1.5029e-01,  7.9583e-02],
         [ 1.1727e-01, -2.8995e-01, -5.4170e-01,  ..., -1.3670e-01,
           7.0986e-02,  1.0259e-01],
         ...,
         [-9.5837e-02, -1.7879e-01, -4.5818e-01,  ..., -1.0674e-01,
           3.1609e-01,  3.4635e-01],
         [ 1.9294e-01,  1.1087e-01,  1.4712e-01,  ..., -1.6221e-04,
          -3.1137e-02,  1.7252e-01],
         [ 4.2944e-01,  2.9351e-03,  9.1485e-01,  ..., -1.6032e-01,
          -1.7634e-01,  2.9936e-01]],

        [[-5.8693e+00,  9.3745e-01, -1.8379e+00,  ...,  2.4698e+00,
           2.0660e+00,  1.2787e+00],
         [-6.8941e-01,  2.4615e-01, -4.9576e-01,  ..., -2.5218e-01,
           1.5029e-01,  7.9583e-02],
         [ 1.1727e-01, -2.8995e-01, -5.4170e-01,  ..., -1.3670e-01,
           7.0986e-02,  1.0259e-01],
         ...,
         [-9.5837e-02, -1.7879e-01, -4.5818e-01,  ..., -1.0674e-01,
           3.1609e-01,  3.4635e-01],
         [ 1.9294e-01,  1.1087e-01,  1.4712e-01,  ..., -1.6221e-04,
          -3.1137e-02,  1.7252e-01],
         [ 5.4977e-01, -8.9901e-02,  9.6283e-01,  ..., -5.4294e-01,
          -6.7182e-01,  1.0580e+00]],

        [[-5.8693e+00,  9.3745e-01, -1.8379e+00,  ...,  2.4698e+00,
           2.0660e+00,  1.2787e+00],
         [-6.8941e-01,  2.4615e-01, -4.9576e-01,  ..., -2.5218e-01,
           1.5029e-01,  7.9583e-02],
         [ 1.1727e-01, -2.8995e-01, -5.4170e-01,  ..., -1.3670e-01,
           7.0986e-02,  1.0259e-01],
         ...,
         [-9.5838e-02, -1.7879e-01, -4.5818e-01,  ..., -1.0674e-01,
           3.1609e-01,  3.4635e-01],
         [ 1.9294e-01,  1.1087e-01,  1.4712e-01,  ..., -1.6232e-04,
          -3.1137e-02,  1.7252e-01],
         [ 1.2907e-01,  2.6486e-01, -3.7272e-01,  ..., -4.1843e-02,
          -6.9806e-01, -3.1107e-02]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ¦ T_txt=23
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 23, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 23, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 23, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 23])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 23, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 23, 64])
ğŸŸ¦ out.shape=torch.Size([3, 23, 512])
ğŸŸ¦ out.shape=torch.Size([3, 23, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 23, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 23, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.6016,  1.2408, -1.6460,  ...,  3.1029,  2.1120,  1.1936],
         [-0.5132,  0.1307, -0.5725,  ..., -0.0805,  0.0303, -0.1367],
         [ 0.2105, -0.6863, -0.6633,  ...,  0.2212,  0.3595,  0.2320],
         ...,
         [-0.1682, -0.4626, -0.5883,  ..., -0.0632,  0.1946,  0.1242],
         [-0.0388, -0.0288, -0.0640,  ...,  0.0703, -0.2369,  0.0478],
         [ 0.5763,  0.1938,  0.9298,  ..., -0.0228, -0.3543,  0.1931]],

        [[-5.6016,  1.2408, -1.6460,  ...,  3.1029,  2.1120,  1.1936],
         [-0.5132,  0.1307, -0.5725,  ..., -0.0805,  0.0303, -0.1367],
         [ 0.2105, -0.6863, -0.6633,  ...,  0.2212,  0.3595,  0.2320],
         ...,
         [-0.1682, -0.4626, -0.5883,  ..., -0.0632,  0.1946,  0.1242],
         [-0.0388, -0.0288, -0.0640,  ...,  0.0703, -0.2369,  0.0478],
         [ 0.5040, -0.0518,  0.9876,  ..., -0.7335, -0.7508,  0.8494]],

        [[-5.6016,  1.2408, -1.6460,  ...,  3.1029,  2.1120,  1.1936],
         [-0.5132,  0.1307, -0.5725,  ..., -0.0805,  0.0303, -0.1367],
         [ 0.2105, -0.6863, -0.6633,  ...,  0.2212,  0.3595,  0.2320],
         ...,
         [-0.1682, -0.4626, -0.5883,  ..., -0.0632,  0.1946,  0.1242],
         [-0.0388, -0.0288, -0.0640,  ...,  0.0703, -0.2369,  0.0478],
         [ 0.4728,  0.0439, -0.1264,  ..., -0.0608, -0.6885, -0.2903]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ¦ T_txt=23
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 23, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 23, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 23, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 23])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 23, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 23, 64])
ğŸŸ¦ out.shape=torch.Size([3, 23, 512])
ğŸŸ¦ out.shape=torch.Size([3, 23, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 23, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 23, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.5722,  1.3828, -1.6196,  ...,  3.5095,  2.5083,  1.2801],
         [-0.7604,  0.1403, -0.7794,  ...,  0.1032,  0.1174, -0.2312],
         [-0.0521, -0.3372, -0.8223,  ...,  0.0621,  0.1464,  0.1382],
         ...,
         [-0.3934, -0.2799, -0.2061,  ..., -0.4735,  0.0483,  0.0476],
         [-0.3888,  0.0774, -0.0618,  ..., -0.3501, -0.3116,  0.3053],
         [ 0.4046,  0.1571,  0.9001,  ..., -0.0757, -0.4872,  0.2787]],

        [[-5.5722,  1.3828, -1.6196,  ...,  3.5095,  2.5083,  1.2801],
         [-0.7604,  0.1403, -0.7794,  ...,  0.1032,  0.1174, -0.2312],
         [-0.0521, -0.3372, -0.8223,  ...,  0.0621,  0.1464,  0.1382],
         ...,
         [-0.3934, -0.2799, -0.2061,  ..., -0.4735,  0.0483,  0.0476],
         [-0.3888,  0.0774, -0.0618,  ..., -0.3501, -0.3116,  0.3053],
         [ 0.2792, -0.1412,  0.9258,  ..., -0.5942, -0.7232,  0.8483]],

        [[-5.5722,  1.3828, -1.6196,  ...,  3.5095,  2.5083,  1.2801],
         [-0.7604,  0.1403, -0.7794,  ...,  0.1032,  0.1174, -0.2312],
         [-0.0521, -0.3372, -0.8223,  ...,  0.0621,  0.1464,  0.1382],
         ...,
         [-0.3934, -0.2799, -0.2061,  ..., -0.4735,  0.0483,  0.0476],
         [-0.3888,  0.0774, -0.0618,  ..., -0.3501, -0.3116,  0.3053],
         [ 0.2506,  0.2202, -0.0860,  ..., -0.0287, -0.8314, -0.2356]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ¦ T_txt=23
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 23, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 23, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 23, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 23])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 23, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 23, 64])
ğŸŸ¦ out.shape=torch.Size([3, 23, 512])
ğŸŸ¦ out.shape=torch.Size([3, 23, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 23, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 23, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.6640e+00,  1.4165e+00, -1.7391e+00,  ...,  3.7237e+00,
           2.6647e+00,  1.4654e+00],
         [-6.0783e-01, -2.5051e-02, -1.0078e+00,  ...,  2.4022e-02,
          -3.9409e-02, -4.4003e-01],
         [-2.3939e-01, -7.4469e-01, -9.9975e-01,  ..., -1.7663e-01,
           9.6495e-02,  5.5718e-02],
         ...,
         [-3.9262e-01, -3.0471e-01, -1.6318e-03,  ..., -1.2015e-01,
           1.6517e-01, -7.2140e-02],
         [-5.2806e-01, -1.1494e-01,  1.3895e-01,  ..., -2.9315e-01,
          -1.1028e-01,  4.4209e-01],
         [ 3.8917e-01, -8.4473e-02,  9.5960e-01,  ..., -1.5561e-01,
          -4.6714e-01,  1.0895e-01]],

        [[-5.6640e+00,  1.4165e+00, -1.7391e+00,  ...,  3.7237e+00,
           2.6647e+00,  1.4654e+00],
         [-6.0783e-01, -2.5051e-02, -1.0078e+00,  ...,  2.4022e-02,
          -3.9409e-02, -4.4003e-01],
         [-2.3939e-01, -7.4469e-01, -9.9975e-01,  ..., -1.7663e-01,
           9.6495e-02,  5.5718e-02],
         ...,
         [-3.9262e-01, -3.0471e-01, -1.6318e-03,  ..., -1.2015e-01,
           1.6517e-01, -7.2140e-02],
         [-5.2806e-01, -1.1494e-01,  1.3895e-01,  ..., -2.9315e-01,
          -1.1028e-01,  4.4209e-01],
         [ 3.8478e-01, -2.6184e-01,  9.1777e-01,  ..., -4.3718e-01,
          -7.8967e-01,  7.4164e-01]],

        [[-5.6640e+00,  1.4165e+00, -1.7391e+00,  ...,  3.7237e+00,
           2.6647e+00,  1.4654e+00],
         [-6.0783e-01, -2.5051e-02, -1.0078e+00,  ...,  2.4022e-02,
          -3.9409e-02, -4.4003e-01],
         [-2.3939e-01, -7.4469e-01, -9.9975e-01,  ..., -1.7663e-01,
           9.6495e-02,  5.5717e-02],
         ...,
         [-3.9262e-01, -3.0471e-01, -1.6314e-03,  ..., -1.2016e-01,
           1.6517e-01, -7.2140e-02],
         [-5.2806e-01, -1.1494e-01,  1.3895e-01,  ..., -2.9315e-01,
          -1.1028e-01,  4.4209e-01],
         [ 2.3496e-01, -7.8931e-02, -2.3642e-01,  ...,  1.9877e-01,
          -8.0178e-01, -6.8609e-02]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ¦ T_txt=23
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 23, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 23, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 23, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 23])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 23, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 23, 64])
ğŸŸ¦ out.shape=torch.Size([3, 23, 512])
ğŸŸ¦ out.shape=torch.Size([3, 23, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 23, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 23, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.3878,  1.2637, -1.3476,  ...,  3.9388,  2.7129,  1.6259],
         [-0.6773,  0.0069, -0.7329,  ...,  0.2023,  0.1743, -0.1756],
         [-0.3587, -0.5944, -1.0050,  ...,  0.2275,  0.4650,  0.1995],
         ...,
         [-0.3912, -0.3264,  0.2907,  ..., -0.3382,  0.2944,  0.1950],
         [-0.4809, -0.3364,  0.3896,  ..., -0.2721,  0.0814,  0.6517],
         [ 0.2838, -0.0121,  1.2331,  ..., -0.1604, -0.6465,  0.4093]],

        [[-5.3878,  1.2637, -1.3476,  ...,  3.9388,  2.7129,  1.6259],
         [-0.6773,  0.0069, -0.7329,  ...,  0.2023,  0.1743, -0.1756],
         [-0.3587, -0.5944, -1.0050,  ...,  0.2275,  0.4650,  0.1995],
         ...,
         [-0.3912, -0.3264,  0.2907,  ..., -0.3382,  0.2944,  0.1950],
         [-0.4809, -0.3364,  0.3896,  ..., -0.2721,  0.0814,  0.6517],
         [ 0.5905, -0.2534,  0.9877,  ..., -0.3993, -0.9285,  0.9923]],

        [[-5.3878,  1.2637, -1.3476,  ...,  3.9388,  2.7129,  1.6259],
         [-0.6773,  0.0069, -0.7329,  ...,  0.2023,  0.1743, -0.1756],
         [-0.3587, -0.5944, -1.0050,  ...,  0.2275,  0.4650,  0.1995],
         ...,
         [-0.3912, -0.3264,  0.2907,  ..., -0.3382,  0.2944,  0.1950],
         [-0.4809, -0.3364,  0.3896,  ..., -0.2721,  0.0814,  0.6517],
         [ 0.4237,  0.3045, -0.2893,  ...,  0.3515, -0.9351, -0.0924]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ¦ T_txt=23
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 23, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 23, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 23, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 23])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 23, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 23, 64])
ğŸŸ¦ out.shape=torch.Size([3, 23, 512])
ğŸŸ¦ out.shape=torch.Size([3, 23, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 23, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 23, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.0959e+00,  8.5670e-01, -1.2666e+00,  ...,  3.8593e+00,
           2.8167e+00,  1.9328e+00],
         [-9.0690e-01, -3.5641e-01, -8.7610e-01,  ...,  1.3842e-01,
           2.8884e-01, -1.7834e-01],
         [-2.4497e-01, -8.7742e-01, -1.2020e+00,  ...,  3.0884e-01,
           3.8290e-01,  2.8289e-01],
         ...,
         [-4.9250e-01, -3.9705e-01,  1.8587e-01,  ..., -9.8828e-02,
           3.3473e-01,  3.6105e-01],
         [-6.2545e-01, -4.2646e-01,  3.0677e-01,  ...,  2.1251e-01,
          -6.2344e-02,  8.1318e-01],
         [ 3.0653e-01,  4.7357e-02,  1.2372e+00,  ...,  2.1307e-02,
          -4.9365e-01,  4.7314e-01]],

        [[-5.0959e+00,  8.5670e-01, -1.2666e+00,  ...,  3.8593e+00,
           2.8167e+00,  1.9328e+00],
         [-9.0690e-01, -3.5641e-01, -8.7610e-01,  ...,  1.3842e-01,
           2.8884e-01, -1.7834e-01],
         [-2.4497e-01, -8.7742e-01, -1.2020e+00,  ...,  3.0884e-01,
           3.8290e-01,  2.8289e-01],
         ...,
         [-4.9250e-01, -3.9705e-01,  1.8587e-01,  ..., -9.8828e-02,
           3.3473e-01,  3.6105e-01],
         [-6.2545e-01, -4.2646e-01,  3.0677e-01,  ...,  2.1251e-01,
          -6.2344e-02,  8.1318e-01],
         [ 6.7746e-01, -1.3585e-01,  1.1488e+00,  ..., -1.6451e-01,
          -7.7133e-01,  1.0117e+00]],

        [[-5.0959e+00,  8.5671e-01, -1.2666e+00,  ...,  3.8593e+00,
           2.8167e+00,  1.9328e+00],
         [-9.0690e-01, -3.5641e-01, -8.7610e-01,  ...,  1.3843e-01,
           2.8884e-01, -1.7834e-01],
         [-2.4497e-01, -8.7742e-01, -1.2020e+00,  ...,  3.0884e-01,
           3.8290e-01,  2.8289e-01],
         ...,
         [-4.9250e-01, -3.9705e-01,  1.8587e-01,  ..., -9.8828e-02,
           3.3472e-01,  3.6105e-01],
         [-6.2545e-01, -4.2646e-01,  3.0677e-01,  ...,  2.1251e-01,
          -6.2345e-02,  8.1318e-01],
         [ 3.8206e-01, -3.6982e-03, -4.0076e-01,  ...,  6.8701e-01,
          -9.0740e-01,  5.4039e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ¦ T_txt=23
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 23, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 23, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 23, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 23])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 23, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 23, 64])
ğŸŸ¦ out.shape=torch.Size([3, 23, 512])
ğŸŸ¦ out.shape=torch.Size([3, 23, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 23, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 23, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.8058,  0.7302, -1.0989,  ...,  3.8324,  2.7810,  1.7821],
         [-0.7038, -0.6393, -0.6297,  ..., -0.0359,  0.1719, -0.3344],
         [-0.1649, -0.7010, -0.9241,  ...,  0.5318,  0.1623, -0.1670],
         ...,
         [-0.6376, -0.3177, -0.2238,  ..., -0.7059,  0.4351,  0.1451],
         [-0.7060, -0.5439,  0.1309,  ..., -0.2375,  0.0102,  0.6080],
         [ 0.4224,  0.2599,  1.3526,  ..., -0.0145, -0.4427,  0.2361]],

        [[-4.8058,  0.7302, -1.0989,  ...,  3.8324,  2.7810,  1.7821],
         [-0.7038, -0.6393, -0.6297,  ..., -0.0359,  0.1719, -0.3344],
         [-0.1649, -0.7010, -0.9241,  ...,  0.5318,  0.1623, -0.1670],
         ...,
         [-0.6376, -0.3177, -0.2238,  ..., -0.7059,  0.4351,  0.1451],
         [-0.7060, -0.5439,  0.1309,  ..., -0.2375,  0.0102,  0.6080],
         [ 0.8323,  0.2344,  1.0905,  ..., -0.2575, -0.4375,  0.8193]],

        [[-4.8058,  0.7302, -1.0989,  ...,  3.8324,  2.7810,  1.7821],
         [-0.7038, -0.6393, -0.6297,  ..., -0.0359,  0.1719, -0.3344],
         [-0.1649, -0.7010, -0.9241,  ...,  0.5318,  0.1623, -0.1670],
         ...,
         [-0.6376, -0.3177, -0.2238,  ..., -0.7059,  0.4351,  0.1451],
         [-0.7060, -0.5439,  0.1309,  ..., -0.2375,  0.0102,  0.6080],
         [ 0.2034,  0.0955, -0.9918,  ...,  0.8578, -1.1750,  0.0903]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ¦ T_txt=23
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 23, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 23, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 23, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 23])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 23, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 23, 64])
ğŸŸ¦ out.shape=torch.Size([3, 23, 512])
ğŸŸ¦ out.shape=torch.Size([3, 23, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 23, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 23, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.5423,  0.4867, -1.3078,  ...,  4.0570,  2.7591,  1.7055],
         [-0.7944, -1.0986, -0.8873,  ..., -0.3006, -0.1496, -0.3139],
         [ 0.3003, -0.6765, -0.9426,  ...,  0.2994,  0.2125, -0.2227],
         ...,
         [-0.6745, -0.0524, -0.9399,  ..., -0.6166,  0.3006, -0.1860],
         [-0.6692, -0.5936, -0.6865,  ..., -0.2726,  0.2328,  0.2570],
         [ 0.4582,  0.3000,  0.4645,  ..., -0.3277, -0.2306,  0.3756]],

        [[-4.5423,  0.4867, -1.3078,  ...,  4.0570,  2.7591,  1.7055],
         [-0.7944, -1.0986, -0.8873,  ..., -0.3006, -0.1496, -0.3139],
         [ 0.3003, -0.6765, -0.9426,  ...,  0.2994,  0.2125, -0.2227],
         ...,
         [-0.6745, -0.0524, -0.9399,  ..., -0.6166,  0.3006, -0.1860],
         [-0.6692, -0.5936, -0.6865,  ..., -0.2726,  0.2328,  0.2570],
         [ 0.9205,  0.2934,  0.6854,  ..., -0.8828, -0.2170,  0.6854]],

        [[-4.5423,  0.4867, -1.3078,  ...,  4.0570,  2.7591,  1.7055],
         [-0.7944, -1.0986, -0.8873,  ..., -0.3006, -0.1496, -0.3139],
         [ 0.3003, -0.6765, -0.9426,  ...,  0.2994,  0.2125, -0.2227],
         ...,
         [-0.6745, -0.0524, -0.9399,  ..., -0.6166,  0.3006, -0.1860],
         [-0.6692, -0.5936, -0.6865,  ..., -0.2726,  0.2328,  0.2570],
         [ 0.2694, -0.0144, -1.3438,  ...,  0.7258, -1.1897,  0.1401]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ¦ T_txt=23
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 23, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 23, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 23, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 23])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 23, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 23, 64])
ğŸŸ¦ out.shape=torch.Size([3, 23, 512])
ğŸŸ¦ out.shape=torch.Size([3, 23, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 23, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 23, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.4194,  0.4068, -1.0771,  ...,  4.0394,  2.7712,  1.5921],
         [-1.0025, -1.3143, -1.0197,  ..., -0.7655, -0.0488, -0.4858],
         [ 0.0073, -0.6469, -0.9511,  ...,  0.0354,  0.6350,  0.2235],
         ...,
         [-0.7279,  0.0073, -0.7943,  ..., -0.6395,  0.7086, -0.1990],
         [-0.9102, -0.4974, -0.5201,  ...,  0.0245,  0.5392,  0.1246],
         [ 0.6006, -0.3519,  0.2725,  ...,  0.0382, -0.0264,  0.6983]],

        [[-4.4194,  0.4068, -1.0771,  ...,  4.0394,  2.7712,  1.5921],
         [-1.0025, -1.3143, -1.0197,  ..., -0.7655, -0.0488, -0.4858],
         [ 0.0073, -0.6469, -0.9511,  ...,  0.0354,  0.6350,  0.2235],
         ...,
         [-0.7279,  0.0073, -0.7943,  ..., -0.6395,  0.7086, -0.1990],
         [-0.9102, -0.4974, -0.5201,  ...,  0.0245,  0.5392,  0.1246],
         [ 1.0983, -0.3486,  0.5914,  ..., -0.4843,  0.4383,  1.0968]],

        [[-4.4194,  0.4068, -1.0771,  ...,  4.0394,  2.7712,  1.5921],
         [-1.0025, -1.3143, -1.0197,  ..., -0.7654, -0.0488, -0.4858],
         [ 0.0073, -0.6469, -0.9511,  ...,  0.0354,  0.6350,  0.2235],
         ...,
         [-0.7279,  0.0073, -0.7943,  ..., -0.6395,  0.7086, -0.1990],
         [-0.9102, -0.4974, -0.5201,  ...,  0.0245,  0.5392,  0.1246],
         [ 0.1042,  0.0541, -1.5284,  ...,  0.9507, -0.9565,  0.3583]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ¦ T_txt=23
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 23, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 23, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 23, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 23])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 23, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 23, 64])
ğŸŸ¦ out.shape=torch.Size([3, 23, 512])
ğŸŸ¦ out.shape=torch.Size([3, 23, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 23, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 23, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.6486e+00,  4.3703e-01, -1.0679e+00,  ...,  4.0760e+00,
           2.7873e+00,  1.4896e+00],
         [-9.1824e-01, -1.6641e+00, -8.0367e-01,  ..., -1.0706e+00,
          -9.7789e-02,  8.5559e-02],
         [-3.2958e-01, -1.1621e+00, -1.2796e+00,  ..., -3.9725e-01,
           5.5436e-01,  2.3460e-01],
         ...,
         [-1.6143e+00,  6.0909e-02, -3.3665e-01,  ..., -3.9274e-01,
           6.8691e-01, -1.4717e-01],
         [-1.7840e+00, -4.7463e-01, -2.9961e-01,  ...,  7.6514e-01,
           4.4933e-01,  4.2029e-01],
         [-7.4074e-01,  8.6397e-02,  5.8763e-01,  ...,  3.0829e-01,
           6.4790e-02,  7.7100e-01]],

        [[-4.6486e+00,  4.3703e-01, -1.0679e+00,  ...,  4.0760e+00,
           2.7873e+00,  1.4896e+00],
         [-9.1824e-01, -1.6641e+00, -8.0367e-01,  ..., -1.0706e+00,
          -9.7789e-02,  8.5559e-02],
         [-3.2958e-01, -1.1621e+00, -1.2796e+00,  ..., -3.9725e-01,
           5.5436e-01,  2.3460e-01],
         ...,
         [-1.6143e+00,  6.0909e-02, -3.3665e-01,  ..., -3.9274e-01,
           6.8691e-01, -1.4717e-01],
         [-1.7840e+00, -4.7463e-01, -2.9961e-01,  ...,  7.6514e-01,
           4.4933e-01,  4.2029e-01],
         [ 2.8291e-03,  2.9193e-01,  6.1430e-01,  ..., -6.6744e-02,
           4.1248e-01,  1.1794e+00]],

        [[-4.6486e+00,  4.3703e-01, -1.0679e+00,  ...,  4.0760e+00,
           2.7874e+00,  1.4896e+00],
         [-9.1824e-01, -1.6641e+00, -8.0367e-01,  ..., -1.0706e+00,
          -9.7788e-02,  8.5560e-02],
         [-3.2958e-01, -1.1621e+00, -1.2796e+00,  ..., -3.9725e-01,
           5.5436e-01,  2.3460e-01],
         ...,
         [-1.6143e+00,  6.0910e-02, -3.3665e-01,  ..., -3.9274e-01,
           6.8691e-01, -1.4717e-01],
         [-1.7840e+00, -4.7463e-01, -2.9961e-01,  ...,  7.6514e-01,
           4.4933e-01,  4.2029e-01],
         [-5.9560e-01, -1.6249e-01, -1.6113e+00,  ...,  1.1438e+00,
          -9.3628e-01,  2.3200e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ¦ T_txt=23
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 23, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 23, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 23, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 23])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 23, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 23, 64])
ğŸŸ¦ out.shape=torch.Size([3, 23, 512])
ğŸŸ¦ out.shape=torch.Size([3, 23, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 23, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 23, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.6982,  0.6115, -1.1511,  ...,  3.9602,  2.6816,  1.0754],
         [-0.8318, -2.6615, -1.2791,  ..., -1.1889,  0.2650, -0.4843],
         [-0.0270, -1.6365, -1.4973,  ..., -0.5320,  0.8756,  0.4654],
         ...,
         [-1.3130,  0.1763, -0.6732,  ..., -0.1909,  0.6826, -0.5629],
         [-1.0176, -0.0554, -0.8662,  ...,  1.2393,  0.3358,  0.2461],
         [-0.5679,  0.5445,  0.1623,  ...,  0.5058,  0.1193,  1.3218]],

        [[-4.6982,  0.6115, -1.1511,  ...,  3.9602,  2.6816,  1.0754],
         [-0.8318, -2.6615, -1.2791,  ..., -1.1889,  0.2650, -0.4843],
         [-0.0270, -1.6365, -1.4973,  ..., -0.5320,  0.8756,  0.4654],
         ...,
         [-1.3130,  0.1763, -0.6732,  ..., -0.1909,  0.6826, -0.5629],
         [-1.0176, -0.0554, -0.8662,  ...,  1.2393,  0.3358,  0.2461],
         [ 0.3004,  0.7089, -0.3612,  ...,  0.0641,  0.5492,  1.4825]],

        [[-4.6982,  0.6115, -1.1511,  ...,  3.9602,  2.6816,  1.0754],
         [-0.8318, -2.6615, -1.2791,  ..., -1.1889,  0.2650, -0.4843],
         [-0.0270, -1.6365, -1.4973,  ..., -0.5320,  0.8756,  0.4654],
         ...,
         [-1.3130,  0.1763, -0.6732,  ..., -0.1909,  0.6826, -0.5629],
         [-1.0176, -0.0554, -0.8662,  ...,  1.2393,  0.3358,  0.2461],
         [-0.4412, -0.2237, -2.3590,  ...,  1.4367, -0.6060, -0.5022]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ¦ T_txt=23
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 23, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 23, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 23, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 23])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 23, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 23, 64])
ğŸŸ¦ out.shape=torch.Size([3, 23, 512])
ğŸŸ¦ out.shape=torch.Size([3, 23, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 23, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 23, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.1992e+00,  1.0861e-01, -1.3292e+00,  ...,  4.5845e+00,
           3.1037e+00,  6.4127e-01],
         [-1.7888e+00, -3.0735e+00, -9.0352e-01,  ..., -6.4027e-01,
          -3.6426e-01, -1.2033e-01],
         [ 6.7153e-01, -1.5127e+00, -1.2408e+00,  ...,  3.2038e-01,
           1.0818e+00,  3.0631e-01],
         ...,
         [-1.3948e+00,  1.2983e-01, -3.0708e-01,  ...,  9.0816e-02,
           1.7694e-01, -6.3714e-01],
         [-1.2233e+00,  7.7011e-03, -9.8320e-01,  ...,  1.7667e+00,
           1.6701e-04,  4.6981e-01],
         [-5.7463e-01,  6.4741e-01,  3.6707e-01,  ...,  8.4325e-01,
          -5.7200e-02,  1.5996e+00]],

        [[-4.1992e+00,  1.0861e-01, -1.3292e+00,  ...,  4.5845e+00,
           3.1037e+00,  6.4127e-01],
         [-1.7888e+00, -3.0735e+00, -9.0352e-01,  ..., -6.4027e-01,
          -3.6426e-01, -1.2033e-01],
         [ 6.7153e-01, -1.5127e+00, -1.2408e+00,  ...,  3.2038e-01,
           1.0818e+00,  3.0631e-01],
         ...,
         [-1.3948e+00,  1.2983e-01, -3.0708e-01,  ...,  9.0816e-02,
           1.7694e-01, -6.3714e-01],
         [-1.2233e+00,  7.7011e-03, -9.8320e-01,  ...,  1.7667e+00,
           1.6701e-04,  4.6981e-01],
         [ 1.7288e-01,  6.4767e-01, -2.9748e-01,  ...,  2.9216e-02,
           8.5137e-01,  1.8736e+00]],

        [[-4.1992e+00,  1.0861e-01, -1.3292e+00,  ...,  4.5845e+00,
           3.1037e+00,  6.4127e-01],
         [-1.7888e+00, -3.0735e+00, -9.0352e-01,  ..., -6.4027e-01,
          -3.6426e-01, -1.2033e-01],
         [ 6.7153e-01, -1.5127e+00, -1.2408e+00,  ...,  3.2038e-01,
           1.0818e+00,  3.0631e-01],
         ...,
         [-1.3948e+00,  1.2983e-01, -3.0708e-01,  ...,  9.0818e-02,
           1.7694e-01, -6.3715e-01],
         [-1.2233e+00,  7.6987e-03, -9.8320e-01,  ...,  1.7667e+00,
           1.6642e-04,  4.6981e-01],
         [-2.8518e-01, -9.6333e-01, -2.7130e+00,  ...,  1.9681e+00,
          -5.4935e-01, -1.9855e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ¦ T_txt=23
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 23, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 23, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 23, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 23])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 23, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 23, 64])
ğŸŸ¦ out.shape=torch.Size([3, 23, 512])
ğŸŸ¦ out.shape=torch.Size([3, 23, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 23, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 23, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-3.4956, -0.4549, -1.3173,  ...,  5.3489,  3.8643,  0.0495],
         [-1.1846, -2.7309, -0.3251,  ..., -0.5469, -0.2345,  0.0928],
         [ 0.3590, -0.8857, -1.3176,  ...,  0.7098,  1.7219,  0.2027],
         ...,
         [-0.7701,  0.4790, -0.4627,  ...,  0.6082,  1.0008, -1.0690],
         [-0.3139,  0.4464, -0.5054,  ...,  2.4753,  0.8644,  0.2732],
         [ 0.2531,  1.0129,  0.9571,  ...,  1.5907,  1.5373,  1.0220]],

        [[-3.4956, -0.4549, -1.3173,  ...,  5.3489,  3.8643,  0.0495],
         [-1.1846, -2.7309, -0.3251,  ..., -0.5469, -0.2345,  0.0928],
         [ 0.3590, -0.8857, -1.3176,  ...,  0.7098,  1.7219,  0.2027],
         ...,
         [-0.7701,  0.4790, -0.4627,  ...,  0.6082,  1.0008, -1.0690],
         [-0.3139,  0.4464, -0.5054,  ...,  2.4753,  0.8644,  0.2732],
         [ 0.9831,  1.0852,  0.3028,  ...,  0.5779,  2.4249,  1.5966]],

        [[-3.4956, -0.4549, -1.3173,  ...,  5.3489,  3.8643,  0.0495],
         [-1.1846, -2.7309, -0.3251,  ..., -0.5469, -0.2345,  0.0928],
         [ 0.3590, -0.8857, -1.3176,  ...,  0.7098,  1.7219,  0.2027],
         ...,
         [-0.7701,  0.4790, -0.4627,  ...,  0.6082,  1.0008, -1.0690],
         [-0.3139,  0.4464, -0.5054,  ...,  2.4753,  0.8644,  0.2732],
         [ 0.1606, -0.9373, -2.7176,  ...,  2.3560, -0.0458, -0.7945]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ¦ T_txt=23
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 23, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 23, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 23, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 23])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 23, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 23, 64])
ğŸŸ¦ out.shape=torch.Size([3, 23, 512])
ğŸŸ¦ out.shape=torch.Size([3, 23, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 23, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 23, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-2.3185e+00, -1.3191e+00, -1.7786e+00,  ...,  8.3678e+00,
           3.3047e+00, -5.9097e-01],
         [-8.1188e-01, -3.2357e+00, -3.2883e-02,  ...,  1.3220e+00,
          -3.9638e-01,  9.7235e-01],
         [ 6.8207e-01, -7.9400e-01, -2.6728e-01,  ...,  3.2716e+00,
           1.7577e+00,  8.6897e-01],
         ...,
         [-5.4658e-01, -3.4789e-01, -8.7686e-01,  ...,  3.6395e+00,
          -4.2720e-02, -5.6463e-01],
         [-1.2651e+00, -5.7598e-01, -2.5607e-01,  ...,  5.3449e+00,
          -6.3446e-01,  3.6178e-01],
         [-2.2489e-01,  1.7957e-01,  4.9832e-01,  ...,  3.6873e+00,
           1.4884e+00,  1.2771e+00]],

        [[-2.3185e+00, -1.3191e+00, -1.7786e+00,  ...,  8.3678e+00,
           3.3047e+00, -5.9097e-01],
         [-8.1188e-01, -3.2357e+00, -3.2883e-02,  ...,  1.3220e+00,
          -3.9638e-01,  9.7235e-01],
         [ 6.8207e-01, -7.9400e-01, -2.6728e-01,  ...,  3.2716e+00,
           1.7577e+00,  8.6897e-01],
         ...,
         [-5.4658e-01, -3.4789e-01, -8.7686e-01,  ...,  3.6395e+00,
          -4.2720e-02, -5.6463e-01],
         [-1.2651e+00, -5.7598e-01, -2.5607e-01,  ...,  5.3449e+00,
          -6.3446e-01,  3.6178e-01],
         [ 1.1300e-01,  8.1279e-03,  1.9817e-01,  ...,  3.1213e+00,
           2.6491e+00,  1.7652e+00]],

        [[-2.3185e+00, -1.3191e+00, -1.7786e+00,  ...,  8.3678e+00,
           3.3047e+00, -5.9097e-01],
         [-8.1188e-01, -3.2357e+00, -3.2884e-02,  ...,  1.3220e+00,
          -3.9638e-01,  9.7235e-01],
         [ 6.8208e-01, -7.9399e-01, -2.6728e-01,  ...,  3.2716e+00,
           1.7577e+00,  8.6897e-01],
         ...,
         [-5.4658e-01, -3.4789e-01, -8.7685e-01,  ...,  3.6395e+00,
          -4.2721e-02, -5.6463e-01],
         [-1.2651e+00, -5.7599e-01, -2.5607e-01,  ...,  5.3449e+00,
          -6.3446e-01,  3.6177e-01],
         [-7.5188e-01, -1.0030e-01, -2.5782e+00,  ...,  4.3010e+00,
          -2.9990e-01, -3.2757e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 23, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 23]), use_cached_media=False
ğŸŸ¦ T_txt=23
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 23, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 23, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 23, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 23])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 23, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 23, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 23, 64])
ğŸŸ¦ out.shape=torch.Size([3, 23, 512])
ğŸŸ¦ out.shape=torch.Size([3, 23, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 23, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 23, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 23, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-1.2009, -0.4256,  0.9579,  ...,  3.0081,  1.0086, -0.1812],
         [-0.2749, -1.1022, -0.6093,  ...,  1.7677, -1.5354, -0.1590],
         [ 0.9989,  0.1369, -0.1195,  ...,  5.2063,  0.3365, -0.3707],
         ...,
         [-0.8508, -0.5504, -0.4473,  ...,  6.0300, -0.6670, -1.1407],
         [-2.0599, -0.3107,  0.2120,  ...,  6.8373, -1.3011, -1.2283],
         [-0.4905,  0.3212,  1.3305,  ...,  5.4371,  0.2796,  0.7576]],

        [[-1.2009, -0.4256,  0.9579,  ...,  3.0081,  1.0086, -0.1812],
         [-0.2749, -1.1022, -0.6093,  ...,  1.7677, -1.5354, -0.1590],
         [ 0.9989,  0.1369, -0.1195,  ...,  5.2063,  0.3365, -0.3707],
         ...,
         [-0.8508, -0.5504, -0.4473,  ...,  6.0300, -0.6670, -1.1407],
         [-2.0599, -0.3107,  0.2120,  ...,  6.8373, -1.3011, -1.2283],
         [-0.4712,  0.2593,  0.7816,  ...,  4.7891,  1.3394,  1.2857]],

        [[-1.2009, -0.4256,  0.9579,  ...,  3.0081,  1.0086, -0.1812],
         [-0.2749, -1.1022, -0.6093,  ...,  1.7677, -1.5354, -0.1590],
         [ 0.9989,  0.1369, -0.1195,  ...,  5.2063,  0.3365, -0.3707],
         ...,
         [-0.8508, -0.5504, -0.4473,  ...,  6.0300, -0.6670, -1.1407],
         [-2.0599, -0.3107,  0.2120,  ...,  6.8373, -1.3011, -1.2283],
         [-1.1800,  0.9079, -1.3563,  ...,  5.3469, -2.2353, -0.9465]]]), None)
ğŸŸ© FlamingoLMMixinã®é †ä¼æ’­å®Œäº†
ğŸŸ© FlamingoLMMixinã®é †ä¼æ’­é–‹å§‹ input_ids.shape=torch.Size([3, 24]), input_ids.dtype=torch.int64, None if attention_mask is None else attention_mask.shape=torch.Size([3, 24]), dict_keys(['prefix_mask', 'sequence_id', 'past_key_values', 'use_cache', 'return_dict'])
ğŸŸ¦ media_locations.shape=torch.Size([3, 24]), media_locations.dtype=torch.bool
ğŸŸ¦ use_cached_media_locations=False
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ¦ T_txt=24
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 24, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 24, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 24, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 24])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 24, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 24, 64])
ğŸŸ¦ out.shape=torch.Size([3, 24, 512])
ğŸŸ¦ out.shape=torch.Size([3, 24, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 24, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 24, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-0.2093, -0.0591,  0.0653,  ...,  0.4109, -0.3524,  0.3726],
         [-0.0174, -0.1497,  0.0368,  ...,  0.1042,  0.0032,  0.4746],
         [-0.0191, -0.1369, -0.1287,  ...,  0.1608, -0.1576,  0.1995],
         ...,
         [ 0.0299, -0.0102, -0.0651,  ...,  0.1253, -0.0123,  0.2513],
         [-0.0557,  0.0681,  0.4820,  ..., -0.0311, -0.3772,  0.7188],
         [-0.0100,  0.0373,  0.1066,  ...,  0.1400, -0.2549,  0.3483]],

        [[-0.2093, -0.0591,  0.0653,  ...,  0.4109, -0.3524,  0.3726],
         [-0.0174, -0.1497,  0.0368,  ...,  0.1042,  0.0032,  0.4746],
         [-0.0191, -0.1369, -0.1287,  ...,  0.1608, -0.1576,  0.1995],
         ...,
         [ 0.0299, -0.0102, -0.0651,  ...,  0.1253, -0.0123,  0.2513],
         [ 0.0244,  0.0468,  0.4299,  ...,  0.0655, -0.0743,  0.4537],
         [ 0.1546, -0.2127, -0.0173,  ...,  0.0720, -0.0731,  0.4898]],

        [[-0.2093, -0.0591,  0.0653,  ...,  0.4109, -0.3524,  0.3726],
         [-0.0174, -0.1497,  0.0368,  ...,  0.1042,  0.0032,  0.4746],
         [-0.0191, -0.1369, -0.1287,  ...,  0.1608, -0.1576,  0.1995],
         ...,
         [ 0.0299, -0.0102, -0.0651,  ...,  0.1253, -0.0123,  0.2513],
         [ 0.0244,  0.0468,  0.4299,  ...,  0.0655, -0.0743,  0.4537],
         [-0.0297,  0.0205,  0.1009,  ...,  0.1497, -0.2603,  0.3349]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ¦ T_txt=24
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 24, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 24, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 24, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 24])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 24, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 24, 64])
ğŸŸ¦ out.shape=torch.Size([3, 24, 512])
ğŸŸ¦ out.shape=torch.Size([3, 24, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 24, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 24, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-0.0762, -0.3746,  0.1300,  ...,  0.1017, -0.0332,  0.2191],
         [-0.0236, -0.1139, -0.0499,  ...,  0.0464,  0.0973,  0.4798],
         [ 0.0476, -0.1903,  0.0666,  ..., -0.0123, -0.0800,  0.3086],
         ...,
         [ 0.0278,  0.0493, -0.0914,  ...,  0.1708, -0.1178,  0.4907],
         [ 0.1335,  0.0972,  0.4912,  ..., -0.0506, -0.4505,  0.8139],
         [ 0.1429,  0.0541,  0.0068,  ...,  0.0633, -0.3146,  0.3919]],

        [[-0.0762, -0.3746,  0.1300,  ...,  0.1017, -0.0332,  0.2191],
         [-0.0236, -0.1139, -0.0499,  ...,  0.0464,  0.0973,  0.4798],
         [ 0.0476, -0.1903,  0.0666,  ..., -0.0123, -0.0800,  0.3086],
         ...,
         [ 0.0278,  0.0493, -0.0914,  ...,  0.1708, -0.1178,  0.4907],
         [-0.0708,  0.0919,  0.6011,  ...,  0.0187, -0.1797,  0.5978],
         [ 0.2166, -0.1439, -0.1998,  ..., -0.2547, -0.1789,  0.4334]],

        [[-0.0762, -0.3746,  0.1300,  ...,  0.1017, -0.0332,  0.2191],
         [-0.0236, -0.1139, -0.0499,  ...,  0.0464,  0.0973,  0.4798],
         [ 0.0476, -0.1903,  0.0666,  ..., -0.0123, -0.0800,  0.3086],
         ...,
         [ 0.0278,  0.0493, -0.0914,  ...,  0.1708, -0.1178,  0.4907],
         [-0.0708,  0.0919,  0.6011,  ...,  0.0187, -0.1797,  0.5978],
         [ 0.1144,  0.0266,  0.0062,  ...,  0.0471, -0.3277,  0.3944]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ¦ T_txt=24
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 24, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 24, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 24, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 24])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 24, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 24, 64])
ğŸŸ¦ out.shape=torch.Size([3, 24, 512])
ğŸŸ¦ out.shape=torch.Size([3, 24, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 24, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 24, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-0.0423, -0.4800,  0.0985,  ..., -0.1247,  0.1871, -0.2268],
         [-0.0501, -0.1131, -0.1332,  ...,  0.1946,  0.1566,  0.3318],
         [-0.0369, -0.1714,  0.2051,  ...,  0.1376, -0.1982,  0.2490],
         ...,
         [ 0.0585,  0.1236, -0.0072,  ...,  0.1960, -0.0054,  0.3329],
         [ 0.2737, -0.1982,  0.2150,  ..., -0.0381, -0.3880,  0.8100],
         [ 0.3451, -0.3134, -0.1434,  ...,  0.0484, -0.2695,  0.1470]],

        [[-0.0423, -0.4800,  0.0985,  ..., -0.1247,  0.1871, -0.2268],
         [-0.0501, -0.1131, -0.1332,  ...,  0.1946,  0.1566,  0.3318],
         [-0.0369, -0.1714,  0.2051,  ...,  0.1376, -0.1982,  0.2490],
         ...,
         [ 0.0585,  0.1236, -0.0072,  ...,  0.1960, -0.0054,  0.3329],
         [ 0.0758, -0.1454,  0.6495,  ..., -0.1463, -0.0908,  0.5520],
         [ 0.2193, -0.2403, -0.1173,  ..., -0.1467, -0.0574,  0.2919]],

        [[-0.0423, -0.4800,  0.0985,  ..., -0.1247,  0.1871, -0.2268],
         [-0.0501, -0.1131, -0.1332,  ...,  0.1946,  0.1566,  0.3318],
         [-0.0369, -0.1714,  0.2051,  ...,  0.1376, -0.1982,  0.2490],
         ...,
         [ 0.0585,  0.1236, -0.0072,  ...,  0.1960, -0.0054,  0.3329],
         [ 0.0758, -0.1454,  0.6495,  ..., -0.1463, -0.0908,  0.5520],
         [ 0.3490, -0.3337, -0.1414,  ...,  0.0240, -0.2785,  0.1427]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ¦ T_txt=24
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 24, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 24, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 24, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 24])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 24, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 24, 64])
ğŸŸ¦ out.shape=torch.Size([3, 24, 512])
ğŸŸ¦ out.shape=torch.Size([3, 24, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 24, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 24, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-0.6808, -0.0752, -0.2681,  ..., -0.1388, -0.2275, -0.2143],
         [-0.2353, -0.1768, -0.1707,  ...,  0.0178,  0.0832,  0.2217],
         [ 0.1139, -0.0718,  0.1118,  ...,  0.0826, -0.0978,  0.2029],
         ...,
         [-0.0029,  0.1539,  0.0426,  ...,  0.1117,  0.0696,  0.2327],
         [ 0.3311, -0.3437,  0.3384,  ...,  0.0665, -0.5832,  0.6978],
         [ 0.2472, -0.4203, -0.2445,  ..., -0.0556, -0.6851,  0.2459]],

        [[-0.6808, -0.0752, -0.2681,  ..., -0.1388, -0.2275, -0.2143],
         [-0.2353, -0.1768, -0.1707,  ...,  0.0178,  0.0832,  0.2217],
         [ 0.1139, -0.0718,  0.1118,  ...,  0.0826, -0.0978,  0.2029],
         ...,
         [-0.0029,  0.1539,  0.0426,  ...,  0.1117,  0.0696,  0.2327],
         [ 0.2183, -0.0785,  0.6720,  ..., -0.0715, -0.3156,  0.3742],
         [-0.0872, -0.0924, -0.1474,  ..., -0.0083, -0.1085,  0.3296]],

        [[-0.6808, -0.0752, -0.2681,  ..., -0.1388, -0.2275, -0.2143],
         [-0.2353, -0.1768, -0.1707,  ...,  0.0178,  0.0832,  0.2217],
         [ 0.1139, -0.0718,  0.1118,  ...,  0.0826, -0.0978,  0.2029],
         ...,
         [-0.0029,  0.1539,  0.0426,  ...,  0.1117,  0.0696,  0.2327],
         [ 0.2183, -0.0785,  0.6720,  ..., -0.0715, -0.3156,  0.3742],
         [ 0.3059, -0.4358, -0.2626,  ..., -0.0514, -0.6672,  0.2423]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ¦ T_txt=24
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 24, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 24, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 24, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 24])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 24, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 24, 64])
ğŸŸ¦ out.shape=torch.Size([3, 24, 512])
ğŸŸ¦ out.shape=torch.Size([3, 24, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 24, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 24, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.0310,  0.7941, -1.4750,  ...,  0.3614,  1.5208, -0.2439],
         [-0.5725, -0.0922, -0.2418,  ...,  0.0514,  0.0311,  0.2457],
         [ 0.0686, -0.0593,  0.1036,  ...,  0.0507,  0.1819,  0.0491],
         ...,
         [-0.0449,  0.1201, -0.0639,  ...,  0.0639, -0.0749,  0.3225],
         [ 0.1553, -0.5355,  0.3048,  ..., -0.0323, -0.6527,  0.4153],
         [ 0.0561, -0.3208, -0.2518,  ...,  0.1978, -0.5437,  0.1993]],

        [[-4.0310,  0.7941, -1.4750,  ...,  0.3614,  1.5208, -0.2439],
         [-0.5725, -0.0922, -0.2418,  ...,  0.0514,  0.0311,  0.2457],
         [ 0.0686, -0.0593,  0.1036,  ...,  0.0507,  0.1819,  0.0491],
         ...,
         [-0.0449,  0.1201, -0.0639,  ...,  0.0639, -0.0749,  0.3225],
         [ 0.1298, -0.1410,  0.5957,  ..., -0.0378, -0.3640,  0.2144],
         [ 0.1142, -0.1232, -0.2430,  ...,  0.1038, -0.0946,  0.4473]],

        [[-4.0310,  0.7941, -1.4750,  ...,  0.3614,  1.5208, -0.2439],
         [-0.5725, -0.0922, -0.2418,  ...,  0.0514,  0.0311,  0.2457],
         [ 0.0686, -0.0593,  0.1036,  ...,  0.0507,  0.1819,  0.0491],
         ...,
         [-0.0449,  0.1201, -0.0639,  ...,  0.0639, -0.0749,  0.3225],
         [ 0.1298, -0.1410,  0.5957,  ..., -0.0378, -0.3640,  0.2144],
         [ 0.1947, -0.3707, -0.1807,  ...,  0.1995, -0.5023,  0.2307]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ¦ T_txt=24
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 24, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 24, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 24, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 24])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 24, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 24, 64])
ğŸŸ¦ out.shape=torch.Size([3, 24, 512])
ğŸŸ¦ out.shape=torch.Size([3, 24, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 24, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 24, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.7946e+00,  9.0221e-01, -1.2882e+00,  ...,  1.1832e+00,
           2.5226e+00, -5.9823e-02],
         [-5.6193e-01, -1.5785e-01, -2.8558e-01,  ..., -3.8618e-02,
          -1.3091e-02,  1.2509e-01],
         [ 4.1304e-03, -1.2649e-01, -2.6289e-01,  ...,  2.2804e-01,
          -9.2656e-02,  5.5099e-03],
         ...,
         [-2.1025e-01,  3.5201e-02,  2.9223e-02,  ...,  3.3373e-01,
           3.1496e-02,  9.7370e-02],
         [ 9.5321e-02, -6.5955e-01,  6.1281e-01,  ..., -3.5334e-01,
          -8.4627e-01,  7.3372e-01],
         [-1.0711e-01, -4.1903e-01, -2.2295e-01,  ..., -8.4910e-02,
          -8.1008e-01,  6.9410e-02]],

        [[-4.7946e+00,  9.0221e-01, -1.2882e+00,  ...,  1.1832e+00,
           2.5226e+00, -5.9823e-02],
         [-5.6193e-01, -1.5785e-01, -2.8558e-01,  ..., -3.8618e-02,
          -1.3091e-02,  1.2509e-01],
         [ 4.1304e-03, -1.2649e-01, -2.6289e-01,  ...,  2.2804e-01,
          -9.2656e-02,  5.5099e-03],
         ...,
         [-2.1025e-01,  3.5201e-02,  2.9223e-02,  ...,  3.3373e-01,
           3.1496e-02,  9.7370e-02],
         [ 1.5137e-01, -3.1456e-01,  6.1986e-01,  ..., -1.8698e-01,
          -4.2912e-01,  3.1011e-01],
         [ 1.8597e-01, -2.3619e-01, -3.2535e-01,  ...,  5.0270e-02,
           9.2434e-02,  4.2249e-01]],

        [[-4.7946e+00,  9.0221e-01, -1.2882e+00,  ...,  1.1832e+00,
           2.5226e+00, -5.9824e-02],
         [-5.6193e-01, -1.5785e-01, -2.8558e-01,  ..., -3.8618e-02,
          -1.3092e-02,  1.2509e-01],
         [ 4.1302e-03, -1.2649e-01, -2.6289e-01,  ...,  2.2804e-01,
          -9.2657e-02,  5.5096e-03],
         ...,
         [-2.1025e-01,  3.5201e-02,  2.9223e-02,  ...,  3.3373e-01,
           3.1496e-02,  9.7370e-02],
         [ 1.5137e-01, -3.1456e-01,  6.1986e-01,  ..., -1.8698e-01,
          -4.2912e-01,  3.1011e-01],
         [-7.2773e-02, -4.3585e-01, -1.2248e-01,  ..., -1.4911e-01,
          -7.9335e-01,  1.7368e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ¦ T_txt=24
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 24, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 24, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 24, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 24])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 24, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 24, 64])
ğŸŸ¦ out.shape=torch.Size([3, 24, 512])
ğŸŸ¦ out.shape=torch.Size([3, 24, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 24, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 24, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.2771e+00,  1.3169e+00, -1.5839e+00,  ...,  1.5235e+00,
           2.5618e+00,  3.0273e-01],
         [-5.1019e-01, -2.0753e-01, -3.9353e-01,  ..., -3.0973e-02,
           3.3680e-01,  1.5358e-01],
         [ 9.6702e-02, -5.6518e-01, -1.5635e-01,  ...,  8.8994e-03,
           7.6486e-02, -5.2472e-03],
         ...,
         [-1.3436e-01,  1.5734e-01, -2.1990e-01,  ...,  4.6067e-01,
           1.1024e-01,  1.8483e-01],
         [ 4.7157e-01, -4.8962e-01,  7.7679e-01,  ..., -3.1238e-01,
          -5.8977e-01,  8.6680e-01],
         [-2.1697e-03, -8.4452e-02, -2.1674e-01,  ...,  1.3828e-01,
          -4.5000e-01,  1.3284e-01]],

        [[-5.2771e+00,  1.3169e+00, -1.5839e+00,  ...,  1.5235e+00,
           2.5618e+00,  3.0273e-01],
         [-5.1019e-01, -2.0753e-01, -3.9353e-01,  ..., -3.0973e-02,
           3.3680e-01,  1.5358e-01],
         [ 9.6702e-02, -5.6518e-01, -1.5635e-01,  ...,  8.8994e-03,
           7.6486e-02, -5.2472e-03],
         ...,
         [-1.3436e-01,  1.5734e-01, -2.1990e-01,  ...,  4.6067e-01,
           1.1024e-01,  1.8483e-01],
         [ 3.8801e-01, -2.2128e-01,  7.5257e-01,  ..., -2.1136e-01,
          -2.9751e-02,  2.3278e-01],
         [ 3.6183e-01, -8.2698e-02, -3.2821e-01,  ..., -1.4714e-01,
           3.8478e-01,  4.9177e-01]],

        [[-5.2771e+00,  1.3169e+00, -1.5839e+00,  ...,  1.5235e+00,
           2.5618e+00,  3.0273e-01],
         [-5.1019e-01, -2.0753e-01, -3.9353e-01,  ..., -3.0973e-02,
           3.3680e-01,  1.5358e-01],
         [ 9.6702e-02, -5.6518e-01, -1.5635e-01,  ...,  8.8996e-03,
           7.6485e-02, -5.2476e-03],
         ...,
         [-1.3436e-01,  1.5734e-01, -2.1990e-01,  ...,  4.6067e-01,
           1.1024e-01,  1.8483e-01],
         [ 3.8801e-01, -2.2128e-01,  7.5257e-01,  ..., -2.1136e-01,
          -2.9751e-02,  2.3278e-01],
         [-3.5616e-03, -1.6476e-01, -7.2072e-02,  ...,  8.6559e-03,
          -4.1433e-01,  2.2636e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ¦ T_txt=24
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 24, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 24, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 24, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 24])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 24, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 24, 64])
ğŸŸ¦ out.shape=torch.Size([3, 24, 512])
ğŸŸ¦ out.shape=torch.Size([3, 24, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 24, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 24, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.3925e+00,  1.2785e+00, -1.7428e+00,  ...,  1.6187e+00,
           2.6666e+00,  6.3102e-01],
         [-7.2190e-01, -9.0366e-02, -3.7054e-01,  ..., -4.8731e-02,
           5.0304e-02,  4.0432e-02],
         [ 3.2142e-02, -5.6480e-01, -2.0480e-01,  ...,  6.2426e-02,
          -1.1226e-01,  5.0913e-03],
         ...,
         [-2.0149e-01,  2.5538e-01,  1.1700e-04,  ...,  4.8664e-01,
          -3.3184e-01,  5.2587e-02],
         [ 4.7406e-01, -5.4928e-01,  6.2735e-01,  ..., -7.1123e-02,
          -6.2055e-01,  7.8802e-01],
         [-7.2949e-02,  1.4121e-01, -3.0084e-01,  ...,  2.2718e-02,
          -5.2362e-01, -1.3222e-01]],

        [[-5.3925e+00,  1.2785e+00, -1.7428e+00,  ...,  1.6187e+00,
           2.6666e+00,  6.3102e-01],
         [-7.2190e-01, -9.0366e-02, -3.7054e-01,  ..., -4.8731e-02,
           5.0304e-02,  4.0432e-02],
         [ 3.2142e-02, -5.6480e-01, -2.0480e-01,  ...,  6.2426e-02,
          -1.1226e-01,  5.0913e-03],
         ...,
         [-2.0149e-01,  2.5538e-01,  1.1700e-04,  ...,  4.8664e-01,
          -3.3184e-01,  5.2587e-02],
         [ 3.1804e-01, -2.3715e-01,  5.9929e-01,  ...,  3.9293e-02,
          -1.5933e-01,  2.9268e-01],
         [ 4.2414e-01, -1.0747e-01, -3.3100e-01,  ..., -3.6298e-02,
           2.2127e-01,  5.8332e-01]],

        [[-5.3925e+00,  1.2785e+00, -1.7428e+00,  ...,  1.6187e+00,
           2.6666e+00,  6.3102e-01],
         [-7.2190e-01, -9.0366e-02, -3.7054e-01,  ..., -4.8731e-02,
           5.0303e-02,  4.0432e-02],
         [ 3.2142e-02, -5.6480e-01, -2.0480e-01,  ...,  6.2426e-02,
          -1.1226e-01,  5.0907e-03],
         ...,
         [-2.0149e-01,  2.5538e-01,  1.1748e-04,  ...,  4.8664e-01,
          -3.3184e-01,  5.2587e-02],
         [ 3.1804e-01, -2.3715e-01,  5.9929e-01,  ...,  3.9292e-02,
          -1.5933e-01,  2.9268e-01],
         [ 1.5856e-02,  5.2091e-02, -8.0247e-02,  ...,  8.5830e-02,
          -4.9585e-01,  7.4877e-02]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ¦ T_txt=24
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 24, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 24, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 24, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 24])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 24, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 24, 64])
ğŸŸ¦ out.shape=torch.Size([3, 24, 512])
ğŸŸ¦ out.shape=torch.Size([3, 24, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 24, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 24, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.7653e+00,  1.1008e+00, -1.8155e+00,  ...,  2.3020e+00,
           2.1681e+00,  1.0300e+00],
         [-6.6199e-01, -7.7735e-02, -5.1326e-01,  ..., -2.2643e-01,
           1.6844e-01, -1.5885e-02],
         [ 2.8691e-02, -6.1208e-01, -4.2365e-01,  ..., -2.2236e-01,
           9.9554e-02,  1.2917e-02],
         ...,
         [-3.2457e-02, -7.0138e-02,  9.0337e-02,  ...,  1.3302e-01,
          -1.7736e-01, -1.4500e-01],
         [ 4.0329e-01, -6.2026e-01,  5.3886e-01,  ..., -5.2571e-01,
          -7.1158e-01,  5.5968e-01],
         [ 2.1613e-01, -9.8405e-02, -5.4292e-01,  ..., -1.1372e-01,
          -5.8016e-01, -3.1952e-01]],

        [[-5.7653e+00,  1.1008e+00, -1.8155e+00,  ...,  2.3020e+00,
           2.1681e+00,  1.0300e+00],
         [-6.6199e-01, -7.7735e-02, -5.1326e-01,  ..., -2.2643e-01,
           1.6844e-01, -1.5885e-02],
         [ 2.8691e-02, -6.1208e-01, -4.2365e-01,  ..., -2.2236e-01,
           9.9554e-02,  1.2917e-02],
         ...,
         [-3.2457e-02, -7.0138e-02,  9.0337e-02,  ...,  1.3302e-01,
          -1.7736e-01, -1.4500e-01],
         [ 2.3910e-01, -5.2146e-01,  5.6144e-01,  ..., -1.4774e-01,
          -1.7351e-01, -1.3322e-03],
         [ 2.4359e-01, -3.0873e-01, -2.8838e-01,  ..., -2.7578e-01,
           3.2443e-01,  3.4007e-02]],

        [[-5.7653e+00,  1.1008e+00, -1.8155e+00,  ...,  2.3020e+00,
           2.1681e+00,  1.0300e+00],
         [-6.6199e-01, -7.7735e-02, -5.1326e-01,  ..., -2.2643e-01,
           1.6844e-01, -1.5885e-02],
         [ 2.8692e-02, -6.1208e-01, -4.2365e-01,  ..., -2.2236e-01,
           9.9554e-02,  1.2916e-02],
         ...,
         [-3.2457e-02, -7.0138e-02,  9.0337e-02,  ...,  1.3302e-01,
          -1.7736e-01, -1.4500e-01],
         [ 2.3910e-01, -5.2146e-01,  5.6144e-01,  ..., -1.4774e-01,
          -1.7351e-01, -1.3321e-03],
         [ 2.4885e-01, -9.8191e-02, -3.1634e-01,  ..., -3.1487e-02,
          -4.7194e-01, -2.4448e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ¦ T_txt=24
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 24, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 24, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 24, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 24])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 24, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 24, 64])
ğŸŸ¦ out.shape=torch.Size([3, 24, 512])
ğŸŸ¦ out.shape=torch.Size([3, 24, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 24, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 24, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.8693e+00,  9.3745e-01, -1.8379e+00,  ...,  2.4698e+00,
           2.0660e+00,  1.2787e+00],
         [-6.8941e-01,  2.4615e-01, -4.9576e-01,  ..., -2.5218e-01,
           1.5029e-01,  7.9583e-02],
         [ 1.1727e-01, -2.8995e-01, -5.4170e-01,  ..., -1.3670e-01,
           7.0986e-02,  1.0259e-01],
         ...,
         [ 1.9294e-01,  1.1087e-01,  1.4712e-01,  ..., -1.6247e-04,
          -3.1137e-02,  1.7252e-01],
         [ 5.4977e-01, -8.9901e-02,  9.6283e-01,  ..., -5.4294e-01,
          -6.7182e-01,  1.0580e+00],
         [ 3.4921e-01,  2.5731e-01, -5.2416e-01,  ..., -1.0038e-01,
          -7.9638e-01, -2.4247e-01]],

        [[-5.8693e+00,  9.3745e-01, -1.8379e+00,  ...,  2.4698e+00,
           2.0660e+00,  1.2787e+00],
         [-6.8941e-01,  2.4615e-01, -4.9576e-01,  ..., -2.5218e-01,
           1.5029e-01,  7.9583e-02],
         [ 1.1727e-01, -2.8995e-01, -5.4170e-01,  ..., -1.3670e-01,
           7.0986e-02,  1.0259e-01],
         ...,
         [ 1.9294e-01,  1.1087e-01,  1.4712e-01,  ..., -1.6247e-04,
          -3.1137e-02,  1.7252e-01],
         [ 4.2944e-01,  2.9350e-03,  9.1485e-01,  ..., -1.6032e-01,
          -1.7634e-01,  2.9936e-01],
         [ 2.1023e-02, -6.2654e-02, -4.0409e-01,  ..., -4.3246e-01,
           2.9215e-01,  3.4777e-02]],

        [[-5.8693e+00,  9.3745e-01, -1.8379e+00,  ...,  2.4698e+00,
           2.0660e+00,  1.2787e+00],
         [-6.8941e-01,  2.4615e-01, -4.9576e-01,  ..., -2.5218e-01,
           1.5029e-01,  7.9583e-02],
         [ 1.1727e-01, -2.8995e-01, -5.4170e-01,  ..., -1.3670e-01,
           7.0986e-02,  1.0259e-01],
         ...,
         [ 1.9294e-01,  1.1087e-01,  1.4712e-01,  ..., -1.6239e-04,
          -3.1137e-02,  1.7252e-01],
         [ 4.2944e-01,  2.9345e-03,  9.1485e-01,  ..., -1.6032e-01,
          -1.7634e-01,  2.9936e-01],
         [ 2.7741e-01,  2.8287e-01, -2.8701e-01,  ..., -6.1591e-02,
          -6.8265e-01, -2.5316e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ¦ T_txt=24
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 24, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 24, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 24, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 24])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 24, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 24, 64])
ğŸŸ¦ out.shape=torch.Size([3, 24, 512])
ğŸŸ¦ out.shape=torch.Size([3, 24, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 24, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 24, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.6016e+00,  1.2408e+00, -1.6460e+00,  ...,  3.1029e+00,
           2.1120e+00,  1.1936e+00],
         [-5.1318e-01,  1.3069e-01, -5.7248e-01,  ..., -8.0478e-02,
           3.0336e-02, -1.3672e-01],
         [ 2.1050e-01, -6.8635e-01, -6.6328e-01,  ...,  2.2120e-01,
           3.5946e-01,  2.3200e-01],
         ...,
         [-3.8822e-02, -2.8795e-02, -6.4037e-02,  ...,  7.0275e-02,
          -2.3688e-01,  4.7767e-02],
         [ 5.0403e-01, -5.1759e-02,  9.8765e-01,  ..., -7.3353e-01,
          -7.5078e-01,  8.4942e-01],
         [ 6.4809e-01,  7.6813e-02, -2.2245e-03,  ...,  4.3426e-02,
          -8.3110e-01, -4.9535e-01]],

        [[-5.6016e+00,  1.2408e+00, -1.6460e+00,  ...,  3.1029e+00,
           2.1120e+00,  1.1936e+00],
         [-5.1318e-01,  1.3069e-01, -5.7248e-01,  ..., -8.0478e-02,
           3.0336e-02, -1.3672e-01],
         [ 2.1050e-01, -6.8635e-01, -6.6328e-01,  ...,  2.2120e-01,
           3.5946e-01,  2.3200e-01],
         ...,
         [-3.8822e-02, -2.8795e-02, -6.4037e-02,  ...,  7.0275e-02,
          -2.3688e-01,  4.7767e-02],
         [ 5.7634e-01,  1.9380e-01,  9.2979e-01,  ..., -2.2846e-02,
          -3.5429e-01,  1.9312e-01],
         [ 1.3018e-01, -4.5977e-02, -5.4057e-01,  ..., -3.2460e-01,
           2.6987e-01, -5.8595e-02]],

        [[-5.6016e+00,  1.2408e+00, -1.6460e+00,  ...,  3.1029e+00,
           2.1120e+00,  1.1936e+00],
         [-5.1318e-01,  1.3069e-01, -5.7248e-01,  ..., -8.0477e-02,
           3.0335e-02, -1.3672e-01],
         [ 2.1050e-01, -6.8635e-01, -6.6328e-01,  ...,  2.2120e-01,
           3.5946e-01,  2.3200e-01],
         ...,
         [-3.8821e-02, -2.8795e-02, -6.4037e-02,  ...,  7.0275e-02,
          -2.3688e-01,  4.7768e-02],
         [ 5.7634e-01,  1.9380e-01,  9.2979e-01,  ..., -2.2847e-02,
          -3.5430e-01,  1.9312e-01],
         [ 6.6441e-01,  2.4975e-01,  1.2501e-01,  ...,  1.7088e-02,
          -7.6693e-01, -5.6628e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ¦ T_txt=24
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 24, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 24, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 24, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 24])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 24, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 24, 64])
ğŸŸ¦ out.shape=torch.Size([3, 24, 512])
ğŸŸ¦ out.shape=torch.Size([3, 24, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 24, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 24, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.5722,  1.3828, -1.6196,  ...,  3.5095,  2.5083,  1.2801],
         [-0.7604,  0.1403, -0.7794,  ...,  0.1032,  0.1174, -0.2312],
         [-0.0521, -0.3372, -0.8223,  ...,  0.0621,  0.1464,  0.1382],
         ...,
         [-0.3888,  0.0774, -0.0618,  ..., -0.3501, -0.3116,  0.3053],
         [ 0.2792, -0.1412,  0.9258,  ..., -0.5942, -0.7232,  0.8483],
         [ 0.4279,  0.3293, -0.2094,  ...,  0.2401, -1.0083, -0.4063]],

        [[-5.5722,  1.3828, -1.6196,  ...,  3.5095,  2.5083,  1.2801],
         [-0.7604,  0.1403, -0.7794,  ...,  0.1032,  0.1174, -0.2312],
         [-0.0521, -0.3372, -0.8223,  ...,  0.0621,  0.1464,  0.1382],
         ...,
         [-0.3888,  0.0774, -0.0618,  ..., -0.3501, -0.3116,  0.3053],
         [ 0.4046,  0.1571,  0.9001,  ..., -0.0757, -0.4872,  0.2787],
         [-0.0794, -0.1273, -0.3627,  ..., -0.5834,  0.4231, -0.0958]],

        [[-5.5722,  1.3828, -1.6196,  ...,  3.5095,  2.5083,  1.2801],
         [-0.7604,  0.1403, -0.7794,  ...,  0.1032,  0.1174, -0.2312],
         [-0.0521, -0.3372, -0.8223,  ...,  0.0621,  0.1464,  0.1382],
         ...,
         [-0.3888,  0.0774, -0.0618,  ..., -0.3501, -0.3116,  0.3053],
         [ 0.4046,  0.1571,  0.9001,  ..., -0.0757, -0.4872,  0.2787],
         [ 0.4762,  0.5052, -0.1303,  ...,  0.1964, -0.9551, -0.4804]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ¦ T_txt=24
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 24, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 24, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 24, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 24])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 24, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 24, 64])
ğŸŸ¦ out.shape=torch.Size([3, 24, 512])
ğŸŸ¦ out.shape=torch.Size([3, 24, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 24, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 24, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.6640,  1.4165, -1.7391,  ...,  3.7237,  2.6647,  1.4654],
         [-0.6078, -0.0251, -1.0078,  ...,  0.0240, -0.0394, -0.4400],
         [-0.2394, -0.7447, -0.9997,  ..., -0.1766,  0.0965,  0.0557],
         ...,
         [-0.5281, -0.1149,  0.1390,  ..., -0.2932, -0.1103,  0.4421],
         [ 0.3848, -0.2618,  0.9178,  ..., -0.4372, -0.7897,  0.7416],
         [ 0.2922,  0.1570, -0.2512,  ...,  0.2008, -1.0361, -0.2140]],

        [[-5.6640,  1.4165, -1.7391,  ...,  3.7237,  2.6647,  1.4654],
         [-0.6078, -0.0251, -1.0078,  ...,  0.0240, -0.0394, -0.4400],
         [-0.2394, -0.7447, -0.9997,  ..., -0.1766,  0.0965,  0.0557],
         ...,
         [-0.5281, -0.1149,  0.1390,  ..., -0.2932, -0.1103,  0.4421],
         [ 0.3892, -0.0845,  0.9596,  ..., -0.1556, -0.4671,  0.1089],
         [-0.1628, -0.5103, -0.2968,  ..., -0.6998,  0.8058, -0.1868]],

        [[-5.6640,  1.4165, -1.7391,  ...,  3.7237,  2.6647,  1.4654],
         [-0.6078, -0.0251, -1.0078,  ...,  0.0240, -0.0394, -0.4400],
         [-0.2394, -0.7447, -0.9997,  ..., -0.1766,  0.0965,  0.0557],
         ...,
         [-0.5281, -0.1149,  0.1390,  ..., -0.2932, -0.1103,  0.4421],
         [ 0.3892, -0.0845,  0.9596,  ..., -0.1556, -0.4671,  0.1089],
         [ 0.4216,  0.2782, -0.1465,  ...,  0.1041, -0.9364, -0.4096]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ¦ T_txt=24
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 24, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 24, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 24, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 24])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 24, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 24, 64])
ğŸŸ¦ out.shape=torch.Size([3, 24, 512])
ğŸŸ¦ out.shape=torch.Size([3, 24, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 24, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 24, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.3878,  1.2637, -1.3476,  ...,  3.9388,  2.7129,  1.6259],
         [-0.6773,  0.0069, -0.7329,  ...,  0.2023,  0.1743, -0.1756],
         [-0.3587, -0.5944, -1.0050,  ...,  0.2275,  0.4650,  0.1995],
         ...,
         [-0.4809, -0.3364,  0.3896,  ..., -0.2721,  0.0814,  0.6517],
         [ 0.5905, -0.2534,  0.9877,  ..., -0.3993, -0.9285,  0.9923],
         [ 0.4333,  0.2429, -0.4584,  ...,  0.2642, -1.1859, -0.0508]],

        [[-5.3878,  1.2637, -1.3476,  ...,  3.9388,  2.7129,  1.6259],
         [-0.6773,  0.0069, -0.7329,  ...,  0.2023,  0.1743, -0.1756],
         [-0.3587, -0.5944, -1.0050,  ...,  0.2275,  0.4650,  0.1995],
         ...,
         [-0.4809, -0.3364,  0.3896,  ..., -0.2721,  0.0814,  0.6517],
         [ 0.2838, -0.0121,  1.2331,  ..., -0.1604, -0.6465,  0.4093],
         [-0.1415, -0.5685, -0.5636,  ..., -0.7246,  0.7350, -0.0069]],

        [[-5.3878,  1.2637, -1.3476,  ...,  3.9388,  2.7129,  1.6259],
         [-0.6773,  0.0069, -0.7329,  ...,  0.2023,  0.1743, -0.1756],
         [-0.3587, -0.5944, -1.0050,  ...,  0.2275,  0.4650,  0.1995],
         ...,
         [-0.4809, -0.3364,  0.3896,  ..., -0.2721,  0.0814,  0.6517],
         [ 0.2838, -0.0121,  1.2331,  ..., -0.1604, -0.6465,  0.4093],
         [ 0.6040,  0.4236, -0.3152,  ...,  0.1281, -1.1290, -0.2424]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ¦ T_txt=24
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 24, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 24, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 24, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 24])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 24, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 24, 64])
ğŸŸ¦ out.shape=torch.Size([3, 24, 512])
ğŸŸ¦ out.shape=torch.Size([3, 24, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 24, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 24, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.0959,  0.8567, -1.2666,  ...,  3.8593,  2.8167,  1.9328],
         [-0.9069, -0.3564, -0.8761,  ...,  0.1384,  0.2888, -0.1783],
         [-0.2450, -0.8774, -1.2020,  ...,  0.3088,  0.3829,  0.2829],
         ...,
         [-0.6254, -0.4265,  0.3068,  ...,  0.2125, -0.0623,  0.8132],
         [ 0.6775, -0.1358,  1.1488,  ..., -0.1645, -0.7713,  1.0117],
         [ 0.4157,  0.3295, -0.3295,  ...,  0.5478, -1.0504,  0.2880]],

        [[-5.0959,  0.8567, -1.2666,  ...,  3.8593,  2.8167,  1.9328],
         [-0.9069, -0.3564, -0.8761,  ...,  0.1384,  0.2888, -0.1783],
         [-0.2450, -0.8774, -1.2020,  ...,  0.3088,  0.3829,  0.2829],
         ...,
         [-0.6254, -0.4265,  0.3068,  ...,  0.2125, -0.0623,  0.8132],
         [ 0.3065,  0.0474,  1.2372,  ...,  0.0213, -0.4936,  0.4731],
         [ 0.1424, -0.2069, -0.5607,  ..., -0.8078,  0.9837,  0.1046]],

        [[-5.0959,  0.8567, -1.2666,  ...,  3.8593,  2.8167,  1.9328],
         [-0.9069, -0.3564, -0.8761,  ...,  0.1384,  0.2888, -0.1783],
         [-0.2450, -0.8774, -1.2020,  ...,  0.3088,  0.3829,  0.2829],
         ...,
         [-0.6254, -0.4265,  0.3068,  ...,  0.2125, -0.0623,  0.8132],
         [ 0.3065,  0.0474,  1.2372,  ...,  0.0213, -0.4936,  0.4731],
         [ 0.6896,  0.4565, -0.2549,  ...,  0.4564, -1.0424,  0.0941]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ¦ T_txt=24
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 24, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 24, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 24, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 24])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 24, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 24, 64])
ğŸŸ¦ out.shape=torch.Size([3, 24, 512])
ğŸŸ¦ out.shape=torch.Size([3, 24, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 24, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 24, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.8058e+00,  7.3018e-01, -1.0989e+00,  ...,  3.8324e+00,
           2.7810e+00,  1.7821e+00],
         [-7.0377e-01, -6.3927e-01, -6.2966e-01,  ..., -3.5870e-02,
           1.7194e-01, -3.3438e-01],
         [-1.6488e-01, -7.0103e-01, -9.2414e-01,  ...,  5.3185e-01,
           1.6227e-01, -1.6698e-01],
         ...,
         [-7.0603e-01, -5.4394e-01,  1.3088e-01,  ..., -2.3748e-01,
           1.0240e-02,  6.0804e-01],
         [ 8.3226e-01,  2.3439e-01,  1.0905e+00,  ..., -2.5745e-01,
          -4.3746e-01,  8.1926e-01],
         [ 1.2331e-01,  4.3793e-01, -7.6396e-01,  ...,  8.5062e-01,
          -1.4413e+00,  7.2748e-02]],

        [[-4.8058e+00,  7.3018e-01, -1.0989e+00,  ...,  3.8324e+00,
           2.7810e+00,  1.7821e+00],
         [-7.0377e-01, -6.3927e-01, -6.2966e-01,  ..., -3.5870e-02,
           1.7194e-01, -3.3438e-01],
         [-1.6488e-01, -7.0103e-01, -9.2414e-01,  ...,  5.3185e-01,
           1.6227e-01, -1.6698e-01],
         ...,
         [-7.0603e-01, -5.4394e-01,  1.3088e-01,  ..., -2.3748e-01,
           1.0240e-02,  6.0804e-01],
         [ 4.2245e-01,  2.5993e-01,  1.3526e+00,  ..., -1.4451e-02,
          -4.4267e-01,  2.3606e-01],
         [-3.3330e-01,  2.1282e-01, -8.5601e-01,  ..., -7.4651e-01,
           8.6654e-01, -4.7342e-03]],

        [[-4.8058e+00,  7.3018e-01, -1.0989e+00,  ...,  3.8324e+00,
           2.7810e+00,  1.7821e+00],
         [-7.0377e-01, -6.3927e-01, -6.2966e-01,  ..., -3.5870e-02,
           1.7194e-01, -3.3437e-01],
         [-1.6488e-01, -7.0103e-01, -9.2414e-01,  ...,  5.3185e-01,
           1.6227e-01, -1.6698e-01],
         ...,
         [-7.0603e-01, -5.4394e-01,  1.3088e-01,  ..., -2.3748e-01,
           1.0241e-02,  6.0804e-01],
         [ 4.2245e-01,  2.5993e-01,  1.3526e+00,  ..., -1.4452e-02,
          -4.4267e-01,  2.3606e-01],
         [ 3.8969e-01,  5.6786e-01, -6.7377e-01,  ...,  6.9383e-01,
          -1.5138e+00, -1.8602e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ¦ T_txt=24
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 24, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 24, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 24, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 24])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 24, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 24, 64])
ğŸŸ¦ out.shape=torch.Size([3, 24, 512])
ğŸŸ¦ out.shape=torch.Size([3, 24, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 24, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 24, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.5423,  0.4867, -1.3078,  ...,  4.0570,  2.7591,  1.7055],
         [-0.7944, -1.0986, -0.8873,  ..., -0.3006, -0.1496, -0.3139],
         [ 0.3003, -0.6765, -0.9426,  ...,  0.2994,  0.2125, -0.2227],
         ...,
         [-0.6692, -0.5936, -0.6865,  ..., -0.2726,  0.2328,  0.2570],
         [ 0.9205,  0.2934,  0.6854,  ..., -0.8828, -0.2170,  0.6854],
         [ 0.0809,  0.3825, -0.8883,  ...,  0.7028, -1.3656,  0.1694]],

        [[-4.5423,  0.4867, -1.3078,  ...,  4.0570,  2.7591,  1.7055],
         [-0.7944, -1.0986, -0.8873,  ..., -0.3006, -0.1496, -0.3139],
         [ 0.3003, -0.6765, -0.9426,  ...,  0.2994,  0.2125, -0.2227],
         ...,
         [-0.6692, -0.5936, -0.6865,  ..., -0.2726,  0.2328,  0.2570],
         [ 0.4582,  0.3000,  0.4645,  ..., -0.3277, -0.2306,  0.3756],
         [-0.2928,  0.2379, -1.2926,  ..., -1.2829,  0.4944,  0.1044]],

        [[-4.5423,  0.4867, -1.3078,  ...,  4.0570,  2.7591,  1.7055],
         [-0.7944, -1.0986, -0.8873,  ..., -0.3006, -0.1496, -0.3139],
         [ 0.3003, -0.6765, -0.9426,  ...,  0.2994,  0.2125, -0.2227],
         ...,
         [-0.6692, -0.5936, -0.6865,  ..., -0.2726,  0.2328,  0.2570],
         [ 0.4582,  0.3000,  0.4645,  ..., -0.3277, -0.2306,  0.3756],
         [ 0.3026,  0.4890, -0.8478,  ...,  0.4644, -1.4480,  0.0626]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ¦ T_txt=24
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 24, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 24, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 24, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 24])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 24, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 24, 64])
ğŸŸ¦ out.shape=torch.Size([3, 24, 512])
ğŸŸ¦ out.shape=torch.Size([3, 24, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 24, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 24, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.4194,  0.4068, -1.0771,  ...,  4.0394,  2.7712,  1.5921],
         [-1.0025, -1.3143, -1.0197,  ..., -0.7655, -0.0488, -0.4858],
         [ 0.0073, -0.6469, -0.9511,  ...,  0.0354,  0.6350,  0.2235],
         ...,
         [-0.9102, -0.4974, -0.5201,  ...,  0.0245,  0.5392,  0.1246],
         [ 1.0983, -0.3486,  0.5914,  ..., -0.4843,  0.4383,  1.0968],
         [-0.2509,  0.6452, -0.7794,  ...,  0.9288, -0.9705,  0.4292]],

        [[-4.4194,  0.4068, -1.0771,  ...,  4.0394,  2.7712,  1.5921],
         [-1.0025, -1.3143, -1.0197,  ..., -0.7655, -0.0488, -0.4858],
         [ 0.0073, -0.6469, -0.9511,  ...,  0.0354,  0.6350,  0.2235],
         ...,
         [-0.9102, -0.4974, -0.5201,  ...,  0.0245,  0.5392,  0.1246],
         [ 0.6006, -0.3519,  0.2725,  ...,  0.0382, -0.0264,  0.6983],
         [ 0.3860,  0.4136, -1.3120,  ..., -1.2965,  0.5401,  0.2613]],

        [[-4.4194,  0.4068, -1.0771,  ...,  4.0394,  2.7712,  1.5921],
         [-1.0025, -1.3143, -1.0197,  ..., -0.7654, -0.0488, -0.4858],
         [ 0.0073, -0.6469, -0.9511,  ...,  0.0354,  0.6350,  0.2235],
         ...,
         [-0.9102, -0.4974, -0.5201,  ...,  0.0245,  0.5392,  0.1246],
         [ 0.6006, -0.3519,  0.2725,  ...,  0.0382, -0.0264,  0.6983],
         [ 0.1116,  0.6736, -0.7352,  ...,  0.7210, -1.1174,  0.4663]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ¦ T_txt=24
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 24, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 24, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 24, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 24])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 24, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 24, 64])
ğŸŸ¦ out.shape=torch.Size([3, 24, 512])
ğŸŸ¦ out.shape=torch.Size([3, 24, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 24, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 24, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.6486e+00,  4.3703e-01, -1.0679e+00,  ...,  4.0760e+00,
           2.7873e+00,  1.4896e+00],
         [-9.1824e-01, -1.6641e+00, -8.0367e-01,  ..., -1.0706e+00,
          -9.7790e-02,  8.5558e-02],
         [-3.2957e-01, -1.1621e+00, -1.2796e+00,  ..., -3.9725e-01,
           5.5436e-01,  2.3460e-01],
         ...,
         [-1.7840e+00, -4.7463e-01, -2.9961e-01,  ...,  7.6514e-01,
           4.4933e-01,  4.2029e-01],
         [ 2.8296e-03,  2.9193e-01,  6.1430e-01,  ..., -6.6745e-02,
           4.1248e-01,  1.1794e+00],
         [-1.0622e+00,  8.6563e-01, -8.9686e-01,  ...,  1.2639e+00,
          -9.8401e-01,  4.1746e-01]],

        [[-4.6486e+00,  4.3703e-01, -1.0679e+00,  ...,  4.0760e+00,
           2.7873e+00,  1.4896e+00],
         [-9.1824e-01, -1.6641e+00, -8.0367e-01,  ..., -1.0706e+00,
          -9.7790e-02,  8.5558e-02],
         [-3.2957e-01, -1.1621e+00, -1.2796e+00,  ..., -3.9725e-01,
           5.5436e-01,  2.3460e-01],
         ...,
         [-1.7840e+00, -4.7463e-01, -2.9961e-01,  ...,  7.6514e-01,
           4.4933e-01,  4.2029e-01],
         [-7.4074e-01,  8.6397e-02,  5.8763e-01,  ...,  3.0829e-01,
           6.4791e-02,  7.7100e-01],
         [-9.7338e-02,  5.0054e-01, -1.0022e+00,  ..., -9.3801e-01,
           2.8831e-01,  3.5120e-01]],

        [[-4.6486e+00,  4.3703e-01, -1.0679e+00,  ...,  4.0760e+00,
           2.7874e+00,  1.4896e+00],
         [-9.1824e-01, -1.6641e+00, -8.0367e-01,  ..., -1.0706e+00,
          -9.7787e-02,  8.5559e-02],
         [-3.2957e-01, -1.1621e+00, -1.2796e+00,  ..., -3.9725e-01,
           5.5436e-01,  2.3460e-01],
         ...,
         [-1.7840e+00, -4.7463e-01, -2.9961e-01,  ...,  7.6514e-01,
           4.4933e-01,  4.2029e-01],
         [-7.4074e-01,  8.6398e-02,  5.8763e-01,  ...,  3.0829e-01,
           6.4792e-02,  7.7100e-01],
         [-7.0177e-01,  8.1621e-01, -8.7412e-01,  ...,  9.3389e-01,
          -1.0631e+00,  5.6727e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ¦ T_txt=24
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 24, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 24, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 24, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 24])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 24, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 24, 64])
ğŸŸ¦ out.shape=torch.Size([3, 24, 512])
ğŸŸ¦ out.shape=torch.Size([3, 24, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 24, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 24, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.6982,  0.6115, -1.1511,  ...,  3.9602,  2.6816,  1.0754],
         [-0.8318, -2.6615, -1.2791,  ..., -1.1889,  0.2650, -0.4843],
         [-0.0270, -1.6365, -1.4973,  ..., -0.5320,  0.8756,  0.4654],
         ...,
         [-1.0176, -0.0554, -0.8662,  ...,  1.2393,  0.3358,  0.2461],
         [ 0.3004,  0.7089, -0.3612,  ...,  0.0641,  0.5492,  1.4825],
         [-0.5257,  1.0484, -1.3466,  ...,  1.4207, -1.5212, -0.0478]],

        [[-4.6982,  0.6115, -1.1511,  ...,  3.9602,  2.6816,  1.0754],
         [-0.8318, -2.6615, -1.2791,  ..., -1.1889,  0.2650, -0.4843],
         [-0.0270, -1.6365, -1.4973,  ..., -0.5320,  0.8756,  0.4654],
         ...,
         [-1.0176, -0.0554, -0.8662,  ...,  1.2393,  0.3358,  0.2461],
         [-0.5679,  0.5445,  0.1623,  ...,  0.5058,  0.1193,  1.3217],
         [-0.6684,  0.7412, -0.7458,  ..., -0.2329,  0.1675, -0.0535]],

        [[-4.6982,  0.6115, -1.1511,  ...,  3.9602,  2.6816,  1.0754],
         [-0.8318, -2.6615, -1.2791,  ..., -1.1889,  0.2650, -0.4843],
         [-0.0270, -1.6365, -1.4973,  ..., -0.5320,  0.8756,  0.4654],
         ...,
         [-1.0176, -0.0554, -0.8662,  ...,  1.2393,  0.3358,  0.2461],
         [-0.5679,  0.5445,  0.1623,  ...,  0.5058,  0.1193,  1.3217],
         [-0.2071,  0.9512, -1.3276,  ...,  1.0895, -1.5700,  0.1267]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ¦ T_txt=24
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 24, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 24, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 24, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 24])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 24, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 24, 64])
ğŸŸ¦ out.shape=torch.Size([3, 24, 512])
ğŸŸ¦ out.shape=torch.Size([3, 24, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 24, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 24, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.1992e+00,  1.0861e-01, -1.3292e+00,  ...,  4.5845e+00,
           3.1037e+00,  6.4127e-01],
         [-1.7888e+00, -3.0735e+00, -9.0352e-01,  ..., -6.4027e-01,
          -3.6426e-01, -1.2033e-01],
         [ 6.7153e-01, -1.5127e+00, -1.2408e+00,  ...,  3.2038e-01,
           1.0818e+00,  3.0631e-01],
         ...,
         [-1.2233e+00,  7.7000e-03, -9.8320e-01,  ...,  1.7667e+00,
           1.6749e-04,  4.6981e-01],
         [ 1.7288e-01,  6.4767e-01, -2.9748e-01,  ...,  2.9216e-02,
           8.5137e-01,  1.8736e+00],
         [-3.1869e-02,  5.0881e-01, -1.5616e+00,  ...,  1.9469e+00,
          -1.5413e+00,  3.3619e-01]],

        [[-4.1992e+00,  1.0861e-01, -1.3292e+00,  ...,  4.5845e+00,
           3.1037e+00,  6.4127e-01],
         [-1.7888e+00, -3.0735e+00, -9.0352e-01,  ..., -6.4027e-01,
          -3.6426e-01, -1.2033e-01],
         [ 6.7153e-01, -1.5127e+00, -1.2408e+00,  ...,  3.2038e-01,
           1.0818e+00,  3.0631e-01],
         ...,
         [-1.2233e+00,  7.7000e-03, -9.8320e-01,  ...,  1.7667e+00,
           1.6749e-04,  4.6981e-01],
         [-5.7463e-01,  6.4741e-01,  3.6707e-01,  ...,  8.4325e-01,
          -5.7199e-02,  1.5996e+00],
         [-6.1291e-01,  2.1742e-01, -6.1155e-01,  ..., -1.5666e-01,
          -2.4173e-01,  6.1973e-01]],

        [[-4.1992e+00,  1.0861e-01, -1.3292e+00,  ...,  4.5845e+00,
           3.1037e+00,  6.4127e-01],
         [-1.7888e+00, -3.0735e+00, -9.0352e-01,  ..., -6.4027e-01,
          -3.6425e-01, -1.2033e-01],
         [ 6.7153e-01, -1.5127e+00, -1.2408e+00,  ...,  3.2038e-01,
           1.0818e+00,  3.0631e-01],
         ...,
         [-1.2233e+00,  7.6981e-03, -9.8320e-01,  ...,  1.7667e+00,
           1.6719e-04,  4.6981e-01],
         [-5.7463e-01,  6.4741e-01,  3.6707e-01,  ...,  8.4325e-01,
          -5.7198e-02,  1.5996e+00],
         [ 2.2895e-01,  4.0308e-01, -1.5890e+00,  ...,  1.6199e+00,
          -1.5787e+00,  4.8819e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ¦ T_txt=24
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 24, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 24, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 24, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 24])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 24, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 24, 64])
ğŸŸ¦ out.shape=torch.Size([3, 24, 512])
ğŸŸ¦ out.shape=torch.Size([3, 24, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 24, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 24, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-3.4956, -0.4549, -1.3173,  ...,  5.3489,  3.8643,  0.0495],
         [-1.1846, -2.7309, -0.3251,  ..., -0.5469, -0.2345,  0.0928],
         [ 0.3590, -0.8857, -1.3176,  ...,  0.7098,  1.7219,  0.2027],
         ...,
         [-0.3139,  0.4464, -0.5054,  ...,  2.4753,  0.8644,  0.2732],
         [ 0.9831,  1.0852,  0.3028,  ...,  0.5779,  2.4249,  1.5966],
         [ 0.6183,  0.9216, -1.7594,  ...,  1.9905, -1.1381,  0.1891]],

        [[-3.4956, -0.4549, -1.3173,  ...,  5.3489,  3.8643,  0.0495],
         [-1.1846, -2.7309, -0.3251,  ..., -0.5469, -0.2345,  0.0928],
         [ 0.3590, -0.8857, -1.3176,  ...,  0.7098,  1.7219,  0.2027],
         ...,
         [-0.3139,  0.4464, -0.5054,  ...,  2.4753,  0.8644,  0.2732],
         [ 0.2531,  1.0129,  0.9571,  ...,  1.5907,  1.5373,  1.0220],
         [-0.1360,  0.7697,  0.0640,  ..., -0.0583,  0.4507,  0.4356]],

        [[-3.4956, -0.4549, -1.3173,  ...,  5.3489,  3.8643,  0.0495],
         [-1.1846, -2.7309, -0.3251,  ..., -0.5469, -0.2345,  0.0928],
         [ 0.3590, -0.8857, -1.3176,  ...,  0.7098,  1.7219,  0.2027],
         ...,
         [-0.3139,  0.4464, -0.5054,  ...,  2.4753,  0.8644,  0.2732],
         [ 0.2531,  1.0129,  0.9571,  ...,  1.5907,  1.5373,  1.0219],
         [ 0.9474,  0.6222, -1.7576,  ...,  1.7126, -1.1423,  0.3601]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ¦ T_txt=24
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 24, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 24, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 24, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 24])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 24, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 24, 64])
ğŸŸ¦ out.shape=torch.Size([3, 24, 512])
ğŸŸ¦ out.shape=torch.Size([3, 24, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 24, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 24, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-2.3185e+00, -1.3191e+00, -1.7786e+00,  ...,  8.3678e+00,
           3.3047e+00, -5.9097e-01],
         [-8.1188e-01, -3.2357e+00, -3.2882e-02,  ...,  1.3220e+00,
          -3.9638e-01,  9.7235e-01],
         [ 6.8207e-01, -7.9400e-01, -2.6728e-01,  ...,  3.2716e+00,
           1.7577e+00,  8.6897e-01],
         ...,
         [-1.2651e+00, -5.7598e-01, -2.5607e-01,  ...,  5.3449e+00,
          -6.3446e-01,  3.6178e-01],
         [ 1.1300e-01,  8.1261e-03,  1.9817e-01,  ...,  3.1213e+00,
           2.6491e+00,  1.7652e+00],
         [ 4.3934e-01,  1.9984e+00, -1.5469e+00,  ...,  3.7783e+00,
          -1.2135e+00,  1.0420e+00]],

        [[-2.3185e+00, -1.3191e+00, -1.7786e+00,  ...,  8.3678e+00,
           3.3047e+00, -5.9097e-01],
         [-8.1188e-01, -3.2357e+00, -3.2882e-02,  ...,  1.3220e+00,
          -3.9638e-01,  9.7235e-01],
         [ 6.8207e-01, -7.9400e-01, -2.6728e-01,  ...,  3.2716e+00,
           1.7577e+00,  8.6897e-01],
         ...,
         [-1.2651e+00, -5.7598e-01, -2.5607e-01,  ...,  5.3449e+00,
          -6.3446e-01,  3.6178e-01],
         [-2.2489e-01,  1.7957e-01,  4.9832e-01,  ...,  3.6873e+00,
           1.4884e+00,  1.2771e+00],
         [-1.2323e+00,  8.8369e-01,  7.2427e-01,  ...,  4.9060e-01,
           3.3909e-01,  1.7801e+00]],

        [[-2.3185e+00, -1.3191e+00, -1.7786e+00,  ...,  8.3678e+00,
           3.3047e+00, -5.9097e-01],
         [-8.1188e-01, -3.2357e+00, -3.2883e-02,  ...,  1.3220e+00,
          -3.9638e-01,  9.7235e-01],
         [ 6.8208e-01, -7.9400e-01, -2.6728e-01,  ...,  3.2716e+00,
           1.7577e+00,  8.6897e-01],
         ...,
         [-1.2651e+00, -5.7599e-01, -2.5607e-01,  ...,  5.3449e+00,
          -6.3446e-01,  3.6177e-01],
         [-2.2489e-01,  1.7957e-01,  4.9832e-01,  ...,  3.6873e+00,
           1.4885e+00,  1.2771e+00],
         [ 7.2441e-01,  1.7324e+00, -1.6217e+00,  ...,  3.3483e+00,
          -1.1308e+00,  1.0826e+00]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 24, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 24]), use_cached_media=False
ğŸŸ¦ T_txt=24
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 24, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 24, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 24, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 24])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 24, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 24, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 24, 64])
ğŸŸ¦ out.shape=torch.Size([3, 24, 512])
ğŸŸ¦ out.shape=torch.Size([3, 24, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 24, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 24, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 24, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-1.2009, -0.4256,  0.9579,  ...,  3.0081,  1.0086, -0.1812],
         [-0.2749, -1.1022, -0.6093,  ...,  1.7677, -1.5354, -0.1590],
         [ 0.9989,  0.1369, -0.1196,  ...,  5.2063,  0.3365, -0.3707],
         ...,
         [-2.0599, -0.3107,  0.2120,  ...,  6.8373, -1.3011, -1.2283],
         [-0.4712,  0.2593,  0.7816,  ...,  4.7891,  1.3394,  1.2857],
         [-0.0882,  2.4424, -0.8261,  ...,  4.8853, -2.8029,  0.2455]],

        [[-1.2009, -0.4256,  0.9579,  ...,  3.0081,  1.0086, -0.1812],
         [-0.2749, -1.1022, -0.6093,  ...,  1.7677, -1.5354, -0.1590],
         [ 0.9989,  0.1369, -0.1196,  ...,  5.2063,  0.3365, -0.3707],
         ...,
         [-2.0599, -0.3107,  0.2120,  ...,  6.8373, -1.3011, -1.2283],
         [-0.4905,  0.3212,  1.3305,  ...,  5.4371,  0.2796,  0.7576],
         [-0.7309,  1.3117,  1.6397,  ...,  2.2348, -1.4950,  0.7095]],

        [[-1.2009, -0.4256,  0.9579,  ...,  3.0081,  1.0086, -0.1812],
         [-0.2749, -1.1022, -0.6093,  ...,  1.7677, -1.5354, -0.1590],
         [ 0.9989,  0.1369, -0.1196,  ...,  5.2063,  0.3365, -0.3707],
         ...,
         [-2.0599, -0.3107,  0.2120,  ...,  6.8373, -1.3011, -1.2283],
         [-0.4905,  0.3212,  1.3305,  ...,  5.4371,  0.2796,  0.7576],
         [ 0.3084,  2.2825, -0.8608,  ...,  4.4687, -2.7245,  0.1768]]]), None)
ğŸŸ© FlamingoLMMixinã®é †ä¼æ’­å®Œäº†
ğŸŸ© FlamingoLMMixinã®é †ä¼æ’­é–‹å§‹ input_ids.shape=torch.Size([3, 25]), input_ids.dtype=torch.int64, None if attention_mask is None else attention_mask.shape=torch.Size([3, 25]), dict_keys(['prefix_mask', 'sequence_id', 'past_key_values', 'use_cache', 'return_dict'])
ğŸŸ¦ media_locations.shape=torch.Size([3, 25]), media_locations.dtype=torch.bool
ğŸŸ¦ use_cached_media_locations=False
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ¦ T_txt=25
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 25, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 25, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 25, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 25])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 25, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 25, 64])
ğŸŸ¦ out.shape=torch.Size([3, 25, 512])
ğŸŸ¦ out.shape=torch.Size([3, 25, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 25, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 25, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-0.2093, -0.0591,  0.0653,  ...,  0.4109, -0.3524,  0.3726],
         [-0.0174, -0.1497,  0.0368,  ...,  0.1042,  0.0032,  0.4746],
         [-0.0191, -0.1369, -0.1287,  ...,  0.1608, -0.1576,  0.1995],
         ...,
         [ 0.0244,  0.0468,  0.4299,  ...,  0.0655, -0.0743,  0.4537],
         [ 0.1546, -0.2127, -0.0173,  ...,  0.0720, -0.0731,  0.4898],
         [ 0.1677,  0.0393,  0.0331,  ...,  0.3379,  0.0133,  0.1894]],

        [[-0.2093, -0.0591,  0.0653,  ...,  0.4109, -0.3524,  0.3726],
         [-0.0174, -0.1497,  0.0368,  ...,  0.1042,  0.0032,  0.4746],
         [-0.0191, -0.1369, -0.1287,  ...,  0.1608, -0.1576,  0.1995],
         ...,
         [-0.0557,  0.0681,  0.4820,  ..., -0.0311, -0.3772,  0.7188],
         [-0.0100,  0.0373,  0.1066,  ...,  0.1400, -0.2549,  0.3483],
         [ 0.0777, -0.0032,  0.0245,  ...,  0.0613, -0.0327, -0.0114]],

        [[-0.2093, -0.0591,  0.0653,  ...,  0.4109, -0.3524,  0.3726],
         [-0.0174, -0.1497,  0.0368,  ...,  0.1042,  0.0032,  0.4746],
         [-0.0191, -0.1369, -0.1287,  ...,  0.1608, -0.1576,  0.1995],
         ...,
         [ 0.0244,  0.0468,  0.4299,  ...,  0.0655, -0.0743,  0.4537],
         [-0.0297,  0.0205,  0.1009,  ...,  0.1497, -0.2603,  0.3349],
         [ 0.0805, -0.0064,  0.0253,  ...,  0.0659, -0.0258, -0.0134]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ¦ T_txt=25
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 25, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 25, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 25, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 25])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 25, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 25, 64])
ğŸŸ¦ out.shape=torch.Size([3, 25, 512])
ğŸŸ¦ out.shape=torch.Size([3, 25, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 25, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 25, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-0.0762, -0.3746,  0.1300,  ...,  0.1017, -0.0332,  0.2191],
         [-0.0236, -0.1139, -0.0499,  ...,  0.0464,  0.0973,  0.4798],
         [ 0.0476, -0.1903,  0.0666,  ..., -0.0123, -0.0800,  0.3086],
         ...,
         [-0.0708,  0.0919,  0.6011,  ...,  0.0187, -0.1797,  0.5978],
         [ 0.2166, -0.1439, -0.1998,  ..., -0.2547, -0.1789,  0.4334],
         [ 0.1441,  0.0809,  0.1581,  ...,  0.2499,  0.1149,  0.2712]],

        [[-0.0762, -0.3746,  0.1300,  ...,  0.1017, -0.0332,  0.2191],
         [-0.0236, -0.1139, -0.0499,  ...,  0.0464,  0.0973,  0.4798],
         [ 0.0476, -0.1903,  0.0666,  ..., -0.0123, -0.0800,  0.3086],
         ...,
         [ 0.1335,  0.0972,  0.4912,  ..., -0.0506, -0.4505,  0.8139],
         [ 0.1429,  0.0541,  0.0068,  ...,  0.0633, -0.3146,  0.3919],
         [ 0.0919,  0.0096,  0.0307,  ..., -0.0081, -0.0136,  0.1322]],

        [[-0.0762, -0.3746,  0.1300,  ...,  0.1017, -0.0332,  0.2191],
         [-0.0236, -0.1139, -0.0499,  ...,  0.0464,  0.0973,  0.4798],
         [ 0.0476, -0.1903,  0.0666,  ..., -0.0123, -0.0800,  0.3086],
         ...,
         [-0.0708,  0.0919,  0.6011,  ...,  0.0187, -0.1797,  0.5978],
         [ 0.1144,  0.0266,  0.0062,  ...,  0.0471, -0.3277,  0.3944],
         [ 0.0979,  0.0105,  0.0254,  ..., -0.0150, -0.0107,  0.1301]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ¦ T_txt=25
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 25, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 25, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 25, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 25])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 25, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 25, 64])
ğŸŸ¦ out.shape=torch.Size([3, 25, 512])
ğŸŸ¦ out.shape=torch.Size([3, 25, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 25, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 25, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-0.0423, -0.4800,  0.0985,  ..., -0.1247,  0.1871, -0.2268],
         [-0.0501, -0.1131, -0.1332,  ...,  0.1946,  0.1566,  0.3318],
         [-0.0369, -0.1714,  0.2051,  ...,  0.1376, -0.1982,  0.2490],
         ...,
         [ 0.0758, -0.1454,  0.6495,  ..., -0.1463, -0.0908,  0.5520],
         [ 0.2193, -0.2403, -0.1173,  ..., -0.1467, -0.0574,  0.2919],
         [ 0.3373, -0.2962,  0.0885,  ...,  0.2633,  0.1972,  0.1149]],

        [[-0.0423, -0.4800,  0.0985,  ..., -0.1247,  0.1871, -0.2268],
         [-0.0501, -0.1131, -0.1332,  ...,  0.1946,  0.1566,  0.3318],
         [-0.0369, -0.1714,  0.2051,  ...,  0.1376, -0.1982,  0.2490],
         ...,
         [ 0.2737, -0.1982,  0.2150,  ..., -0.0381, -0.3880,  0.8100],
         [ 0.3451, -0.3134, -0.1434,  ...,  0.0484, -0.2695,  0.1470],
         [-0.1392,  0.0040, -0.0138,  ...,  0.0598, -0.0136,  0.0108]],

        [[-0.0423, -0.4800,  0.0985,  ..., -0.1247,  0.1871, -0.2268],
         [-0.0501, -0.1131, -0.1332,  ...,  0.1946,  0.1566,  0.3318],
         [-0.0369, -0.1714,  0.2051,  ...,  0.1376, -0.1982,  0.2490],
         ...,
         [ 0.0758, -0.1454,  0.6495,  ..., -0.1463, -0.0908,  0.5520],
         [ 0.3490, -0.3337, -0.1414,  ...,  0.0240, -0.2785,  0.1427],
         [-0.1252,  0.0105, -0.0231,  ...,  0.0557,  0.0091,  0.0064]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ¦ T_txt=25
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 25, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 25, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 25, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 25])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 25, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 25, 64])
ğŸŸ¦ out.shape=torch.Size([3, 25, 512])
ğŸŸ¦ out.shape=torch.Size([3, 25, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 25, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 25, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-0.6808, -0.0752, -0.2681,  ..., -0.1388, -0.2275, -0.2143],
         [-0.2353, -0.1768, -0.1707,  ...,  0.0178,  0.0832,  0.2217],
         [ 0.1139, -0.0718,  0.1118,  ...,  0.0826, -0.0978,  0.2029],
         ...,
         [ 0.2183, -0.0785,  0.6720,  ..., -0.0715, -0.3156,  0.3742],
         [-0.0872, -0.0924, -0.1474,  ..., -0.0083, -0.1085,  0.3296],
         [ 0.1688, -0.3080,  0.0063,  ...,  0.3659,  0.1373,  0.1016]],

        [[-0.6808, -0.0752, -0.2681,  ..., -0.1388, -0.2275, -0.2143],
         [-0.2353, -0.1768, -0.1707,  ...,  0.0178,  0.0832,  0.2217],
         [ 0.1139, -0.0718,  0.1118,  ...,  0.0826, -0.0978,  0.2029],
         ...,
         [ 0.3311, -0.3437,  0.3384,  ...,  0.0665, -0.5832,  0.6978],
         [ 0.2472, -0.4203, -0.2445,  ..., -0.0556, -0.6851,  0.2459],
         [-0.1409, -0.0335,  0.0901,  ...,  0.1262, -0.0717, -0.0317]],

        [[-0.6808, -0.0752, -0.2681,  ..., -0.1388, -0.2275, -0.2143],
         [-0.2353, -0.1768, -0.1707,  ...,  0.0178,  0.0832,  0.2217],
         [ 0.1139, -0.0718,  0.1118,  ...,  0.0826, -0.0978,  0.2029],
         ...,
         [ 0.2183, -0.0785,  0.6720,  ..., -0.0715, -0.3156,  0.3742],
         [ 0.3059, -0.4358, -0.2626,  ..., -0.0514, -0.6672,  0.2423],
         [-0.1380, -0.0189,  0.0841,  ...,  0.1267, -0.0621, -0.0330]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ¦ T_txt=25
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 25, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 25, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 25, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 25])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 25, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 25, 64])
ğŸŸ¦ out.shape=torch.Size([3, 25, 512])
ğŸŸ¦ out.shape=torch.Size([3, 25, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 25, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 25, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.0310,  0.7941, -1.4750,  ...,  0.3614,  1.5208, -0.2439],
         [-0.5725, -0.0922, -0.2418,  ...,  0.0514,  0.0311,  0.2457],
         [ 0.0686, -0.0593,  0.1036,  ...,  0.0507,  0.1819,  0.0491],
         ...,
         [ 0.1298, -0.1410,  0.5957,  ..., -0.0378, -0.3640,  0.2144],
         [ 0.1142, -0.1232, -0.2430,  ...,  0.1038, -0.0946,  0.4473],
         [ 0.3483, -0.3436,  0.1093,  ...,  0.3054, -0.2380,  0.1830]],

        [[-4.0310,  0.7941, -1.4750,  ...,  0.3614,  1.5208, -0.2439],
         [-0.5725, -0.0922, -0.2418,  ...,  0.0514,  0.0311,  0.2457],
         [ 0.0686, -0.0593,  0.1036,  ...,  0.0507,  0.1819,  0.0491],
         ...,
         [ 0.1553, -0.5355,  0.3048,  ..., -0.0323, -0.6527,  0.4153],
         [ 0.0561, -0.3208, -0.2518,  ...,  0.1978, -0.5437,  0.1993],
         [-0.1113, -0.1143, -0.0607,  ...,  0.0934, -0.0435, -0.0680]],

        [[-4.0310,  0.7941, -1.4750,  ...,  0.3614,  1.5208, -0.2439],
         [-0.5725, -0.0922, -0.2418,  ...,  0.0514,  0.0311,  0.2457],
         [ 0.0686, -0.0593,  0.1036,  ...,  0.0507,  0.1819,  0.0491],
         ...,
         [ 0.1298, -0.1410,  0.5957,  ..., -0.0378, -0.3640,  0.2144],
         [ 0.1947, -0.3707, -0.1807,  ...,  0.1995, -0.5023,  0.2307],
         [-0.1017, -0.1083, -0.0664,  ...,  0.0899, -0.0343, -0.0566]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ¦ T_txt=25
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 25, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 25, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 25, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 25])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 25, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 25, 64])
ğŸŸ¦ out.shape=torch.Size([3, 25, 512])
ğŸŸ¦ out.shape=torch.Size([3, 25, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 25, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 25, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.7946e+00,  9.0221e-01, -1.2882e+00,  ...,  1.1832e+00,
           2.5226e+00, -5.9823e-02],
         [-5.6193e-01, -1.5785e-01, -2.8558e-01,  ..., -3.8618e-02,
          -1.3092e-02,  1.2509e-01],
         [ 4.1303e-03, -1.2649e-01, -2.6289e-01,  ...,  2.2804e-01,
          -9.2656e-02,  5.5100e-03],
         ...,
         [ 1.5137e-01, -3.1456e-01,  6.1986e-01,  ..., -1.8698e-01,
          -4.2912e-01,  3.1011e-01],
         [ 1.8597e-01, -2.3619e-01, -3.2535e-01,  ...,  5.0271e-02,
           9.2434e-02,  4.2249e-01],
         [ 2.9708e-01, -5.3556e-01,  9.0744e-02,  ...,  5.6743e-01,
          -3.1411e-01,  4.4154e-01]],

        [[-4.7946e+00,  9.0221e-01, -1.2882e+00,  ...,  1.1832e+00,
           2.5226e+00, -5.9823e-02],
         [-5.6193e-01, -1.5785e-01, -2.8558e-01,  ..., -3.8618e-02,
          -1.3092e-02,  1.2509e-01],
         [ 4.1303e-03, -1.2649e-01, -2.6289e-01,  ...,  2.2804e-01,
          -9.2656e-02,  5.5100e-03],
         ...,
         [ 9.5321e-02, -6.5955e-01,  6.1281e-01,  ..., -3.5334e-01,
          -8.4627e-01,  7.3372e-01],
         [-1.0711e-01, -4.1903e-01, -2.2295e-01,  ..., -8.4910e-02,
          -8.1008e-01,  6.9410e-02],
         [-2.5848e-01,  1.4609e-01,  6.7453e-02,  ...,  8.3614e-02,
          -7.9746e-02, -1.4668e-02]],

        [[-4.7946e+00,  9.0221e-01, -1.2882e+00,  ...,  1.1832e+00,
           2.5226e+00, -5.9824e-02],
         [-5.6193e-01, -1.5785e-01, -2.8558e-01,  ..., -3.8618e-02,
          -1.3092e-02,  1.2509e-01],
         [ 4.1304e-03, -1.2649e-01, -2.6289e-01,  ...,  2.2804e-01,
          -9.2657e-02,  5.5100e-03],
         ...,
         [ 1.5137e-01, -3.1456e-01,  6.1986e-01,  ..., -1.8698e-01,
          -4.2912e-01,  3.1011e-01],
         [-7.2773e-02, -4.3585e-01, -1.2248e-01,  ..., -1.4911e-01,
          -7.9335e-01,  1.7368e-01],
         [-2.4865e-01,  1.5267e-01,  6.8554e-02,  ...,  7.8212e-02,
          -6.6218e-02, -5.2163e-03]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ¦ T_txt=25
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 25, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 25, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 25, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 25])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 25, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 25, 64])
ğŸŸ¦ out.shape=torch.Size([3, 25, 512])
ğŸŸ¦ out.shape=torch.Size([3, 25, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 25, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 25, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.2771e+00,  1.3169e+00, -1.5839e+00,  ...,  1.5235e+00,
           2.5618e+00,  3.0273e-01],
         [-5.1019e-01, -2.0753e-01, -3.9353e-01,  ..., -3.0973e-02,
           3.3680e-01,  1.5358e-01],
         [ 9.6702e-02, -5.6518e-01, -1.5635e-01,  ...,  8.8998e-03,
           7.6486e-02, -5.2472e-03],
         ...,
         [ 3.8801e-01, -2.2128e-01,  7.5257e-01,  ..., -2.1136e-01,
          -2.9751e-02,  2.3278e-01],
         [ 3.6183e-01, -8.2698e-02, -3.2821e-01,  ..., -1.4714e-01,
           3.8478e-01,  4.9177e-01],
         [ 3.6524e-01, -3.1060e-01,  2.4156e-02,  ...,  5.0680e-01,
          -1.8818e-01,  4.5126e-01]],

        [[-5.2771e+00,  1.3169e+00, -1.5839e+00,  ...,  1.5235e+00,
           2.5618e+00,  3.0273e-01],
         [-5.1019e-01, -2.0753e-01, -3.9353e-01,  ..., -3.0973e-02,
           3.3680e-01,  1.5358e-01],
         [ 9.6702e-02, -5.6518e-01, -1.5635e-01,  ...,  8.8998e-03,
           7.6486e-02, -5.2472e-03],
         ...,
         [ 4.7157e-01, -4.8962e-01,  7.7679e-01,  ..., -3.1238e-01,
          -5.8977e-01,  8.6680e-01],
         [-2.1696e-03, -8.4452e-02, -2.1674e-01,  ...,  1.3828e-01,
          -4.5000e-01,  1.3284e-01],
         [-1.2386e-01,  2.9836e-01, -1.0181e-01,  ...,  8.4010e-02,
           5.1625e-02, -7.9608e-02]],

        [[-5.2771e+00,  1.3169e+00, -1.5839e+00,  ...,  1.5235e+00,
           2.5618e+00,  3.0273e-01],
         [-5.1019e-01, -2.0753e-01, -3.9353e-01,  ..., -3.0973e-02,
           3.3680e-01,  1.5358e-01],
         [ 9.6702e-02, -5.6518e-01, -1.5635e-01,  ...,  8.8994e-03,
           7.6485e-02, -5.2473e-03],
         ...,
         [ 3.8801e-01, -2.2128e-01,  7.5257e-01,  ..., -2.1136e-01,
          -2.9751e-02,  2.3278e-01],
         [-3.5616e-03, -1.6476e-01, -7.2072e-02,  ...,  8.6559e-03,
          -4.1433e-01,  2.2636e-01],
         [-1.6445e-01,  3.0974e-01, -7.5250e-02,  ...,  8.7225e-02,
           1.4696e-02, -1.0518e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ¦ T_txt=25
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 25, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 25, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 25, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 25])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 25, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 25, 64])
ğŸŸ¦ out.shape=torch.Size([3, 25, 512])
ğŸŸ¦ out.shape=torch.Size([3, 25, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 25, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 25, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.3925e+00,  1.2785e+00, -1.7428e+00,  ...,  1.6187e+00,
           2.6666e+00,  6.3102e-01],
         [-7.2190e-01, -9.0366e-02, -3.7054e-01,  ..., -4.8731e-02,
           5.0303e-02,  4.0432e-02],
         [ 3.2142e-02, -5.6480e-01, -2.0480e-01,  ...,  6.2426e-02,
          -1.1226e-01,  5.0913e-03],
         ...,
         [ 3.1804e-01, -2.3715e-01,  5.9929e-01,  ...,  3.9293e-02,
          -1.5933e-01,  2.9268e-01],
         [ 4.2414e-01, -1.0747e-01, -3.3100e-01,  ..., -3.6298e-02,
           2.2127e-01,  5.8332e-01],
         [ 1.3164e-01, -3.3266e-01, -8.8986e-02,  ...,  5.1443e-01,
          -1.8559e-01, -3.8852e-02]],

        [[-5.3925e+00,  1.2785e+00, -1.7428e+00,  ...,  1.6187e+00,
           2.6666e+00,  6.3102e-01],
         [-7.2190e-01, -9.0366e-02, -3.7054e-01,  ..., -4.8731e-02,
           5.0303e-02,  4.0432e-02],
         [ 3.2142e-02, -5.6480e-01, -2.0480e-01,  ...,  6.2426e-02,
          -1.1226e-01,  5.0913e-03],
         ...,
         [ 4.7406e-01, -5.4928e-01,  6.2735e-01,  ..., -7.1123e-02,
          -6.2055e-01,  7.8802e-01],
         [-7.2949e-02,  1.4121e-01, -3.0084e-01,  ...,  2.2718e-02,
          -5.2362e-01, -1.3222e-01],
         [-1.8546e-01,  1.4471e-01,  8.1018e-02,  ...,  5.5265e-02,
          -1.6732e-01, -1.4840e-01]],

        [[-5.3925e+00,  1.2785e+00, -1.7428e+00,  ...,  1.6187e+00,
           2.6666e+00,  6.3102e-01],
         [-7.2190e-01, -9.0366e-02, -3.7054e-01,  ..., -4.8731e-02,
           5.0303e-02,  4.0432e-02],
         [ 3.2142e-02, -5.6480e-01, -2.0480e-01,  ...,  6.2426e-02,
          -1.1226e-01,  5.0909e-03],
         ...,
         [ 3.1804e-01, -2.3715e-01,  5.9929e-01,  ...,  3.9293e-02,
          -1.5933e-01,  2.9268e-01],
         [ 1.5856e-02,  5.2091e-02, -8.0247e-02,  ...,  8.5830e-02,
          -4.9585e-01,  7.4877e-02],
         [-2.6010e-01,  1.0704e-01,  5.5329e-02,  ...,  9.3500e-02,
          -2.3610e-01, -1.9595e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ¦ T_txt=25
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 25, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 25, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 25, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 25])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 25, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 25, 64])
ğŸŸ¦ out.shape=torch.Size([3, 25, 512])
ğŸŸ¦ out.shape=torch.Size([3, 25, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 25, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 25, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.7653e+00,  1.1008e+00, -1.8155e+00,  ...,  2.3020e+00,
           2.1681e+00,  1.0300e+00],
         [-6.6199e-01, -7.7735e-02, -5.1326e-01,  ..., -2.2643e-01,
           1.6844e-01, -1.5885e-02],
         [ 2.8691e-02, -6.1208e-01, -4.2365e-01,  ..., -2.2236e-01,
           9.9555e-02,  1.2918e-02],
         ...,
         [ 2.3910e-01, -5.2146e-01,  5.6144e-01,  ..., -1.4774e-01,
          -1.7351e-01, -1.3317e-03],
         [ 2.4359e-01, -3.0873e-01, -2.8838e-01,  ..., -2.7578e-01,
           3.2443e-01,  3.4007e-02],
         [ 1.1457e-01, -3.6857e-01, -2.7525e-01,  ...,  9.8315e-02,
          -1.8090e-01, -2.6101e-01]],

        [[-5.7653e+00,  1.1008e+00, -1.8155e+00,  ...,  2.3020e+00,
           2.1681e+00,  1.0300e+00],
         [-6.6199e-01, -7.7735e-02, -5.1326e-01,  ..., -2.2643e-01,
           1.6844e-01, -1.5885e-02],
         [ 2.8691e-02, -6.1208e-01, -4.2365e-01,  ..., -2.2236e-01,
           9.9555e-02,  1.2918e-02],
         ...,
         [ 4.0329e-01, -6.2026e-01,  5.3886e-01,  ..., -5.2571e-01,
          -7.1158e-01,  5.5968e-01],
         [ 2.1613e-01, -9.8405e-02, -5.4292e-01,  ..., -1.1372e-01,
          -5.8016e-01, -3.1952e-01],
         [-2.2823e-01,  3.0677e-01,  3.2382e-02,  ..., -1.3619e-01,
          -7.0670e-02, -5.5818e-01]],

        [[-5.7653e+00,  1.1008e+00, -1.8155e+00,  ...,  2.3020e+00,
           2.1681e+00,  1.0300e+00],
         [-6.6199e-01, -7.7735e-02, -5.1326e-01,  ..., -2.2643e-01,
           1.6844e-01, -1.5885e-02],
         [ 2.8692e-02, -6.1208e-01, -4.2365e-01,  ..., -2.2236e-01,
           9.9554e-02,  1.2917e-02],
         ...,
         [ 2.3910e-01, -5.2146e-01,  5.6144e-01,  ..., -1.4774e-01,
          -1.7351e-01, -1.3324e-03],
         [ 2.4885e-01, -9.8192e-02, -3.1634e-01,  ..., -3.1486e-02,
          -4.7194e-01, -2.4448e-01],
         [-3.5465e-01,  2.6990e-01,  4.0033e-02,  ..., -7.1132e-02,
          -1.0388e-01, -5.7599e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ¦ T_txt=25
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 25, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 25, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 25, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 25])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 25, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 25, 64])
ğŸŸ¦ out.shape=torch.Size([3, 25, 512])
ğŸŸ¦ out.shape=torch.Size([3, 25, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 25, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 25, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.8693e+00,  9.3745e-01, -1.8379e+00,  ...,  2.4698e+00,
           2.0660e+00,  1.2787e+00],
         [-6.8941e-01,  2.4615e-01, -4.9576e-01,  ..., -2.5218e-01,
           1.5029e-01,  7.9583e-02],
         [ 1.1727e-01, -2.8995e-01, -5.4170e-01,  ..., -1.3670e-01,
           7.0986e-02,  1.0259e-01],
         ...,
         [ 4.2944e-01,  2.9349e-03,  9.1485e-01,  ..., -1.6032e-01,
          -1.7634e-01,  2.9936e-01],
         [ 2.1023e-02, -6.2654e-02, -4.0409e-01,  ..., -4.3246e-01,
           2.9215e-01,  3.4777e-02],
         [ 3.0940e-01,  2.8978e-01,  2.0281e-02,  ...,  2.4822e-03,
          -5.3647e-01, -2.2344e-01]],

        [[-5.8693e+00,  9.3745e-01, -1.8379e+00,  ...,  2.4698e+00,
           2.0660e+00,  1.2787e+00],
         [-6.8941e-01,  2.4615e-01, -4.9576e-01,  ..., -2.5218e-01,
           1.5029e-01,  7.9583e-02],
         [ 1.1727e-01, -2.8995e-01, -5.4170e-01,  ..., -1.3670e-01,
           7.0986e-02,  1.0259e-01],
         ...,
         [ 5.4977e-01, -8.9901e-02,  9.6283e-01,  ..., -5.4294e-01,
          -6.7182e-01,  1.0580e+00],
         [ 3.4921e-01,  2.5731e-01, -5.2416e-01,  ..., -1.0038e-01,
          -7.9638e-01, -2.4247e-01],
         [-2.8065e-01,  4.5307e-01,  2.8570e-02,  ..., -4.9174e-02,
           8.1138e-03, -1.4153e-01]],

        [[-5.8693e+00,  9.3745e-01, -1.8379e+00,  ...,  2.4698e+00,
           2.0660e+00,  1.2787e+00],
         [-6.8941e-01,  2.4615e-01, -4.9576e-01,  ..., -2.5218e-01,
           1.5029e-01,  7.9583e-02],
         [ 1.1727e-01, -2.8995e-01, -5.4170e-01,  ..., -1.3670e-01,
           7.0986e-02,  1.0259e-01],
         ...,
         [ 4.2944e-01,  2.9348e-03,  9.1485e-01,  ..., -1.6032e-01,
          -1.7634e-01,  2.9936e-01],
         [ 2.7741e-01,  2.8287e-01, -2.8701e-01,  ..., -6.1591e-02,
          -6.8265e-01, -2.5316e-01],
         [-3.5772e-01,  4.1787e-01, -1.8792e-03,  ...,  5.0497e-02,
          -1.3561e-02, -1.6553e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ¦ T_txt=25
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 25, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 25, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 25, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 25])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 25, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 25, 64])
ğŸŸ¦ out.shape=torch.Size([3, 25, 512])
ğŸŸ¦ out.shape=torch.Size([3, 25, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 25, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 25, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.6016e+00,  1.2408e+00, -1.6460e+00,  ...,  3.1029e+00,
           2.1120e+00,  1.1936e+00],
         [-5.1318e-01,  1.3069e-01, -5.7248e-01,  ..., -8.0478e-02,
           3.0335e-02, -1.3672e-01],
         [ 2.1050e-01, -6.8635e-01, -6.6328e-01,  ...,  2.2120e-01,
           3.5946e-01,  2.3200e-01],
         ...,
         [ 5.7634e-01,  1.9380e-01,  9.2979e-01,  ..., -2.2846e-02,
          -3.5429e-01,  1.9313e-01],
         [ 1.3018e-01, -4.5977e-02, -5.4057e-01,  ..., -3.2460e-01,
           2.6987e-01, -5.8595e-02],
         [ 6.8112e-01,  5.5985e-02,  1.2636e-01,  ...,  1.1199e-01,
          -7.5633e-01, -3.2698e-01]],

        [[-5.6016e+00,  1.2408e+00, -1.6460e+00,  ...,  3.1029e+00,
           2.1120e+00,  1.1936e+00],
         [-5.1318e-01,  1.3069e-01, -5.7248e-01,  ..., -8.0478e-02,
           3.0335e-02, -1.3672e-01],
         [ 2.1050e-01, -6.8635e-01, -6.6328e-01,  ...,  2.2120e-01,
           3.5946e-01,  2.3200e-01],
         ...,
         [ 5.0403e-01, -5.1759e-02,  9.8765e-01,  ..., -7.3353e-01,
          -7.5078e-01,  8.4942e-01],
         [ 6.4809e-01,  7.6813e-02, -2.2245e-03,  ...,  4.3426e-02,
          -8.3110e-01, -4.9535e-01],
         [-3.8452e-01,  3.1135e-01,  2.6976e-01,  ..., -9.6989e-02,
          -2.4907e-01, -1.5286e-01]],

        [[-5.6016e+00,  1.2408e+00, -1.6460e+00,  ...,  3.1029e+00,
           2.1120e+00,  1.1936e+00],
         [-5.1318e-01,  1.3069e-01, -5.7248e-01,  ..., -8.0477e-02,
           3.0335e-02, -1.3672e-01],
         [ 2.1050e-01, -6.8635e-01, -6.6328e-01,  ...,  2.2120e-01,
           3.5946e-01,  2.3200e-01],
         ...,
         [ 5.7634e-01,  1.9380e-01,  9.2979e-01,  ..., -2.2847e-02,
          -3.5430e-01,  1.9312e-01],
         [ 6.6441e-01,  2.4975e-01,  1.2501e-01,  ...,  1.7089e-02,
          -7.6693e-01, -5.6628e-01],
         [-4.7871e-01,  2.5384e-01,  2.0358e-01,  ...,  1.2343e-02,
          -2.8466e-01, -1.2647e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ¦ T_txt=25
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 25, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 25, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 25, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 25])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 25, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 25, 64])
ğŸŸ¦ out.shape=torch.Size([3, 25, 512])
ğŸŸ¦ out.shape=torch.Size([3, 25, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 25, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 25, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.5722,  1.3828, -1.6196,  ...,  3.5095,  2.5083,  1.2801],
         [-0.7604,  0.1403, -0.7794,  ...,  0.1032,  0.1174, -0.2312],
         [-0.0521, -0.3372, -0.8223,  ...,  0.0621,  0.1464,  0.1382],
         ...,
         [ 0.4046,  0.1571,  0.9001,  ..., -0.0757, -0.4872,  0.2787],
         [-0.0794, -0.1273, -0.3627,  ..., -0.5834,  0.4231, -0.0958],
         [ 0.5518,  0.2439, -0.0876,  ...,  0.2645, -1.1485, -0.2385]],

        [[-5.5722,  1.3828, -1.6196,  ...,  3.5095,  2.5083,  1.2801],
         [-0.7604,  0.1403, -0.7794,  ...,  0.1032,  0.1174, -0.2312],
         [-0.0521, -0.3372, -0.8223,  ...,  0.0621,  0.1464,  0.1382],
         ...,
         [ 0.2792, -0.1412,  0.9258,  ..., -0.5942, -0.7232,  0.8483],
         [ 0.4279,  0.3293, -0.2094,  ...,  0.2401, -1.0083, -0.4063],
         [-0.4674,  0.4709,  0.0801,  ..., -0.2831, -0.0674, -0.0350]],

        [[-5.5722,  1.3828, -1.6196,  ...,  3.5095,  2.5083,  1.2801],
         [-0.7604,  0.1403, -0.7794,  ...,  0.1032,  0.1174, -0.2312],
         [-0.0521, -0.3372, -0.8223,  ...,  0.0621,  0.1464,  0.1382],
         ...,
         [ 0.4046,  0.1571,  0.9001,  ..., -0.0757, -0.4872,  0.2787],
         [ 0.4762,  0.5052, -0.1303,  ...,  0.1964, -0.9551, -0.4804],
         [-0.5541,  0.4565, -0.0359,  ..., -0.2302, -0.1423, -0.0590]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ¦ T_txt=25
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 25, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 25, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 25, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 25])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 25, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 25, 64])
ğŸŸ¦ out.shape=torch.Size([3, 25, 512])
ğŸŸ¦ out.shape=torch.Size([3, 25, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 25, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 25, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.6640,  1.4165, -1.7391,  ...,  3.7237,  2.6647,  1.4654],
         [-0.6078, -0.0251, -1.0078,  ...,  0.0240, -0.0394, -0.4400],
         [-0.2394, -0.7447, -0.9997,  ..., -0.1766,  0.0965,  0.0557],
         ...,
         [ 0.3892, -0.0845,  0.9596,  ..., -0.1556, -0.4671,  0.1089],
         [-0.1628, -0.5103, -0.2968,  ..., -0.6998,  0.8058, -0.1868],
         [ 0.3320,  0.0154, -0.0785,  ...,  0.4108, -1.0679, -0.2036]],

        [[-5.6640,  1.4165, -1.7391,  ...,  3.7237,  2.6647,  1.4654],
         [-0.6078, -0.0251, -1.0078,  ...,  0.0240, -0.0394, -0.4400],
         [-0.2394, -0.7447, -0.9997,  ..., -0.1766,  0.0965,  0.0557],
         ...,
         [ 0.3848, -0.2618,  0.9178,  ..., -0.4372, -0.7897,  0.7416],
         [ 0.2922,  0.1570, -0.2512,  ...,  0.2008, -1.0361, -0.2140],
         [-0.9957,  0.8342, -0.1901,  ..., -0.2309,  0.2770, -0.0235]],

        [[-5.6640,  1.4165, -1.7391,  ...,  3.7237,  2.6647,  1.4654],
         [-0.6078, -0.0251, -1.0078,  ...,  0.0240, -0.0394, -0.4400],
         [-0.2394, -0.7447, -0.9997,  ..., -0.1766,  0.0965,  0.0557],
         ...,
         [ 0.3892, -0.0845,  0.9596,  ..., -0.1556, -0.4671,  0.1089],
         [ 0.4216,  0.2782, -0.1465,  ...,  0.1041, -0.9364, -0.4096],
         [-1.0460,  0.8981, -0.2357,  ..., -0.2006,  0.2278, -0.0338]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ¦ T_txt=25
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 25, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 25, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 25, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 25])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 25, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 25, 64])
ğŸŸ¦ out.shape=torch.Size([3, 25, 512])
ğŸŸ¦ out.shape=torch.Size([3, 25, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 25, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 25, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.3878,  1.2637, -1.3476,  ...,  3.9388,  2.7129,  1.6259],
         [-0.6773,  0.0069, -0.7329,  ...,  0.2023,  0.1743, -0.1756],
         [-0.3587, -0.5944, -1.0050,  ...,  0.2275,  0.4650,  0.1995],
         ...,
         [ 0.2838, -0.0121,  1.2331,  ..., -0.1604, -0.6465,  0.4093],
         [-0.1415, -0.5685, -0.5636,  ..., -0.7246,  0.7350, -0.0069],
         [ 0.4086,  0.1663, -0.3030,  ...,  0.5982, -1.0544, -0.3236]],

        [[-5.3878,  1.2637, -1.3476,  ...,  3.9388,  2.7129,  1.6259],
         [-0.6773,  0.0069, -0.7329,  ...,  0.2023,  0.1743, -0.1756],
         [-0.3587, -0.5944, -1.0050,  ...,  0.2275,  0.4650,  0.1995],
         ...,
         [ 0.5905, -0.2534,  0.9877,  ..., -0.3993, -0.9285,  0.9923],
         [ 0.4333,  0.2429, -0.4584,  ...,  0.2642, -1.1859, -0.0508],
         [-1.0259,  0.7541, -0.3358,  ..., -0.2170,  0.1911,  0.1802]],

        [[-5.3878,  1.2637, -1.3476,  ...,  3.9388,  2.7129,  1.6259],
         [-0.6773,  0.0069, -0.7329,  ...,  0.2023,  0.1743, -0.1756],
         [-0.3587, -0.5944, -1.0050,  ...,  0.2275,  0.4650,  0.1995],
         ...,
         [ 0.2838, -0.0121,  1.2331,  ..., -0.1604, -0.6465,  0.4093],
         [ 0.6040,  0.4236, -0.3152,  ...,  0.1281, -1.1290, -0.2424],
         [-1.0853,  0.8425, -0.3480,  ..., -0.1602,  0.1427,  0.1676]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ¦ T_txt=25
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 25, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 25, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 25, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 25])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 25, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 25, 64])
ğŸŸ¦ out.shape=torch.Size([3, 25, 512])
ğŸŸ¦ out.shape=torch.Size([3, 25, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 25, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 25, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.0959,  0.8567, -1.2666,  ...,  3.8593,  2.8167,  1.9328],
         [-0.9069, -0.3564, -0.8761,  ...,  0.1384,  0.2888, -0.1783],
         [-0.2450, -0.8774, -1.2020,  ...,  0.3088,  0.3829,  0.2829],
         ...,
         [ 0.3065,  0.0474,  1.2372,  ...,  0.0213, -0.4936,  0.4731],
         [ 0.1424, -0.2069, -0.5607,  ..., -0.8078,  0.9837,  0.1046],
         [ 0.7327, -0.0366, -0.2507,  ...,  0.8824, -0.8270, -0.3381]],

        [[-5.0959,  0.8567, -1.2666,  ...,  3.8593,  2.8167,  1.9328],
         [-0.9069, -0.3564, -0.8761,  ...,  0.1384,  0.2888, -0.1783],
         [-0.2450, -0.8774, -1.2020,  ...,  0.3088,  0.3829,  0.2829],
         ...,
         [ 0.6775, -0.1358,  1.1488,  ..., -0.1645, -0.7713,  1.0117],
         [ 0.4157,  0.3295, -0.3295,  ...,  0.5478, -1.0504,  0.2880],
         [-1.3828,  0.7323, -0.5127,  ...,  0.0650,  0.3360,  0.2833]],

        [[-5.0959,  0.8567, -1.2666,  ...,  3.8593,  2.8167,  1.9328],
         [-0.9069, -0.3564, -0.8761,  ...,  0.1384,  0.2888, -0.1783],
         [-0.2450, -0.8774, -1.2020,  ...,  0.3088,  0.3829,  0.2829],
         ...,
         [ 0.3065,  0.0474,  1.2372,  ...,  0.0213, -0.4936,  0.4731],
         [ 0.6896,  0.4565, -0.2549,  ...,  0.4564, -1.0424,  0.0941],
         [-1.4783,  0.8173, -0.5545,  ...,  0.1550,  0.3044,  0.3004]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ¦ T_txt=25
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 25, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 25, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 25, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 25])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 25, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 25, 64])
ğŸŸ¦ out.shape=torch.Size([3, 25, 512])
ğŸŸ¦ out.shape=torch.Size([3, 25, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 25, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 25, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.8058e+00,  7.3018e-01, -1.0989e+00,  ...,  3.8324e+00,
           2.7810e+00,  1.7821e+00],
         [-7.0377e-01, -6.3927e-01, -6.2966e-01,  ..., -3.5870e-02,
           1.7194e-01, -3.3438e-01],
         [-1.6488e-01, -7.0103e-01, -9.2414e-01,  ...,  5.3185e-01,
           1.6227e-01, -1.6698e-01],
         ...,
         [ 4.2245e-01,  2.5993e-01,  1.3526e+00,  ..., -1.4451e-02,
          -4.4267e-01,  2.3606e-01],
         [-3.3330e-01,  2.1282e-01, -8.5601e-01,  ..., -7.4651e-01,
           8.6654e-01, -4.7348e-03],
         [ 2.6426e-01,  2.6206e-01, -5.6295e-01,  ...,  1.0858e+00,
          -9.5241e-01, -3.3721e-01]],

        [[-4.8058e+00,  7.3018e-01, -1.0989e+00,  ...,  3.8324e+00,
           2.7810e+00,  1.7821e+00],
         [-7.0377e-01, -6.3927e-01, -6.2966e-01,  ..., -3.5870e-02,
           1.7194e-01, -3.3438e-01],
         [-1.6488e-01, -7.0103e-01, -9.2414e-01,  ...,  5.3185e-01,
           1.6227e-01, -1.6698e-01],
         ...,
         [ 8.3226e-01,  2.3439e-01,  1.0905e+00,  ..., -2.5745e-01,
          -4.3746e-01,  8.1926e-01],
         [ 1.2331e-01,  4.3793e-01, -7.6396e-01,  ...,  8.5062e-01,
          -1.4413e+00,  7.2747e-02],
         [-1.3262e+00,  5.6989e-01, -6.2491e-01,  ...,  2.3833e-01,
           4.0484e-01, -9.7607e-02]],

        [[-4.8058e+00,  7.3018e-01, -1.0989e+00,  ...,  3.8324e+00,
           2.7810e+00,  1.7821e+00],
         [-7.0377e-01, -6.3927e-01, -6.2966e-01,  ..., -3.5869e-02,
           1.7194e-01, -3.3437e-01],
         [-1.6488e-01, -7.0103e-01, -9.2413e-01,  ...,  5.3185e-01,
           1.6227e-01, -1.6698e-01],
         ...,
         [ 4.2245e-01,  2.5993e-01,  1.3526e+00,  ..., -1.4452e-02,
          -4.4267e-01,  2.3606e-01],
         [ 3.8969e-01,  5.6786e-01, -6.7377e-01,  ...,  6.9383e-01,
          -1.5138e+00, -1.8602e-01],
         [-1.3939e+00,  6.7337e-01, -6.5667e-01,  ...,  3.3859e-01,
           3.6934e-01, -7.6804e-02]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ¦ T_txt=25
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 25, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 25, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 25, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 25])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 25, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 25, 64])
ğŸŸ¦ out.shape=torch.Size([3, 25, 512])
ğŸŸ¦ out.shape=torch.Size([3, 25, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 25, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 25, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.5423,  0.4867, -1.3078,  ...,  4.0570,  2.7591,  1.7055],
         [-0.7944, -1.0986, -0.8873,  ..., -0.3006, -0.1496, -0.3139],
         [ 0.3003, -0.6765, -0.9426,  ...,  0.2994,  0.2125, -0.2227],
         ...,
         [ 0.4582,  0.3000,  0.4645,  ..., -0.3277, -0.2306,  0.3756],
         [-0.2928,  0.2379, -1.2926,  ..., -1.2829,  0.4944,  0.1044],
         [ 0.2314,  0.4070, -0.9769,  ...,  1.1371, -0.9586, -0.4296]],

        [[-4.5423,  0.4867, -1.3078,  ...,  4.0570,  2.7591,  1.7055],
         [-0.7944, -1.0986, -0.8873,  ..., -0.3006, -0.1496, -0.3139],
         [ 0.3003, -0.6765, -0.9426,  ...,  0.2994,  0.2125, -0.2227],
         ...,
         [ 0.9205,  0.2934,  0.6854,  ..., -0.8828, -0.2170,  0.6854],
         [ 0.0809,  0.3825, -0.8883,  ...,  0.7028, -1.3656,  0.1694],
         [-1.6531,  0.4312, -0.8482,  ...,  0.6424,  0.2859, -0.4425]],

        [[-4.5423,  0.4867, -1.3078,  ...,  4.0570,  2.7591,  1.7055],
         [-0.7944, -1.0986, -0.8873,  ..., -0.3006, -0.1496, -0.3139],
         [ 0.3003, -0.6765, -0.9426,  ...,  0.2994,  0.2125, -0.2227],
         ...,
         [ 0.4582,  0.3000,  0.4645,  ..., -0.3277, -0.2306,  0.3756],
         [ 0.3026,  0.4890, -0.8478,  ...,  0.4644, -1.4480,  0.0626],
         [-1.7606,  0.5350, -0.9298,  ...,  0.7531,  0.2693, -0.4030]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ¦ T_txt=25
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 25, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 25, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 25, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 25])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 25, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 25, 64])
ğŸŸ¦ out.shape=torch.Size([3, 25, 512])
ğŸŸ¦ out.shape=torch.Size([3, 25, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 25, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 25, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.4194,  0.4068, -1.0771,  ...,  4.0394,  2.7712,  1.5921],
         [-1.0025, -1.3143, -1.0197,  ..., -0.7655, -0.0488, -0.4858],
         [ 0.0073, -0.6469, -0.9511,  ...,  0.0354,  0.6350,  0.2235],
         ...,
         [ 0.6006, -0.3519,  0.2725,  ...,  0.0382, -0.0264,  0.6983],
         [ 0.3860,  0.4136, -1.3120,  ..., -1.2965,  0.5401,  0.2613],
         [ 0.2150,  0.3973, -0.7569,  ...,  1.4225, -0.6833, -0.2296]],

        [[-4.4194,  0.4068, -1.0771,  ...,  4.0394,  2.7712,  1.5921],
         [-1.0025, -1.3143, -1.0197,  ..., -0.7655, -0.0488, -0.4858],
         [ 0.0073, -0.6469, -0.9511,  ...,  0.0354,  0.6350,  0.2235],
         ...,
         [ 1.0983, -0.3486,  0.5914,  ..., -0.4843,  0.4383,  1.0968],
         [-0.2509,  0.6452, -0.7794,  ...,  0.9288, -0.9705,  0.4292],
         [-1.8423,  0.5681, -0.6620,  ...,  0.3672,  0.6592, -0.2609]],

        [[-4.4194,  0.4068, -1.0771,  ...,  4.0394,  2.7712,  1.5921],
         [-1.0025, -1.3143, -1.0197,  ..., -0.7654, -0.0488, -0.4858],
         [ 0.0073, -0.6469, -0.9511,  ...,  0.0354,  0.6350,  0.2235],
         ...,
         [ 0.6006, -0.3519,  0.2725,  ...,  0.0382, -0.0264,  0.6983],
         [ 0.1116,  0.6736, -0.7352,  ...,  0.7210, -1.1174,  0.4663],
         [-1.9606,  0.6363, -0.7234,  ...,  0.4419,  0.6187, -0.2166]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ¦ T_txt=25
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 25, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 25, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 25, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 25])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 25, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 25, 64])
ğŸŸ¦ out.shape=torch.Size([3, 25, 512])
ğŸŸ¦ out.shape=torch.Size([3, 25, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 25, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 25, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.6486e+00,  4.3703e-01, -1.0679e+00,  ...,  4.0760e+00,
           2.7873e+00,  1.4896e+00],
         [-9.1824e-01, -1.6641e+00, -8.0367e-01,  ..., -1.0706e+00,
          -9.7789e-02,  8.5559e-02],
         [-3.2958e-01, -1.1621e+00, -1.2796e+00,  ..., -3.9725e-01,
           5.5436e-01,  2.3460e-01],
         ...,
         [-7.4074e-01,  8.6398e-02,  5.8763e-01,  ...,  3.0829e-01,
           6.4791e-02,  7.7100e-01],
         [-9.7339e-02,  5.0054e-01, -1.0022e+00,  ..., -9.3801e-01,
           2.8831e-01,  3.5120e-01],
         [-8.4731e-01,  6.4450e-01, -8.2339e-01,  ...,  1.9850e+00,
          -4.7562e-01, -4.0456e-02]],

        [[-4.6486e+00,  4.3703e-01, -1.0679e+00,  ...,  4.0760e+00,
           2.7873e+00,  1.4896e+00],
         [-9.1824e-01, -1.6641e+00, -8.0367e-01,  ..., -1.0706e+00,
          -9.7789e-02,  8.5559e-02],
         [-3.2958e-01, -1.1621e+00, -1.2796e+00,  ..., -3.9725e-01,
           5.5436e-01,  2.3460e-01],
         ...,
         [ 2.8290e-03,  2.9193e-01,  6.1430e-01,  ..., -6.6745e-02,
           4.1248e-01,  1.1794e+00],
         [-1.0622e+00,  8.6563e-01, -8.9686e-01,  ...,  1.2639e+00,
          -9.8401e-01,  4.1746e-01],
         [-2.0223e+00,  8.4206e-01, -6.3980e-01,  ...,  2.2923e-01,
           5.1333e-01, -4.3489e-01]],

        [[-4.6486e+00,  4.3703e-01, -1.0679e+00,  ...,  4.0760e+00,
           2.7874e+00,  1.4896e+00],
         [-9.1824e-01, -1.6641e+00, -8.0366e-01,  ..., -1.0706e+00,
          -9.7788e-02,  8.5560e-02],
         [-3.2957e-01, -1.1621e+00, -1.2796e+00,  ..., -3.9725e-01,
           5.5436e-01,  2.3460e-01],
         ...,
         [-7.4074e-01,  8.6398e-02,  5.8763e-01,  ...,  3.0829e-01,
           6.4791e-02,  7.7100e-01],
         [-7.0177e-01,  8.1621e-01, -8.7412e-01,  ...,  9.3389e-01,
          -1.0631e+00,  5.6727e-01],
         [-2.1082e+00,  9.0305e-01, -7.2690e-01,  ...,  2.8494e-01,
           4.7466e-01, -3.8395e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ¦ T_txt=25
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 25, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 25, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 25, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 25])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 25, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 25, 64])
ğŸŸ¦ out.shape=torch.Size([3, 25, 512])
ğŸŸ¦ out.shape=torch.Size([3, 25, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 25, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 25, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.6982,  0.6115, -1.1511,  ...,  3.9602,  2.6816,  1.0754],
         [-0.8318, -2.6615, -1.2791,  ..., -1.1889,  0.2650, -0.4843],
         [-0.0270, -1.6365, -1.4973,  ..., -0.5320,  0.8756,  0.4654],
         ...,
         [-0.5679,  0.5445,  0.1623,  ...,  0.5058,  0.1193,  1.3218],
         [-0.6684,  0.7412, -0.7458,  ..., -0.2329,  0.1675, -0.0535],
         [-0.3859,  0.8917, -1.2309,  ...,  2.4433, -1.2303, -0.2932]],

        [[-4.6982,  0.6115, -1.1511,  ...,  3.9602,  2.6816,  1.0754],
         [-0.8318, -2.6615, -1.2791,  ..., -1.1889,  0.2650, -0.4843],
         [-0.0270, -1.6365, -1.4973,  ..., -0.5320,  0.8756,  0.4654],
         ...,
         [ 0.3004,  0.7089, -0.3612,  ...,  0.0641,  0.5492,  1.4825],
         [-0.5257,  1.0484, -1.3466,  ...,  1.4207, -1.5212, -0.0478],
         [-2.3589,  1.2300, -0.4139,  ...,  0.2365,  0.4524, -0.4830]],

        [[-4.6982,  0.6115, -1.1511,  ...,  3.9602,  2.6816,  1.0754],
         [-0.8318, -2.6615, -1.2791,  ..., -1.1889,  0.2650, -0.4843],
         [-0.0270, -1.6365, -1.4973,  ..., -0.5320,  0.8756,  0.4654],
         ...,
         [-0.5679,  0.5445,  0.1623,  ...,  0.5058,  0.1193,  1.3217],
         [-0.2071,  0.9512, -1.3276,  ...,  1.0895, -1.5700,  0.1267],
         [-2.4196,  1.2566, -0.5185,  ...,  0.3012,  0.4236, -0.4288]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ¦ T_txt=25
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 25, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 25, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 25, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 25])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 25, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 25, 64])
ğŸŸ¦ out.shape=torch.Size([3, 25, 512])
ğŸŸ¦ out.shape=torch.Size([3, 25, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 25, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 25, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.1992,  0.1086, -1.3292,  ...,  4.5845,  3.1037,  0.6413],
         [-1.7888, -3.0735, -0.9035,  ..., -0.6403, -0.3643, -0.1203],
         [ 0.6715, -1.5127, -1.2408,  ...,  0.3204,  1.0818,  0.3063],
         ...,
         [-0.5746,  0.6474,  0.3671,  ...,  0.8432, -0.0572,  1.5996],
         [-0.6129,  0.2174, -0.6116,  ..., -0.1567, -0.2417,  0.6197],
         [ 0.0445,  0.6043, -1.3337,  ...,  2.9810, -0.9202,  0.4459]],

        [[-4.1992,  0.1086, -1.3292,  ...,  4.5845,  3.1037,  0.6413],
         [-1.7888, -3.0735, -0.9035,  ..., -0.6403, -0.3643, -0.1203],
         [ 0.6715, -1.5127, -1.2408,  ...,  0.3204,  1.0818,  0.3063],
         ...,
         [ 0.1729,  0.6477, -0.2975,  ...,  0.0292,  0.8514,  1.8736],
         [-0.0319,  0.5088, -1.5616,  ...,  1.9469, -1.5413,  0.3362],
         [-2.1351,  0.8356, -0.4322,  ...,  0.6923,  0.6194, -0.6441]],

        [[-4.1992,  0.1086, -1.3292,  ...,  4.5845,  3.1037,  0.6413],
         [-1.7888, -3.0735, -0.9035,  ..., -0.6403, -0.3643, -0.1203],
         [ 0.6715, -1.5127, -1.2408,  ...,  0.3204,  1.0818,  0.3063],
         ...,
         [-0.5746,  0.6474,  0.3671,  ...,  0.8433, -0.0572,  1.5996],
         [ 0.2290,  0.4031, -1.5890,  ...,  1.6199, -1.5787,  0.4882],
         [-2.2647,  0.7947, -0.5258,  ...,  0.7135,  0.5435, -0.5750]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ¦ T_txt=25
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 25, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 25, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 25, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 25])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 25, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 25, 64])
ğŸŸ¦ out.shape=torch.Size([3, 25, 512])
ğŸŸ¦ out.shape=torch.Size([3, 25, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 25, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 25, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-3.4956, -0.4549, -1.3173,  ...,  5.3489,  3.8643,  0.0495],
         [-1.1846, -2.7309, -0.3251,  ..., -0.5469, -0.2345,  0.0928],
         [ 0.3590, -0.8857, -1.3176,  ...,  0.7098,  1.7219,  0.2027],
         ...,
         [ 0.2531,  1.0129,  0.9571,  ...,  1.5907,  1.5373,  1.0220],
         [-0.1360,  0.7697,  0.0640,  ..., -0.0583,  0.4507,  0.4356],
         [ 0.6855,  0.9001, -1.5968,  ...,  3.1686,  0.1257,  0.0960]],

        [[-3.4956, -0.4549, -1.3173,  ...,  5.3489,  3.8643,  0.0495],
         [-1.1846, -2.7309, -0.3251,  ..., -0.5469, -0.2345,  0.0928],
         [ 0.3590, -0.8857, -1.3176,  ...,  0.7098,  1.7219,  0.2027],
         ...,
         [ 0.9831,  1.0852,  0.3028,  ...,  0.5779,  2.4249,  1.5966],
         [ 0.6183,  0.9216, -1.7594,  ...,  1.9905, -1.1381,  0.1891],
         [-2.2879,  0.5559, -0.2919,  ...,  0.4960,  0.5658, -0.5986]],

        [[-3.4956, -0.4549, -1.3173,  ...,  5.3489,  3.8643,  0.0495],
         [-1.1846, -2.7309, -0.3251,  ..., -0.5469, -0.2345,  0.0928],
         [ 0.3590, -0.8857, -1.3176,  ...,  0.7098,  1.7219,  0.2027],
         ...,
         [ 0.2531,  1.0129,  0.9571,  ...,  1.5907,  1.5373,  1.0219],
         [ 0.9474,  0.6222, -1.7576,  ...,  1.7126, -1.1423,  0.3601],
         [-2.3982,  0.5013, -0.3913,  ...,  0.5400,  0.4669, -0.5765]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ¦ T_txt=25
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 25, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 25, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 25, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 25])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 25, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 25, 64])
ğŸŸ¦ out.shape=torch.Size([3, 25, 512])
ğŸŸ¦ out.shape=torch.Size([3, 25, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 25, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 25, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-2.3185e+00, -1.3191e+00, -1.7786e+00,  ...,  8.3678e+00,
           3.3047e+00, -5.9097e-01],
         [-8.1188e-01, -3.2357e+00, -3.2883e-02,  ...,  1.3220e+00,
          -3.9638e-01,  9.7235e-01],
         [ 6.8207e-01, -7.9400e-01, -2.6729e-01,  ...,  3.2716e+00,
           1.7577e+00,  8.6897e-01],
         ...,
         [-2.2489e-01,  1.7957e-01,  4.9832e-01,  ...,  3.6873e+00,
           1.4884e+00,  1.2771e+00],
         [-1.2323e+00,  8.8369e-01,  7.2427e-01,  ...,  4.9060e-01,
           3.3909e-01,  1.7801e+00],
         [ 3.2102e-01,  1.5600e+00, -1.0896e+00,  ...,  5.5041e+00,
          -3.9509e-01,  5.6687e-01]],

        [[-2.3185e+00, -1.3191e+00, -1.7786e+00,  ...,  8.3678e+00,
           3.3047e+00, -5.9097e-01],
         [-8.1188e-01, -3.2357e+00, -3.2883e-02,  ...,  1.3220e+00,
          -3.9638e-01,  9.7235e-01],
         [ 6.8207e-01, -7.9400e-01, -2.6729e-01,  ...,  3.2716e+00,
           1.7577e+00,  8.6897e-01],
         ...,
         [ 1.1300e-01,  8.1283e-03,  1.9817e-01,  ...,  3.1213e+00,
           2.6491e+00,  1.7652e+00],
         [ 4.3934e-01,  1.9984e+00, -1.5469e+00,  ...,  3.7783e+00,
          -1.2135e+00,  1.0420e+00],
         [-1.5817e+00,  2.7664e-01, -7.4103e-01,  ...,  1.7232e+00,
           2.1230e-01,  1.5757e-01]],

        [[-2.3185e+00, -1.3191e+00, -1.7786e+00,  ...,  8.3678e+00,
           3.3047e+00, -5.9097e-01],
         [-8.1188e-01, -3.2357e+00, -3.2882e-02,  ...,  1.3220e+00,
          -3.9638e-01,  9.7235e-01],
         [ 6.8208e-01, -7.9400e-01, -2.6728e-01,  ...,  3.2716e+00,
           1.7577e+00,  8.6897e-01],
         ...,
         [-2.2489e-01,  1.7957e-01,  4.9832e-01,  ...,  3.6873e+00,
           1.4884e+00,  1.2771e+00],
         [ 7.2441e-01,  1.7324e+00, -1.6217e+00,  ...,  3.3483e+00,
          -1.1308e+00,  1.0826e+00],
         [-1.6785e+00,  2.0004e-01, -7.9884e-01,  ...,  1.6973e+00,
           1.6387e-01,  1.9091e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 25, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 25]), use_cached_media=False
ğŸŸ¦ T_txt=25
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 25, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 25, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 25, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 25])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 25, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 25, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 25, 64])
ğŸŸ¦ out.shape=torch.Size([3, 25, 512])
ğŸŸ¦ out.shape=torch.Size([3, 25, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 25, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 25, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 25, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-1.2009, -0.4256,  0.9579,  ...,  3.0081,  1.0086, -0.1812],
         [-0.2749, -1.1022, -0.6093,  ...,  1.7677, -1.5354, -0.1590],
         [ 0.9989,  0.1369, -0.1196,  ...,  5.2063,  0.3365, -0.3707],
         ...,
         [-0.4905,  0.3212,  1.3305,  ...,  5.4371,  0.2796,  0.7576],
         [-0.7309,  1.3117,  1.6397,  ...,  2.2348, -1.4950,  0.7095],
         [-0.1340,  1.8127, -0.4585,  ...,  6.8104, -2.1463, -0.0880]],

        [[-1.2009, -0.4256,  0.9579,  ...,  3.0081,  1.0086, -0.1812],
         [-0.2749, -1.1022, -0.6093,  ...,  1.7677, -1.5354, -0.1590],
         [ 0.9989,  0.1369, -0.1196,  ...,  5.2063,  0.3365, -0.3707],
         ...,
         [-0.4712,  0.2593,  0.7816,  ...,  4.7891,  1.3394,  1.2857],
         [-0.0882,  2.4424, -0.8261,  ...,  4.8853, -2.8029,  0.2455],
         [ 0.3400,  0.9791, -1.1667,  ...,  0.0203,  0.3535, -1.3063]],

        [[-1.2009, -0.4256,  0.9579,  ...,  3.0081,  1.0086, -0.1812],
         [-0.2749, -1.1022, -0.6093,  ...,  1.7677, -1.5354, -0.1590],
         [ 0.9989,  0.1369, -0.1195,  ...,  5.2063,  0.3365, -0.3707],
         ...,
         [-0.4905,  0.3212,  1.3305,  ...,  5.4371,  0.2796,  0.7576],
         [ 0.3084,  2.2825, -0.8608,  ...,  4.4687, -2.7245,  0.1768],
         [ 0.2267,  0.9314, -1.2185,  ..., -0.0097,  0.2962, -1.2869]]]), None)
ğŸŸ© FlamingoLMMixinã®é †ä¼æ’­å®Œäº†
ğŸŸ© FlamingoLMMixinã®é †ä¼æ’­é–‹å§‹ input_ids.shape=torch.Size([3, 26]), input_ids.dtype=torch.int64, None if attention_mask is None else attention_mask.shape=torch.Size([3, 26]), dict_keys(['prefix_mask', 'sequence_id', 'past_key_values', 'use_cache', 'return_dict'])
ğŸŸ¦ media_locations.shape=torch.Size([3, 26]), media_locations.dtype=torch.bool
ğŸŸ¦ use_cached_media_locations=False
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ¦ T_txt=26
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 26, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 26, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 26, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 26])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 26, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 26, 64])
ğŸŸ¦ out.shape=torch.Size([3, 26, 512])
ğŸŸ¦ out.shape=torch.Size([3, 26, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 26, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 26, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-0.2093, -0.0591,  0.0653,  ...,  0.4109, -0.3524,  0.3726],
         [-0.0174, -0.1497,  0.0368,  ...,  0.1042,  0.0032,  0.4746],
         [-0.0191, -0.1369, -0.1287,  ...,  0.1608, -0.1576,  0.1995],
         ...,
         [ 0.1546, -0.2127, -0.0173,  ...,  0.0720, -0.0731,  0.4898],
         [ 0.1677,  0.0393,  0.0331,  ...,  0.3379,  0.0133,  0.1894],
         [ 0.0764, -0.0082,  0.0217,  ...,  0.0654, -0.0186, -0.0107]],

        [[-0.2093, -0.0591,  0.0653,  ...,  0.4109, -0.3524,  0.3726],
         [-0.0174, -0.1497,  0.0368,  ...,  0.1042,  0.0032,  0.4746],
         [-0.0191, -0.1369, -0.1287,  ...,  0.1608, -0.1576,  0.1995],
         ...,
         [ 0.1546, -0.2127, -0.0173,  ...,  0.0720, -0.0731,  0.4898],
         [ 0.1677,  0.0393,  0.0331,  ...,  0.3379,  0.0133,  0.1894],
         [-0.0318,  0.0104,  0.0758,  ...,  0.1410, -0.2683,  0.3320]],

        [[-0.2093, -0.0591,  0.0653,  ...,  0.4109, -0.3524,  0.3726],
         [-0.0174, -0.1497,  0.0368,  ...,  0.1042,  0.0032,  0.4746],
         [-0.0191, -0.1369, -0.1287,  ...,  0.1608, -0.1576,  0.1995],
         ...,
         [-0.0100,  0.0373,  0.1066,  ...,  0.1400, -0.2549,  0.3483],
         [ 0.0777, -0.0032,  0.0245,  ...,  0.0613, -0.0327, -0.0114],
         [ 0.0181, -0.2162, -0.0266,  ..., -0.0404,  0.0212,  0.3634]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ¦ T_txt=26
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 26, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 26, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 26, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 26])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 26, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 26, 64])
ğŸŸ¦ out.shape=torch.Size([3, 26, 512])
ğŸŸ¦ out.shape=torch.Size([3, 26, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 26, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 26, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-0.0762, -0.3746,  0.1300,  ...,  0.1017, -0.0332,  0.2191],
         [-0.0236, -0.1139, -0.0499,  ...,  0.0464,  0.0973,  0.4798],
         [ 0.0476, -0.1903,  0.0666,  ..., -0.0123, -0.0800,  0.3086],
         ...,
         [ 0.2166, -0.1439, -0.1998,  ..., -0.2547, -0.1789,  0.4334],
         [ 0.1441,  0.0809,  0.1581,  ...,  0.2499,  0.1149,  0.2712],
         [ 0.1011,  0.0107,  0.0350,  ..., -0.0106, -0.0096,  0.1194]],

        [[-0.0762, -0.3746,  0.1300,  ...,  0.1017, -0.0332,  0.2191],
         [-0.0236, -0.1139, -0.0499,  ...,  0.0464,  0.0973,  0.4798],
         [ 0.0476, -0.1903,  0.0666,  ..., -0.0123, -0.0800,  0.3086],
         ...,
         [ 0.2166, -0.1439, -0.1998,  ..., -0.2547, -0.1789,  0.4334],
         [ 0.1441,  0.0809,  0.1581,  ...,  0.2499,  0.1149,  0.2712],
         [ 0.1116,  0.0091, -0.0224,  ...,  0.0117, -0.3344,  0.3675]],

        [[-0.0762, -0.3746,  0.1300,  ...,  0.1017, -0.0332,  0.2191],
         [-0.0236, -0.1139, -0.0499,  ...,  0.0464,  0.0973,  0.4798],
         [ 0.0476, -0.1903,  0.0666,  ..., -0.0123, -0.0800,  0.3086],
         ...,
         [ 0.1429,  0.0541,  0.0068,  ...,  0.0633, -0.3146,  0.3919],
         [ 0.0919,  0.0096,  0.0307,  ..., -0.0081, -0.0136,  0.1322],
         [ 0.1082, -0.1561, -0.1719,  ..., -0.1287,  0.0805,  0.5493]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ¦ T_txt=26
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 26, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 26, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 26, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 26])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 26, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 26, 64])
ğŸŸ¦ out.shape=torch.Size([3, 26, 512])
ğŸŸ¦ out.shape=torch.Size([3, 26, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 26, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 26, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-0.0423, -0.4800,  0.0985,  ..., -0.1247,  0.1871, -0.2268],
         [-0.0501, -0.1131, -0.1332,  ...,  0.1946,  0.1566,  0.3318],
         [-0.0369, -0.1714,  0.2051,  ...,  0.1376, -0.1982,  0.2490],
         ...,
         [ 0.2193, -0.2403, -0.1173,  ..., -0.1467, -0.0574,  0.2919],
         [ 0.3373, -0.2962,  0.0885,  ...,  0.2633,  0.1972,  0.1149],
         [-0.1160,  0.0092,  0.0017,  ...,  0.0595,  0.0079, -0.0068]],

        [[-0.0423, -0.4800,  0.0985,  ..., -0.1247,  0.1871, -0.2268],
         [-0.0501, -0.1131, -0.1332,  ...,  0.1946,  0.1566,  0.3318],
         [-0.0369, -0.1714,  0.2051,  ...,  0.1376, -0.1982,  0.2490],
         ...,
         [ 0.2193, -0.2403, -0.1173,  ..., -0.1467, -0.0574,  0.2919],
         [ 0.3373, -0.2962,  0.0885,  ...,  0.2633,  0.1972,  0.1149],
         [ 0.2793, -0.4810, -0.1731,  ..., -0.0711, -0.3920,  0.1239]],

        [[-0.0423, -0.4800,  0.0985,  ..., -0.1247,  0.1871, -0.2268],
         [-0.0501, -0.1131, -0.1332,  ...,  0.1946,  0.1566,  0.3318],
         [-0.0369, -0.1714,  0.2051,  ...,  0.1376, -0.1982,  0.2490],
         ...,
         [ 0.3451, -0.3134, -0.1434,  ...,  0.0484, -0.2695,  0.1470],
         [-0.1392,  0.0040, -0.0138,  ...,  0.0598, -0.0136,  0.0108],
         [ 0.0539, -0.1581, -0.1512,  ...,  0.0255,  0.1806,  0.4842]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ¦ T_txt=26
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 26, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 26, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 26, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 26])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 26, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 26, 64])
ğŸŸ¦ out.shape=torch.Size([3, 26, 512])
ğŸŸ¦ out.shape=torch.Size([3, 26, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 26, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 26, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-0.6808, -0.0752, -0.2681,  ..., -0.1388, -0.2275, -0.2143],
         [-0.2353, -0.1768, -0.1707,  ...,  0.0178,  0.0832,  0.2217],
         [ 0.1139, -0.0718,  0.1118,  ...,  0.0826, -0.0978,  0.2029],
         ...,
         [-0.0872, -0.0924, -0.1474,  ..., -0.0083, -0.1085,  0.3296],
         [ 0.1688, -0.3080,  0.0063,  ...,  0.3659,  0.1373,  0.1016],
         [-0.1362, -0.0315,  0.1031,  ...,  0.1227, -0.0441, -0.0527]],

        [[-0.6808, -0.0752, -0.2681,  ..., -0.1388, -0.2275, -0.2143],
         [-0.2353, -0.1768, -0.1707,  ...,  0.0178,  0.0832,  0.2217],
         [ 0.1139, -0.0718,  0.1118,  ...,  0.0826, -0.0978,  0.2029],
         ...,
         [-0.0872, -0.0924, -0.1474,  ..., -0.0083, -0.1085,  0.3296],
         [ 0.1688, -0.3080,  0.0063,  ...,  0.3659,  0.1373,  0.1016],
         [ 0.1318, -0.4454, -0.2198,  ..., -0.1270, -0.7359,  0.1223]],

        [[-0.6808, -0.0752, -0.2681,  ..., -0.1388, -0.2275, -0.2143],
         [-0.2353, -0.1768, -0.1707,  ...,  0.0178,  0.0832,  0.2217],
         [ 0.1139, -0.0718,  0.1118,  ...,  0.0826, -0.0978,  0.2029],
         ...,
         [ 0.2472, -0.4203, -0.2445,  ..., -0.0556, -0.6851,  0.2459],
         [-0.1409, -0.0335,  0.0901,  ...,  0.1262, -0.0717, -0.0317],
         [-0.1151, -0.1234, -0.0849,  ..., -0.0315,  0.1753,  0.3614]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ¦ T_txt=26
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 26, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 26, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 26, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 26])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 26, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 26, 64])
ğŸŸ¦ out.shape=torch.Size([3, 26, 512])
ğŸŸ¦ out.shape=torch.Size([3, 26, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 26, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 26, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.0310,  0.7941, -1.4750,  ...,  0.3614,  1.5208, -0.2439],
         [-0.5725, -0.0922, -0.2418,  ...,  0.0514,  0.0311,  0.2457],
         [ 0.0686, -0.0593,  0.1036,  ...,  0.0507,  0.1819,  0.0491],
         ...,
         [ 0.1142, -0.1232, -0.2430,  ...,  0.1038, -0.0946,  0.4473],
         [ 0.3483, -0.3436,  0.1093,  ...,  0.3054, -0.2380,  0.1830],
         [-0.1603, -0.0339, -0.0379,  ...,  0.1531, -0.0552, -0.0213]],

        [[-4.0310,  0.7941, -1.4750,  ...,  0.3614,  1.5208, -0.2439],
         [-0.5725, -0.0922, -0.2418,  ...,  0.0514,  0.0311,  0.2457],
         [ 0.0686, -0.0593,  0.1036,  ...,  0.0507,  0.1819,  0.0491],
         ...,
         [ 0.1142, -0.1232, -0.2430,  ...,  0.1038, -0.0946,  0.4473],
         [ 0.3483, -0.3436,  0.1093,  ...,  0.3054, -0.2380,  0.1830],
         [-0.0127, -0.4247, -0.4128,  ...,  0.0330, -0.6768, -0.0209]],

        [[-4.0310,  0.7941, -1.4750,  ...,  0.3614,  1.5208, -0.2439],
         [-0.5725, -0.0922, -0.2418,  ...,  0.0514,  0.0311,  0.2457],
         [ 0.0686, -0.0593,  0.1036,  ...,  0.0507,  0.1819,  0.0491],
         ...,
         [ 0.0561, -0.3208, -0.2518,  ...,  0.1978, -0.5437,  0.1993],
         [-0.1113, -0.1143, -0.0607,  ...,  0.0934, -0.0435, -0.0680],
         [-0.2660, -0.0106, -0.2606,  ...,  0.0061,  0.0947,  0.5010]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ¦ T_txt=26
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 26, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 26, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 26, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 26])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 26, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 26, 64])
ğŸŸ¦ out.shape=torch.Size([3, 26, 512])
ğŸŸ¦ out.shape=torch.Size([3, 26, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 26, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 26, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.7946e+00,  9.0221e-01, -1.2882e+00,  ...,  1.1832e+00,
           2.5226e+00, -5.9823e-02],
         [-5.6193e-01, -1.5785e-01, -2.8558e-01,  ..., -3.8618e-02,
          -1.3092e-02,  1.2509e-01],
         [ 4.1303e-03, -1.2649e-01, -2.6289e-01,  ...,  2.2804e-01,
          -9.2656e-02,  5.5100e-03],
         ...,
         [ 1.8597e-01, -2.3619e-01, -3.2535e-01,  ...,  5.0270e-02,
           9.2434e-02,  4.2249e-01],
         [ 2.9708e-01, -5.3556e-01,  9.0744e-02,  ...,  5.6743e-01,
          -3.1411e-01,  4.4154e-01],
         [-3.0899e-01,  1.7894e-01,  1.3580e-01,  ...,  1.1064e-01,
          -5.1119e-02,  2.2545e-02]],

        [[-4.7946e+00,  9.0221e-01, -1.2882e+00,  ...,  1.1832e+00,
           2.5226e+00, -5.9823e-02],
         [-5.6193e-01, -1.5785e-01, -2.8558e-01,  ..., -3.8618e-02,
          -1.3092e-02,  1.2509e-01],
         [ 4.1303e-03, -1.2649e-01, -2.6289e-01,  ...,  2.2804e-01,
          -9.2656e-02,  5.5100e-03],
         ...,
         [ 1.8597e-01, -2.3619e-01, -3.2535e-01,  ...,  5.0271e-02,
           9.2434e-02,  4.2249e-01],
         [ 2.9708e-01, -5.3556e-01,  9.0744e-02,  ...,  5.6743e-01,
          -3.1411e-01,  4.4154e-01],
         [-3.7675e-01, -5.0614e-01, -2.9346e-01,  ..., -2.1442e-01,
          -8.5081e-01, -2.0450e-01]],

        [[-4.7946e+00,  9.0221e-01, -1.2882e+00,  ...,  1.1832e+00,
           2.5226e+00, -5.9824e-02],
         [-5.6193e-01, -1.5785e-01, -2.8558e-01,  ..., -3.8618e-02,
          -1.3092e-02,  1.2509e-01],
         [ 4.1302e-03, -1.2649e-01, -2.6289e-01,  ...,  2.2804e-01,
          -9.2657e-02,  5.5097e-03],
         ...,
         [-1.0711e-01, -4.1903e-01, -2.2295e-01,  ..., -8.4910e-02,
          -8.1008e-01,  6.9410e-02],
         [-2.5848e-01,  1.4609e-01,  6.7453e-02,  ...,  8.3614e-02,
          -7.9746e-02, -1.4668e-02],
         [-5.6699e-01, -2.4759e-02, -1.5113e-01,  ...,  1.4579e-02,
          -6.1826e-02,  5.8786e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ¦ T_txt=26
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 26, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 26, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 26, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 26])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 26, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 26, 64])
ğŸŸ¦ out.shape=torch.Size([3, 26, 512])
ğŸŸ¦ out.shape=torch.Size([3, 26, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 26, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 26, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.2771e+00,  1.3169e+00, -1.5839e+00,  ...,  1.5235e+00,
           2.5618e+00,  3.0273e-01],
         [-5.1019e-01, -2.0753e-01, -3.9353e-01,  ..., -3.0973e-02,
           3.3680e-01,  1.5358e-01],
         [ 9.6702e-02, -5.6518e-01, -1.5635e-01,  ...,  8.8994e-03,
           7.6486e-02, -5.2471e-03],
         ...,
         [ 3.6183e-01, -8.2698e-02, -3.2821e-01,  ..., -1.4714e-01,
           3.8478e-01,  4.9177e-01],
         [ 3.6524e-01, -3.1060e-01,  2.4156e-02,  ...,  5.0680e-01,
          -1.8818e-01,  4.5126e-01],
         [-1.4536e-01,  3.4484e-01,  4.9204e-02,  ...,  1.1870e-01,
          -1.6550e-02, -5.6063e-02]],

        [[-5.2771e+00,  1.3169e+00, -1.5839e+00,  ...,  1.5235e+00,
           2.5618e+00,  3.0273e-01],
         [-5.1019e-01, -2.0753e-01, -3.9353e-01,  ..., -3.0973e-02,
           3.3680e-01,  1.5358e-01],
         [ 9.6702e-02, -5.6518e-01, -1.5635e-01,  ...,  8.8994e-03,
           7.6486e-02, -5.2471e-03],
         ...,
         [ 3.6183e-01, -8.2698e-02, -3.2821e-01,  ..., -1.4714e-01,
           3.8478e-01,  4.9177e-01],
         [ 3.6524e-01, -3.1060e-01,  2.4156e-02,  ...,  5.0680e-01,
          -1.8818e-01,  4.5126e-01],
         [-3.1543e-01, -6.5300e-02, -2.6716e-01,  ..., -9.6837e-02,
          -5.4250e-01, -1.2284e-01]],

        [[-5.2771e+00,  1.3169e+00, -1.5839e+00,  ...,  1.5235e+00,
           2.5618e+00,  3.0273e-01],
         [-5.1019e-01, -2.0753e-01, -3.9353e-01,  ..., -3.0973e-02,
           3.3680e-01,  1.5358e-01],
         [ 9.6702e-02, -5.6518e-01, -1.5635e-01,  ...,  8.8994e-03,
           7.6486e-02, -5.2473e-03],
         ...,
         [-2.1693e-03, -8.4452e-02, -2.1674e-01,  ...,  1.3828e-01,
          -4.5000e-01,  1.3284e-01],
         [-1.2386e-01,  2.9836e-01, -1.0181e-01,  ...,  8.4010e-02,
           5.1625e-02, -7.9607e-02],
         [-3.0820e-01,  2.8663e-02, -2.1373e-01,  ..., -2.2537e-02,
           2.8678e-01,  6.1511e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ¦ T_txt=26
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 26, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 26, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 26, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 26])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 26, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 26, 64])
ğŸŸ¦ out.shape=torch.Size([3, 26, 512])
ğŸŸ¦ out.shape=torch.Size([3, 26, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 26, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 26, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.3925e+00,  1.2785e+00, -1.7428e+00,  ...,  1.6187e+00,
           2.6666e+00,  6.3102e-01],
         [-7.2190e-01, -9.0365e-02, -3.7054e-01,  ..., -4.8731e-02,
           5.0303e-02,  4.0432e-02],
         [ 3.2142e-02, -5.6480e-01, -2.0480e-01,  ...,  6.2425e-02,
          -1.1226e-01,  5.0915e-03],
         ...,
         [ 4.2414e-01, -1.0747e-01, -3.3100e-01,  ..., -3.6299e-02,
           2.2127e-01,  5.8332e-01],
         [ 1.3164e-01, -3.3266e-01, -8.8986e-02,  ...,  5.1443e-01,
          -1.8559e-01, -3.8852e-02],
         [-3.2845e-01,  2.5847e-01,  1.2324e-01,  ...,  1.4198e-01,
          -2.1467e-01, -1.6414e-01]],

        [[-5.3925e+00,  1.2785e+00, -1.7428e+00,  ...,  1.6187e+00,
           2.6666e+00,  6.3102e-01],
         [-7.2190e-01, -9.0365e-02, -3.7054e-01,  ..., -4.8731e-02,
           5.0303e-02,  4.0432e-02],
         [ 3.2142e-02, -5.6480e-01, -2.0480e-01,  ...,  6.2425e-02,
          -1.1226e-01,  5.0915e-03],
         ...,
         [ 4.2414e-01, -1.0747e-01, -3.3100e-01,  ..., -3.6298e-02,
           2.2127e-01,  5.8332e-01],
         [ 1.3164e-01, -3.3266e-01, -8.8985e-02,  ...,  5.1443e-01,
          -1.8559e-01, -3.8853e-02],
         [-3.5816e-01, -2.9295e-02, -4.6898e-01,  ..., -2.5754e-01,
          -6.8066e-01, -3.5683e-01]],

        [[-5.3925e+00,  1.2785e+00, -1.7428e+00,  ...,  1.6187e+00,
           2.6666e+00,  6.3102e-01],
         [-7.2190e-01, -9.0366e-02, -3.7054e-01,  ..., -4.8731e-02,
           5.0304e-02,  4.0432e-02],
         [ 3.2142e-02, -5.6480e-01, -2.0480e-01,  ...,  6.2426e-02,
          -1.1226e-01,  5.0911e-03],
         ...,
         [-7.2948e-02,  1.4121e-01, -3.0084e-01,  ...,  2.2718e-02,
          -5.2362e-01, -1.3222e-01],
         [-1.8546e-01,  1.4471e-01,  8.1019e-02,  ...,  5.5264e-02,
          -1.6732e-01, -1.4840e-01],
         [-4.4084e-01,  6.4046e-03, -1.7165e-01,  ..., -4.4606e-02,
           1.7631e-02,  5.5833e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ¦ T_txt=26
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 26, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 26, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 26, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 26])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 26, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 26, 64])
ğŸŸ¦ out.shape=torch.Size([3, 26, 512])
ğŸŸ¦ out.shape=torch.Size([3, 26, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 26, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 26, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.7653,  1.1008, -1.8155,  ...,  2.3020,  2.1681,  1.0300],
         [-0.6620, -0.0777, -0.5133,  ..., -0.2264,  0.1684, -0.0159],
         [ 0.0287, -0.6121, -0.4236,  ..., -0.2224,  0.0996,  0.0129],
         ...,
         [ 0.2436, -0.3087, -0.2884,  ..., -0.2758,  0.3244,  0.0340],
         [ 0.1146, -0.3686, -0.2752,  ...,  0.0983, -0.1809, -0.2610],
         [-0.3670,  0.3838,  0.0439,  ..., -0.0436, -0.1331, -0.5332]],

        [[-5.7653,  1.1008, -1.8155,  ...,  2.3020,  2.1681,  1.0300],
         [-0.6620, -0.0777, -0.5133,  ..., -0.2264,  0.1684, -0.0159],
         [ 0.0287, -0.6121, -0.4236,  ..., -0.2224,  0.0996,  0.0129],
         ...,
         [ 0.2436, -0.3087, -0.2884,  ..., -0.2758,  0.3244,  0.0340],
         [ 0.1146, -0.3686, -0.2752,  ...,  0.0983, -0.1809, -0.2610],
         [-0.1091, -0.1604, -0.4950,  ..., -0.3915, -0.7502, -0.3274]],

        [[-5.7653,  1.1008, -1.8155,  ...,  2.3020,  2.1681,  1.0300],
         [-0.6620, -0.0777, -0.5133,  ..., -0.2264,  0.1684, -0.0159],
         [ 0.0287, -0.6121, -0.4236,  ..., -0.2224,  0.0996,  0.0129],
         ...,
         [ 0.2161, -0.0984, -0.5429,  ..., -0.1137, -0.5802, -0.3195],
         [-0.2282,  0.3068,  0.0324,  ..., -0.1362, -0.0707, -0.5582],
         [-0.3149, -0.0817, -0.3575,  ..., -0.2174,  0.0176,  0.1418]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ¦ T_txt=26
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 26, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 26, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 26, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 26])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 26, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 26, 64])
ğŸŸ¦ out.shape=torch.Size([3, 26, 512])
ğŸŸ¦ out.shape=torch.Size([3, 26, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 26, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 26, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.8693e+00,  9.3745e-01, -1.8379e+00,  ...,  2.4698e+00,
           2.0660e+00,  1.2787e+00],
         [-6.8941e-01,  2.4615e-01, -4.9576e-01,  ..., -2.5218e-01,
           1.5029e-01,  7.9583e-02],
         [ 1.1727e-01, -2.8995e-01, -5.4170e-01,  ..., -1.3670e-01,
           7.0987e-02,  1.0259e-01],
         ...,
         [ 2.1023e-02, -6.2653e-02, -4.0409e-01,  ..., -4.3246e-01,
           2.9215e-01,  3.4777e-02],
         [ 3.0940e-01,  2.8978e-01,  2.0281e-02,  ...,  2.4821e-03,
          -5.3647e-01, -2.2344e-01],
         [-3.3876e-01,  5.2658e-01, -1.9298e-02,  ...,  8.7357e-02,
          -3.9318e-02, -1.3851e-01]],

        [[-5.8693e+00,  9.3745e-01, -1.8379e+00,  ...,  2.4698e+00,
           2.0660e+00,  1.2787e+00],
         [-6.8941e-01,  2.4615e-01, -4.9576e-01,  ..., -2.5218e-01,
           1.5029e-01,  7.9583e-02],
         [ 1.1727e-01, -2.8995e-01, -5.4170e-01,  ..., -1.3670e-01,
           7.0987e-02,  1.0259e-01],
         ...,
         [ 2.1023e-02, -6.2654e-02, -4.0409e-01,  ..., -4.3246e-01,
           2.9215e-01,  3.4777e-02],
         [ 3.0940e-01,  2.8978e-01,  2.0281e-02,  ...,  2.4819e-03,
          -5.3647e-01, -2.2344e-01],
         [-4.8989e-02,  2.2977e-02, -5.6571e-01,  ..., -2.5247e-01,
          -8.3652e-01, -1.8707e-01]],

        [[-5.8693e+00,  9.3745e-01, -1.8379e+00,  ...,  2.4698e+00,
           2.0660e+00,  1.2787e+00],
         [-6.8941e-01,  2.4615e-01, -4.9576e-01,  ..., -2.5218e-01,
           1.5029e-01,  7.9583e-02],
         [ 1.1727e-01, -2.8995e-01, -5.4170e-01,  ..., -1.3670e-01,
           7.0987e-02,  1.0259e-01],
         ...,
         [ 3.4921e-01,  2.5731e-01, -5.2416e-01,  ..., -1.0038e-01,
          -7.9638e-01, -2.4247e-01],
         [-2.8065e-01,  4.5307e-01,  2.8570e-02,  ..., -4.9174e-02,
           8.1136e-03, -1.4153e-01],
         [-3.5433e-01, -2.3786e-01, -5.0937e-01,  ..., -9.7654e-02,
           1.9145e-01,  6.0930e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ¦ T_txt=26
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 26, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 26, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 26, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 26])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 26, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 26, 64])
ğŸŸ¦ out.shape=torch.Size([3, 26, 512])
ğŸŸ¦ out.shape=torch.Size([3, 26, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 26, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 26, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.6016e+00,  1.2408e+00, -1.6460e+00,  ...,  3.1029e+00,
           2.1120e+00,  1.1936e+00],
         [-5.1318e-01,  1.3069e-01, -5.7248e-01,  ..., -8.0478e-02,
           3.0335e-02, -1.3672e-01],
         [ 2.1050e-01, -6.8635e-01, -6.6328e-01,  ...,  2.2120e-01,
           3.5946e-01,  2.3200e-01],
         ...,
         [ 1.3018e-01, -4.5976e-02, -5.4057e-01,  ..., -3.2460e-01,
           2.6987e-01, -5.8595e-02],
         [ 6.8112e-01,  5.5986e-02,  1.2636e-01,  ...,  1.1199e-01,
          -7.5633e-01, -3.2698e-01],
         [-4.7474e-01,  3.9976e-01,  2.6517e-01,  ...,  3.5566e-02,
          -2.7465e-01, -1.5553e-01]],

        [[-5.6016e+00,  1.2408e+00, -1.6460e+00,  ...,  3.1029e+00,
           2.1120e+00,  1.1936e+00],
         [-5.1318e-01,  1.3069e-01, -5.7248e-01,  ..., -8.0478e-02,
           3.0335e-02, -1.3672e-01],
         [ 2.1050e-01, -6.8635e-01, -6.6328e-01,  ...,  2.2120e-01,
           3.5946e-01,  2.3200e-01],
         ...,
         [ 1.3018e-01, -4.5977e-02, -5.4056e-01,  ..., -3.2460e-01,
           2.6987e-01, -5.8595e-02],
         [ 6.8112e-01,  5.5986e-02,  1.2636e-01,  ...,  1.1199e-01,
          -7.5633e-01, -3.2698e-01],
         [ 2.1124e-01,  6.0799e-02, -2.5274e-01,  ..., -5.0233e-02,
          -1.0710e+00, -3.4929e-01]],

        [[-5.6016e+00,  1.2408e+00, -1.6460e+00,  ...,  3.1029e+00,
           2.1120e+00,  1.1936e+00],
         [-5.1318e-01,  1.3069e-01, -5.7248e-01,  ..., -8.0478e-02,
           3.0336e-02, -1.3672e-01],
         [ 2.1050e-01, -6.8635e-01, -6.6328e-01,  ...,  2.2120e-01,
           3.5946e-01,  2.3200e-01],
         ...,
         [ 6.4809e-01,  7.6813e-02, -2.2250e-03,  ...,  4.3426e-02,
          -8.3110e-01, -4.9535e-01],
         [-3.8452e-01,  3.1135e-01,  2.6976e-01,  ..., -9.6989e-02,
          -2.4907e-01, -1.5286e-01],
         [-4.0706e-01, -2.4391e-01, -2.5247e-01,  ...,  1.1959e-02,
          -4.7926e-02,  4.7690e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ¦ T_txt=26
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 26, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 26, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 26, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 26])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 26, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 26, 64])
ğŸŸ¦ out.shape=torch.Size([3, 26, 512])
ğŸŸ¦ out.shape=torch.Size([3, 26, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 26, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 26, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.5722,  1.3828, -1.6196,  ...,  3.5095,  2.5083,  1.2801],
         [-0.7604,  0.1403, -0.7794,  ...,  0.1032,  0.1174, -0.2312],
         [-0.0521, -0.3372, -0.8223,  ...,  0.0621,  0.1464,  0.1382],
         ...,
         [-0.0794, -0.1273, -0.3627,  ..., -0.5834,  0.4231, -0.0958],
         [ 0.5518,  0.2439, -0.0876,  ...,  0.2645, -1.1485, -0.2385],
         [-0.5903,  0.6246,  0.0362,  ..., -0.2740, -0.1611, -0.0683]],

        [[-5.5722,  1.3828, -1.6196,  ...,  3.5095,  2.5083,  1.2801],
         [-0.7604,  0.1403, -0.7794,  ...,  0.1032,  0.1174, -0.2312],
         [-0.0521, -0.3372, -0.8223,  ...,  0.0621,  0.1464,  0.1382],
         ...,
         [-0.0794, -0.1273, -0.3627,  ..., -0.5834,  0.4231, -0.0958],
         [ 0.5518,  0.2439, -0.0876,  ...,  0.2645, -1.1485, -0.2385],
         [ 0.1893,  0.3143, -0.3975,  ...,  0.1675, -1.1192, -0.3290]],

        [[-5.5722,  1.3828, -1.6196,  ...,  3.5095,  2.5083,  1.2801],
         [-0.7604,  0.1403, -0.7794,  ...,  0.1032,  0.1174, -0.2312],
         [-0.0521, -0.3372, -0.8223,  ...,  0.0621,  0.1464,  0.1382],
         ...,
         [ 0.4279,  0.3293, -0.2094,  ...,  0.2401, -1.0083, -0.4063],
         [-0.4674,  0.4709,  0.0801,  ..., -0.2831, -0.0674, -0.0350],
         [-0.3847, -0.4440, -0.4115,  ..., -0.3271, -0.4279,  0.5181]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ¦ T_txt=26
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 26, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 26, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 26, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 26])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 26, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 26, 64])
ğŸŸ¦ out.shape=torch.Size([3, 26, 512])
ğŸŸ¦ out.shape=torch.Size([3, 26, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 26, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 26, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.6640,  1.4165, -1.7391,  ...,  3.7237,  2.6647,  1.4654],
         [-0.6078, -0.0251, -1.0078,  ...,  0.0240, -0.0394, -0.4400],
         [-0.2394, -0.7447, -0.9997,  ..., -0.1766,  0.0965,  0.0557],
         ...,
         [-0.1628, -0.5103, -0.2968,  ..., -0.6998,  0.8058, -0.1868],
         [ 0.3320,  0.0154, -0.0785,  ...,  0.4108, -1.0679, -0.2036],
         [-1.0822,  0.9224, -0.1780,  ..., -0.2300,  0.2295, -0.0240]],

        [[-5.6640,  1.4165, -1.7391,  ...,  3.7237,  2.6647,  1.4654],
         [-0.6078, -0.0251, -1.0078,  ...,  0.0240, -0.0394, -0.4400],
         [-0.2394, -0.7447, -0.9997,  ..., -0.1766,  0.0965,  0.0557],
         ...,
         [-0.1628, -0.5103, -0.2968,  ..., -0.6998,  0.8058, -0.1868],
         [ 0.3320,  0.0154, -0.0785,  ...,  0.4108, -1.0679, -0.2036],
         [ 0.0475,  0.0482, -0.4083,  ...,  0.1022, -0.9063, -0.0679]],

        [[-5.6640,  1.4165, -1.7391,  ...,  3.7237,  2.6647,  1.4654],
         [-0.6078, -0.0251, -1.0078,  ...,  0.0240, -0.0394, -0.4400],
         [-0.2394, -0.7447, -0.9997,  ..., -0.1766,  0.0965,  0.0557],
         ...,
         [ 0.2922,  0.1570, -0.2512,  ...,  0.2008, -1.0361, -0.2140],
         [-0.9957,  0.8342, -0.1901,  ..., -0.2309,  0.2770, -0.0235],
         [-0.5858, -0.6718, -0.2322,  ..., -0.1393, -0.3600,  0.3833]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ¦ T_txt=26
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 26, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 26, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 26, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 26])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 26, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 26, 64])
ğŸŸ¦ out.shape=torch.Size([3, 26, 512])
ğŸŸ¦ out.shape=torch.Size([3, 26, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 26, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 26, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.3878e+00,  1.2637e+00, -1.3476e+00,  ...,  3.9388e+00,
           2.7129e+00,  1.6259e+00],
         [-6.7732e-01,  6.8938e-03, -7.3291e-01,  ...,  2.0232e-01,
           1.7429e-01, -1.7563e-01],
         [-3.5867e-01, -5.9444e-01, -1.0050e+00,  ...,  2.2751e-01,
           4.6504e-01,  1.9952e-01],
         ...,
         [-1.4153e-01, -5.6855e-01, -5.6364e-01,  ..., -7.2460e-01,
           7.3500e-01, -6.9292e-03],
         [ 4.0864e-01,  1.6629e-01, -3.0298e-01,  ...,  5.9822e-01,
          -1.0544e+00, -3.2365e-01],
         [-1.1367e+00,  8.1945e-01, -3.3105e-01,  ..., -1.8592e-01,
           1.3247e-01,  1.1749e-01]],

        [[-5.3878e+00,  1.2637e+00, -1.3476e+00,  ...,  3.9388e+00,
           2.7129e+00,  1.6259e+00],
         [-6.7732e-01,  6.8938e-03, -7.3291e-01,  ...,  2.0232e-01,
           1.7429e-01, -1.7563e-01],
         [-3.5867e-01, -5.9444e-01, -1.0050e+00,  ...,  2.2751e-01,
           4.6504e-01,  1.9952e-01],
         ...,
         [-1.4153e-01, -5.6855e-01, -5.6364e-01,  ..., -7.2460e-01,
           7.3500e-01, -6.9287e-03],
         [ 4.0864e-01,  1.6629e-01, -3.0299e-01,  ...,  5.9822e-01,
          -1.0544e+00, -3.2365e-01],
         [ 7.4614e-02,  1.1541e-01, -4.2981e-01,  ..., -7.4750e-02,
          -9.4286e-01,  2.8947e-02]],

        [[-5.3878e+00,  1.2637e+00, -1.3476e+00,  ...,  3.9388e+00,
           2.7129e+00,  1.6259e+00],
         [-6.7732e-01,  6.8932e-03, -7.3291e-01,  ...,  2.0232e-01,
           1.7429e-01, -1.7563e-01],
         [-3.5867e-01, -5.9444e-01, -1.0050e+00,  ...,  2.2751e-01,
           4.6504e-01,  1.9952e-01],
         ...,
         [ 4.3326e-01,  2.4291e-01, -4.5843e-01,  ...,  2.6419e-01,
          -1.1859e+00, -5.0818e-02],
         [-1.0259e+00,  7.5406e-01, -3.3577e-01,  ..., -2.1700e-01,
           1.9110e-01,  1.8016e-01],
         [-7.7945e-01, -8.2923e-01, -6.0682e-01,  ..., -2.8924e-02,
           5.2436e-03,  4.9907e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ¦ T_txt=26
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 26, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 26, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 26, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 26])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 26, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 26, 64])
ğŸŸ¦ out.shape=torch.Size([3, 26, 512])
ğŸŸ¦ out.shape=torch.Size([3, 26, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 26, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 26, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-5.0959,  0.8567, -1.2666,  ...,  3.8593,  2.8167,  1.9328],
         [-0.9069, -0.3564, -0.8761,  ...,  0.1384,  0.2888, -0.1783],
         [-0.2450, -0.8774, -1.2020,  ...,  0.3088,  0.3829,  0.2829],
         ...,
         [ 0.1424, -0.2069, -0.5607,  ..., -0.8078,  0.9837,  0.1046],
         [ 0.7327, -0.0366, -0.2507,  ...,  0.8824, -0.8270, -0.3381],
         [-1.4948,  0.7576, -0.5307,  ...,  0.1487,  0.2796,  0.2533]],

        [[-5.0959,  0.8567, -1.2666,  ...,  3.8593,  2.8167,  1.9328],
         [-0.9069, -0.3564, -0.8761,  ...,  0.1384,  0.2888, -0.1783],
         [-0.2450, -0.8774, -1.2020,  ...,  0.3088,  0.3829,  0.2829],
         ...,
         [ 0.1424, -0.2069, -0.5607,  ..., -0.8078,  0.9837,  0.1046],
         [ 0.7327, -0.0366, -0.2507,  ...,  0.8824, -0.8270, -0.3381],
         [-0.0328,  0.1482, -0.3004,  ...,  0.2470, -0.7588,  0.3955]],

        [[-5.0959,  0.8567, -1.2666,  ...,  3.8593,  2.8167,  1.9328],
         [-0.9069, -0.3564, -0.8761,  ...,  0.1384,  0.2888, -0.1783],
         [-0.2450, -0.8774, -1.2020,  ...,  0.3088,  0.3829,  0.2829],
         ...,
         [ 0.4157,  0.3295, -0.3295,  ...,  0.5478, -1.0504,  0.2880],
         [-1.3828,  0.7323, -0.5127,  ...,  0.0650,  0.3360,  0.2833],
         [-0.6639, -1.0509, -0.5311,  ...,  0.1157,  0.3729,  0.4885]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ¦ T_txt=26
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 26, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 26, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 26, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 26])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 26, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 26, 64])
ğŸŸ¦ out.shape=torch.Size([3, 26, 512])
ğŸŸ¦ out.shape=torch.Size([3, 26, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 26, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 26, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.8058e+00,  7.3018e-01, -1.0989e+00,  ...,  3.8324e+00,
           2.7810e+00,  1.7821e+00],
         [-7.0377e-01, -6.3927e-01, -6.2966e-01,  ..., -3.5871e-02,
           1.7194e-01, -3.3438e-01],
         [-1.6488e-01, -7.0103e-01, -9.2414e-01,  ...,  5.3185e-01,
           1.6227e-01, -1.6698e-01],
         ...,
         [-3.3330e-01,  2.1282e-01, -8.5601e-01,  ..., -7.4651e-01,
           8.6654e-01, -4.7343e-03],
         [ 2.6426e-01,  2.6206e-01, -5.6295e-01,  ...,  1.0858e+00,
          -9.5241e-01, -3.3721e-01],
         [-1.4506e+00,  5.6055e-01, -5.8809e-01,  ...,  3.6316e-01,
           4.1123e-01, -1.2950e-01]],

        [[-4.8058e+00,  7.3018e-01, -1.0989e+00,  ...,  3.8324e+00,
           2.7810e+00,  1.7821e+00],
         [-7.0377e-01, -6.3927e-01, -6.2966e-01,  ..., -3.5871e-02,
           1.7194e-01, -3.3438e-01],
         [-1.6488e-01, -7.0103e-01, -9.2414e-01,  ...,  5.3185e-01,
           1.6227e-01, -1.6698e-01],
         ...,
         [-3.3330e-01,  2.1282e-01, -8.5601e-01,  ..., -7.4651e-01,
           8.6654e-01, -4.7341e-03],
         [ 2.6426e-01,  2.6206e-01, -5.6296e-01,  ...,  1.0858e+00,
          -9.5241e-01, -3.3721e-01],
         [-2.9092e-01,  1.8784e-01, -7.5083e-01,  ...,  5.4788e-01,
          -1.1320e+00,  1.4647e-01]],

        [[-4.8058e+00,  7.3018e-01, -1.0989e+00,  ...,  3.8324e+00,
           2.7810e+00,  1.7821e+00],
         [-7.0377e-01, -6.3927e-01, -6.2966e-01,  ..., -3.5870e-02,
           1.7194e-01, -3.3437e-01],
         [-1.6488e-01, -7.0103e-01, -9.2414e-01,  ...,  5.3185e-01,
           1.6227e-01, -1.6698e-01],
         ...,
         [ 1.2331e-01,  4.3793e-01, -7.6396e-01,  ...,  8.5062e-01,
          -1.4413e+00,  7.2749e-02],
         [-1.3262e+00,  5.6989e-01, -6.2491e-01,  ...,  2.3833e-01,
           4.0483e-01, -9.7607e-02],
         [-6.6170e-01, -9.6925e-01, -4.5140e-01,  ..., -2.4435e-01,
           4.3864e-01,  4.5787e-01]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ¦ T_txt=26
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 26, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 26, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 26, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 26])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 26, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 26, 64])
ğŸŸ¦ out.shape=torch.Size([3, 26, 512])
ğŸŸ¦ out.shape=torch.Size([3, 26, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 26, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 26, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.5423,  0.4867, -1.3078,  ...,  4.0570,  2.7591,  1.7055],
         [-0.7944, -1.0986, -0.8873,  ..., -0.3006, -0.1496, -0.3139],
         [ 0.3003, -0.6765, -0.9426,  ...,  0.2994,  0.2125, -0.2227],
         ...,
         [-0.2928,  0.2379, -1.2926,  ..., -1.2829,  0.4944,  0.1044],
         [ 0.2314,  0.4070, -0.9769,  ...,  1.1371, -0.9586, -0.4296],
         [-1.7768,  0.4245, -0.8725,  ...,  0.7475,  0.3110, -0.4455]],

        [[-4.5423,  0.4867, -1.3078,  ...,  4.0570,  2.7591,  1.7055],
         [-0.7944, -1.0986, -0.8873,  ..., -0.3006, -0.1496, -0.3139],
         [ 0.3003, -0.6765, -0.9426,  ...,  0.2994,  0.2125, -0.2227],
         ...,
         [-0.2928,  0.2379, -1.2926,  ..., -1.2829,  0.4944,  0.1044],
         [ 0.2314,  0.4070, -0.9769,  ...,  1.1371, -0.9586, -0.4296],
         [-0.2928, -0.0816, -0.9656,  ...,  0.5797, -1.0326,  0.3242]],

        [[-4.5423,  0.4867, -1.3078,  ...,  4.0570,  2.7591,  1.7055],
         [-0.7944, -1.0986, -0.8873,  ..., -0.3006, -0.1496, -0.3139],
         [ 0.3003, -0.6765, -0.9426,  ...,  0.2994,  0.2125, -0.2227],
         ...,
         [ 0.0809,  0.3825, -0.8883,  ...,  0.7028, -1.3656,  0.1694],
         [-1.6531,  0.4312, -0.8482,  ...,  0.6424,  0.2859, -0.4425],
         [-0.6280, -1.0341, -0.5352,  ..., -0.2008,  0.4989,  0.3991]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ¦ T_txt=26
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 26, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 26, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 26, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 26])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 26, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 26, 64])
ğŸŸ¦ out.shape=torch.Size([3, 26, 512])
ğŸŸ¦ out.shape=torch.Size([3, 26, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 26, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 26, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.4194,  0.4068, -1.0771,  ...,  4.0394,  2.7712,  1.5921],
         [-1.0025, -1.3143, -1.0197,  ..., -0.7655, -0.0488, -0.4858],
         [ 0.0073, -0.6469, -0.9511,  ...,  0.0354,  0.6350,  0.2235],
         ...,
         [ 0.3860,  0.4136, -1.3120,  ..., -1.2965,  0.5401,  0.2613],
         [ 0.2150,  0.3973, -0.7569,  ...,  1.4225, -0.6833, -0.2296],
         [-2.0199,  0.5090, -0.6947,  ...,  0.4944,  0.6247, -0.2591]],

        [[-4.4194,  0.4068, -1.0771,  ...,  4.0394,  2.7712,  1.5921],
         [-1.0025, -1.3143, -1.0197,  ..., -0.7655, -0.0488, -0.4858],
         [ 0.0073, -0.6469, -0.9511,  ...,  0.0354,  0.6350,  0.2235],
         ...,
         [ 0.3860,  0.4136, -1.3120,  ..., -1.2965,  0.5401,  0.2613],
         [ 0.2150,  0.3973, -0.7569,  ...,  1.4225, -0.6833, -0.2296],
         [-0.6718,  0.0828, -0.7497,  ...,  0.6439, -0.7081,  0.6340]],

        [[-4.4194,  0.4068, -1.0771,  ...,  4.0394,  2.7712,  1.5921],
         [-1.0025, -1.3143, -1.0197,  ..., -0.7654, -0.0488, -0.4858],
         [ 0.0073, -0.6469, -0.9511,  ...,  0.0354,  0.6350,  0.2235],
         ...,
         [-0.2509,  0.6452, -0.7794,  ...,  0.9288, -0.9705,  0.4292],
         [-1.8423,  0.5681, -0.6620,  ...,  0.3672,  0.6592, -0.2609],
         [-0.4635, -0.8826, -0.6092,  ..., -0.0139,  0.9351,  0.4897]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ¦ T_txt=26
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 26, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 26, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 26, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 26])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 26, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 26, 64])
ğŸŸ¦ out.shape=torch.Size([3, 26, 512])
ğŸŸ¦ out.shape=torch.Size([3, 26, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 26, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 26, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.6486,  0.4370, -1.0679,  ...,  4.0760,  2.7873,  1.4896],
         [-0.9182, -1.6641, -0.8037,  ..., -1.0706, -0.0978,  0.0856],
         [-0.3296, -1.1621, -1.2796,  ..., -0.3973,  0.5544,  0.2346],
         ...,
         [-0.0973,  0.5005, -1.0022,  ..., -0.9380,  0.2883,  0.3512],
         [-0.8473,  0.6445, -0.8234,  ...,  1.9850, -0.4756, -0.0405],
         [-2.2173,  0.7783, -0.6844,  ...,  0.3516,  0.5015, -0.4225]],

        [[-4.6486,  0.4370, -1.0679,  ...,  4.0760,  2.7873,  1.4896],
         [-0.9182, -1.6641, -0.8037,  ..., -1.0706, -0.0978,  0.0856],
         [-0.3296, -1.1621, -1.2796,  ..., -0.3973,  0.5544,  0.2346],
         ...,
         [-0.0973,  0.5005, -1.0022,  ..., -0.9380,  0.2883,  0.3512],
         [-0.8473,  0.6445, -0.8234,  ...,  1.9850, -0.4756, -0.0405],
         [-1.5772,  0.3978, -0.9900,  ...,  1.1678, -0.7330,  0.6296]],

        [[-4.6486,  0.4370, -1.0679,  ...,  4.0760,  2.7874,  1.4896],
         [-0.9182, -1.6641, -0.8037,  ..., -1.0706, -0.0978,  0.0856],
         [-0.3296, -1.1621, -1.2796,  ..., -0.3973,  0.5544,  0.2346],
         ...,
         [-1.0622,  0.8656, -0.8969,  ...,  1.2639, -0.9840,  0.4175],
         [-2.0223,  0.8421, -0.6398,  ...,  0.2292,  0.5133, -0.4349],
         [-1.0333, -1.0175, -0.5481,  ..., -0.2451,  0.6274,  0.7374]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ¦ T_txt=26
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 26, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 26, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 26, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 26])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 26, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 26, 64])
ğŸŸ¦ out.shape=torch.Size([3, 26, 512])
ğŸŸ¦ out.shape=torch.Size([3, 26, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 26, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 26, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.6982,  0.6115, -1.1511,  ...,  3.9602,  2.6816,  1.0754],
         [-0.8318, -2.6615, -1.2791,  ..., -1.1889,  0.2650, -0.4843],
         [-0.0270, -1.6365, -1.4973,  ..., -0.5320,  0.8756,  0.4654],
         ...,
         [-0.6684,  0.7412, -0.7458,  ..., -0.2329,  0.1675, -0.0535],
         [-0.3859,  0.8917, -1.2309,  ...,  2.4433, -1.2303, -0.2932],
         [-2.5293,  1.0956, -0.4662,  ...,  0.3758,  0.4679, -0.4696]],

        [[-4.6982,  0.6115, -1.1511,  ...,  3.9602,  2.6816,  1.0754],
         [-0.8318, -2.6615, -1.2791,  ..., -1.1889,  0.2650, -0.4843],
         [-0.0270, -1.6365, -1.4973,  ..., -0.5320,  0.8756,  0.4654],
         ...,
         [-0.6684,  0.7412, -0.7458,  ..., -0.2329,  0.1675, -0.0535],
         [-0.3859,  0.8917, -1.2309,  ...,  2.4433, -1.2303, -0.2932],
         [-1.1821,  0.4699, -1.2756,  ...,  1.3188, -1.3518,  0.1262]],

        [[-4.6982,  0.6115, -1.1511,  ...,  3.9602,  2.6816,  1.0754],
         [-0.8318, -2.6615, -1.2791,  ..., -1.1889,  0.2650, -0.4843],
         [-0.0270, -1.6365, -1.4973,  ..., -0.5320,  0.8756,  0.4654],
         ...,
         [-0.5257,  1.0484, -1.3466,  ...,  1.4207, -1.5212, -0.0478],
         [-2.3589,  1.2300, -0.4139,  ...,  0.2365,  0.4524, -0.4830],
         [-0.9271, -1.4155, -0.7659,  ...,  0.0590,  0.6625,  0.4101]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ¦ T_txt=26
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 26, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 26, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 26, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 26])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 26, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 26, 64])
ğŸŸ¦ out.shape=torch.Size([3, 26, 512])
ğŸŸ¦ out.shape=torch.Size([3, 26, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 26, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 26, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-4.1992,  0.1086, -1.3292,  ...,  4.5845,  3.1037,  0.6413],
         [-1.7888, -3.0735, -0.9035,  ..., -0.6403, -0.3643, -0.1203],
         [ 0.6715, -1.5127, -1.2408,  ...,  0.3204,  1.0818,  0.3063],
         ...,
         [-0.6129,  0.2174, -0.6116,  ..., -0.1567, -0.2417,  0.6197],
         [ 0.0445,  0.6043, -1.3336,  ...,  2.9810, -0.9202,  0.4459],
         [-2.3648,  0.6499, -0.4537,  ...,  0.7906,  0.5454, -0.5912]],

        [[-4.1992,  0.1086, -1.3292,  ...,  4.5845,  3.1037,  0.6413],
         [-1.7888, -3.0735, -0.9035,  ..., -0.6403, -0.3643, -0.1203],
         [ 0.6715, -1.5127, -1.2408,  ...,  0.3204,  1.0818,  0.3063],
         ...,
         [-0.6129,  0.2174, -0.6116,  ..., -0.1567, -0.2417,  0.6197],
         [ 0.0445,  0.6043, -1.3337,  ...,  2.9810, -0.9202,  0.4459],
         [-0.8265,  0.0534, -1.5256,  ...,  2.0943, -1.4424,  0.5435]],

        [[-4.1992,  0.1086, -1.3292,  ...,  4.5845,  3.1037,  0.6413],
         [-1.7888, -3.0735, -0.9035,  ..., -0.6403, -0.3643, -0.1203],
         [ 0.6715, -1.5127, -1.2408,  ...,  0.3204,  1.0818,  0.3063],
         ...,
         [-0.0319,  0.5088, -1.5616,  ...,  1.9469, -1.5413,  0.3362],
         [-2.1351,  0.8356, -0.4322,  ...,  0.6923,  0.6194, -0.6441],
         [-0.6924, -1.4550, -0.1844,  ...,  0.6437,  0.6806,  0.1286]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ¦ T_txt=26
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 26, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 26, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 26, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 26])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 26, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 26, 64])
ğŸŸ¦ out.shape=torch.Size([3, 26, 512])
ğŸŸ¦ out.shape=torch.Size([3, 26, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 26, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 26, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-3.4956, -0.4549, -1.3173,  ...,  5.3489,  3.8643,  0.0495],
         [-1.1846, -2.7309, -0.3251,  ..., -0.5469, -0.2345,  0.0928],
         [ 0.3590, -0.8857, -1.3176,  ...,  0.7098,  1.7219,  0.2027],
         ...,
         [-0.1360,  0.7697,  0.0640,  ..., -0.0583,  0.4507,  0.4356],
         [ 0.6855,  0.9001, -1.5967,  ...,  3.1686,  0.1257,  0.0960],
         [-2.5249,  0.3872, -0.3274,  ...,  0.6133,  0.4729, -0.6236]],

        [[-3.4956, -0.4549, -1.3173,  ...,  5.3489,  3.8643,  0.0495],
         [-1.1846, -2.7309, -0.3251,  ..., -0.5469, -0.2345,  0.0928],
         [ 0.3590, -0.8857, -1.3176,  ...,  0.7098,  1.7219,  0.2027],
         ...,
         [-0.1360,  0.7697,  0.0640,  ..., -0.0583,  0.4507,  0.4356],
         [ 0.6855,  0.9001, -1.5968,  ...,  3.1686,  0.1257,  0.0960],
         [-0.3854,  0.3506, -1.5744,  ...,  2.2885, -0.8089,  0.3093]],

        [[-3.4956, -0.4549, -1.3173,  ...,  5.3489,  3.8643,  0.0495],
         [-1.1846, -2.7309, -0.3251,  ..., -0.5469, -0.2345,  0.0928],
         [ 0.3590, -0.8857, -1.3176,  ...,  0.7098,  1.7219,  0.2027],
         ...,
         [ 0.6183,  0.9216, -1.7594,  ...,  1.9905, -1.1381,  0.1891],
         [-2.2879,  0.5559, -0.2919,  ...,  0.4960,  0.5658, -0.5986],
         [-0.9876, -0.8078, -0.1859,  ...,  1.3774,  0.8793,  0.3978]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ¦ T_txt=26
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 26, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 26, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 26, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 26])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 26, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 26, 64])
ğŸŸ¦ out.shape=torch.Size([3, 26, 512])
ğŸŸ¦ out.shape=torch.Size([3, 26, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 26, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 26, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-2.3185, -1.3191, -1.7786,  ...,  8.3678,  3.3047, -0.5910],
         [-0.8119, -3.2357, -0.0329,  ...,  1.3220, -0.3964,  0.9723],
         [ 0.6821, -0.7940, -0.2673,  ...,  3.2716,  1.7577,  0.8690],
         ...,
         [-1.2323,  0.8837,  0.7243,  ...,  0.4906,  0.3391,  1.7801],
         [ 0.3210,  1.5600, -1.0896,  ...,  5.5041, -0.3951,  0.5669],
         [-1.8368,  0.1681, -0.7164,  ...,  1.7837,  0.1392,  0.1526]],

        [[-2.3185, -1.3191, -1.7786,  ...,  8.3678,  3.3047, -0.5910],
         [-0.8119, -3.2357, -0.0329,  ...,  1.3220, -0.3964,  0.9723],
         [ 0.6821, -0.7940, -0.2673,  ...,  3.2716,  1.7577,  0.8690],
         ...,
         [-1.2323,  0.8837,  0.7243,  ...,  0.4906,  0.3391,  1.7801],
         [ 0.3210,  1.5600, -1.0896,  ...,  5.5041, -0.3951,  0.5669],
         [-0.4977,  1.3903, -1.2691,  ...,  4.2845, -1.1480,  1.1179]],

        [[-2.3185, -1.3191, -1.7786,  ...,  8.3678,  3.3047, -0.5910],
         [-0.8119, -3.2357, -0.0329,  ...,  1.3220, -0.3964,  0.9723],
         [ 0.6821, -0.7940, -0.2673,  ...,  3.2716,  1.7577,  0.8690],
         ...,
         [ 0.4393,  1.9984, -1.5469,  ...,  3.7783, -1.2135,  1.0420],
         [-1.5817,  0.2766, -0.7410,  ...,  1.7232,  0.2123,  0.1576],
         [-0.6927, -0.4604,  0.3543,  ...,  4.0343, -0.2260,  0.7634]]]), None)
ğŸŸ© FlamingoLayerã®é †ä¼æ’­é–‹å§‹ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32, None if attention_mask is None else attention_mask.shape=None, dict_keys(['past_key_value', 'attn_bias', 'is_causal'])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), x.dtype=torch.float32 media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­é–‹å§‹ x.shape=torch.Size([3, 26, 2048]), media.shape=torch.Size([3, 3, 64, 1024]), None if media_locations is None else media_locations.shape=torch.Size([3, 26]), use_cached_media=False
ğŸŸ¦ T_txt=26
ğŸŸ¦ T_img=3, n=64
ğŸŸ¦ q.shape=torch.Size([3, 26, 512])
ğŸŸ¦ media.shape=torch.Size([3, 192, 1024])
ğŸŸ¦ k.shape=torch.Size([3, 192, 512]), v.shape=torch.Size([3, 192, 512])
ğŸŸ¦ q.shape=torch.Size([3, 8, 26, 64]), k.shape=torch.Size([3, 8, 192, 64]), v.shape=torch.Size([3, 8, 192, 64])
ğŸŸ¦ media_time=tensor([1, 2, 3])
ğŸŸ¦ use_cached_media=False, text_time=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3],
        [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
         3, 3]])
ğŸŸ¦ mask_op=<built-in method eq of type object at 0x7212b54f74a0>
ğŸŸ¦ text_to_media_mask.shape=torch.Size([3, 1, 26, 192])
ğŸŸ¦ sim.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 26])
ğŸŸ¦ text_without_media_mask.shape=torch.Size([3, 1, 26, 1])
ğŸŸ¦ attn.shape=torch.Size([3, 8, 26, 192])
ğŸŸ¦ out.shape=torch.Size([3, 8, 26, 64])
ğŸŸ¦ out.shape=torch.Size([3, 26, 512])
ğŸŸ¦ out.shape=torch.Size([3, 26, 2048])
ğŸŸ© MaskedCrossAttentionã®é †ä¼æ’­å®Œäº† out.shape=torch.Size([3, 26, 2048])
ğŸŸ© GatedCrossAttentionBlockã®é †ä¼æ’­å®Œäº† x.shape=torch.Size([3, 26, 2048]) x.dtype=torch.float32
ğŸŸ¦ lang_x.shape=torch.Size([3, 26, 2048]), lang_x.dtype=torch.float32
ğŸŸ© FlamingoLayerã®é †ä¼æ’­çµ‚äº† (tensor([[[-1.2009, -0.4256,  0.9579,  ...,  3.0081,  1.0086, -0.1812],
         [-0.2749, -1.1022, -0.6093,  ...,  1.7677, -1.5354, -0.1590],
         [ 0.9989,  0.1369, -0.1195,  ...,  5.2063,  0.3365, -0.3707],
         ...,
         [-0.7309,  1.3117,  1.6397,  ...,  2.2348, -1.4950,  0.7095],
         [-0.1340,  1.8127, -0.4585,  ...,  6.8104, -2.1463, -0.0880],
         [ 0.0782,  0.9032, -1.1053,  ...,  0.0433,  0.2359, -1.3668]],

        [[-1.2009, -0.4256,  0.9579,  ...,  3.0081,  1.0086, -0.1812],
         [-0.2749, -1.1022, -0.6093,  ...,  1.7677, -1.5354, -0.1590],
         [ 0.9989,  0.1369, -0.1195,  ...,  5.2063,  0.3365, -0.3707],
         ...,
         [-0.7309,  1.3117,  1.6397,  ...,  2.2348, -1.4950,  0.7095],
         [-0.1340,  1.8127, -0.4585,  ...,  6.8104, -2.1463, -0.0880],
         [-1.1364,  1.7899, -0.7027,  ...,  5.5597, -2.6572,  0.5955]],

        [[-1.2009, -0.4256,  0.9579,  ...,  3.0081,  1.0086, -0.1812],
         [-0.2749, -1.1022, -0.6093,  ...,  1.7677, -1.5354, -0.1590],
         [ 0.9989,  0.1369, -0.1195,  ...,  5.2063,  0.3365, -0.3707],
         ...,
         [-0.0882,  2.4424, -0.8261,  ...,  4.8853, -2.8029,  0.2455],
         [ 0.3400,  0.9791, -1.1667,  ...,  0.0203,  0.3535, -1.3063],
         [-0.5505,  1.7580,  0.5016,  ...,  6.0343, -2.1825, -0.6970]]]), None)
ğŸŸ© FlamingoLMMixinã®é †ä¼æ’­å®Œäº†
ğŸŸ¦ output.shape=torch.Size([1, 27])
ğŸŸ© Flamingoã®generateå®Œäº† output.shape=torch.Size([1, 27]) output.dtype=torch.int64
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆå®Œäº† tensor([[50278,  1145,  2460,   273,   767, 16581,    15, 50277, 50278,  1145,
          2460,   273,   247, 15336, 16338,    15, 50277, 50278,  1145,  2460,
           273,   247,  9449, 14664,   292,    15, 50277]])
ğŸŸ© ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ: <image>An image of two cats.<|endofchunk|><image>An image of a bathroom sink.<|endofchunk|><image>An image of a Christmas buffet.<|endofchunk|>
